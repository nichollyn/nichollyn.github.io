<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>The Infinite Game</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://theinfinitegame.tech/"/>
  <updated>2020-02-03T13:39:20.594Z</updated>
  <id>https://theinfinitegame.tech/</id>
  
  <author>
    <name>猫克杯</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>极速统计教程之二十三 | 第一类错误和第二类错误</title>
    <link href="https://theinfinitegame.tech/uncategorized/statistics-type-i-and-type-ii-errors/"/>
    <id>https://theinfinitegame.tech/uncategorized/statistics-type-i-and-type-ii-errors/</id>
    <published>2020-02-03T05:58:06.000Z</published>
    <updated>2020-02-03T13:39:20.594Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第一类错误和第二类错误"><a href="#第一类错误和第二类错误" class="headerlink" title="第一类错误和第二类错误"></a>第一类错误和第二类错误</h1><p>回忆一下此前提到过的庭审的例子。被告方的辩护律师的观点是被告是无辜的，公诉方则试图说服陪审团和法官被告是有罪的。举证有罪的责任在于原告。被告只有在原告提供有力证据驳斥被告假定无罪的情况下才能被认定为有罪。</p><p>在审判时，有四种可能的结果，一，被告确实有罪且被判有罪，这是个正确的决定。二，被告确实无辜且被判无罪，这也是正确的决定。三，被告实际上是无辜的，但被判有罪，这是错误的决定。四，被告实际上有罪的，但是被判无罪，这也是错误的决定。</p><p>这也是我们在实施显著性检验时会发生的情况。辩方观点类似零假设为真，而被告有罪则等效于零假设为假。判被告有罪类似拒绝零假设，而无罪释放则等同于不拒绝零假设。这会导致四种可能的情形。其中的两种，你做了正确的决定，包括零假设的确为真并且你没有拒绝它以及零假设的确为假并且你拒绝了它。但也有两种你做了错误的决定，包括零假设为真而你拒绝了它以及零假设的确为假而你没有拒绝它。第一个错误我们称为 <strong>第一类错误 (type I error)</strong> ，或者说 <strong>伪阳性 (false positive)</strong> 。第个错误我们称为 <strong>第二类错误 (type II error)</strong> ，或者说 <strong>伪阴性 (false negative)</strong> 。</p><img src="/images/t1t2_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>让我给你举个例子。想象你的零假设是：美国的持证水肺潜水者总体， 50% 有超过 35 小时的潜水经验。换言之， $ \pi = 0.5 $ 。备选假设是它是另外一个百分比，换言之， $ \pi \neq 0.5 $ 。你问了一组简单随机抽样的 500 个美国潜水者，你发现有 0.56 的比例有超过 35 小时的潜水经验。现在，假定你的零假设实际上是真的，当你决定基于你的样本数据拒绝零假设时，一个第一类错误就出现了。 </p><img src="/images/t1t2_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><a id="more"></a><p>如果零假设为真，抽样分布是像下面这样的：</p><img src="/images/t1t2_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>如果你的显著性水平 $ \alpha $ 等于 0.05 ，通过查询 z 表得到临界值是 -1.96 和 1.96 。你的检验统计量落在拒绝域内。换言之，你要拒绝零假设。这件事情发生的概率是 0.025 加上 0.025 ，等于 0.05 。意味着第一类错误发生的概率等于显著性水平。</p><img src="/images/t1t2_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>由此，你可能想到要降低显著性水平。</p><img src="/images/t1t2_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>但是，这不一定是个好主意。如果你在零假设实际为真时降低了错误地拒绝它的概率，你实际上增加了零假设实际为假而你错误地没有拒绝它的概率。 </p><img src="/images/t1t2_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>犯第二类错误的概率我们称为 $ \beta $ 。</p><img src="/images/t1t2_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>计算 $ \beta $ 相当复杂，它依赖各种因素，例如 $ \alpha $ 的值，样本容量以及参数的真实值。基于这个原因，我们并不会去计算 $ \beta $ 的值，但重要的是你需要意识到，当我们试图降低某一类错误的概率时，另一类错误的概率会上升。</p><img src="/images/t1t2_8.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>当零假设为假时，并且你实施了检验，你希望检验的 <strong>功效 (power)</strong> 是高的。检验的功效是拒绝零假设的概率，给定它为假，换言之，一个检验的功效等于 1 减去第二类错误的概率，也就是 $ 1 - \beta $ 。</p><img src="/images/t1t2_9.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>为什么功效这么重要呢？是这样的，当你要实施一项研究之前，它可以帮助你确定你需要多少的参与者。在你实施完研究之后，它能帮助你确定结论不是统计显著的。</p><p>最后一个提示，在实践中，你永远无从得知某个决定正确与否。我们唯一能做的是控制做出不正确决定的概率。</p><hr><h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><p>想象你是一个对鲸鲨感兴趣的潜水者，你想要知道这些巨大的动物平均的身长有多少。我们还假设你已经花费了很多年在世界各地研究了这些生物。这些年你已经测量了 258 头鲸鲨。因为你已经测量了世界各地的鲸鲨，我们假定这 258 头鲸鲨可以被看作一个简单随机样本。平均的长度等于 8.3 米，样本标准差是 3.4 米，并且鲸鲨长度的分布也近似正态分布。</p><img src="/images/t1t2ex_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>在这一节中，我们将检验三种备选假设和一种零假设：鲸鲨总体的长度均值等于 8 米。第一个假设是总体均值不是 8 米。第二个假设是均值大于 8 米，第三个假设是总体均值小于 8 米。所有这几种情况中，我们都把显著性水平设为 0.10 。 </p><img src="/images/t1t2ex_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>首先，我们得检查我们的假定。如我之前说过的，鲸鲨的选择可以看作是简单随机抽样，并且我们也看到鲸鲨身长的分布近似正态。因此，我们没有理由预期总体分布会和正态分布差异巨大。再者，这也不是个问题，因为我们的样本量相当大。 </p><p>现在，让我们计算检验统计量，它的值对于几个假设都是一样的，毕竟，样本均值和零假设一样。</p><img src="/images/t1t2ex_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>代入公式， 8.3 减去 8 ，除以 3.4 除以 258 的平方根，等于大约 1.42 。</p><p>现在，我们开始第一个备选假设，它断言总体均值不是 8 米。我们画出相关的抽样分布，并显示零假设的值。我们需要基于 0.01 的显著性水平做双尾检验，查询 t 表格得到临界值 -1.66 和 1.66 ，检验统计量等于 1.42 不在拒绝域内因为我们不拒绝零假设。这意味着基于 0.10 的显著性水平，我们不能得出总体均值不是 8 的结论。</p><img src="/images/t1t2ex_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>第二个备选假设是总体均值大于 8 。抽样分布一样，但这一次我们做右尾检验。查询 t 表格得临界值是 1.29 ，这一次检验统计量是落在拒绝域内。因此在这种情况下，我们拒绝零假设，并且下结论总体的均值的确大于 8 。</p><img src="/images/t1t2ex_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>最后的备选假设是总体均值小于 8 。在这种情况下，我们做左尾检验，它是右尾的镜像，所以相关的临界值是 -1.29 。现在我们的检验统计量是 1.42 ，对于临界值时一个极端值，但它在分布的另一边。这意味着，它也不在拒绝域内，因此我们也不拒绝零假设。</p><img src="/images/t1t2ex_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>最后的例子显示，画出抽样分布很重要。否则，你可能会无法注意到检验统计量相对于临界值处于分布的另一边。不论检验的结果如何，有两件事是可以确定的。第一，鲸鲨真的很大。第二，教程即将结束，我要放假啦～感谢阅读！</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;第一类错误和第二类错误&quot;&gt;&lt;a href=&quot;#第一类错误和第二类错误&quot; class=&quot;headerlink&quot; title=&quot;第一类错误和第二类错误&quot;&gt;&lt;/a&gt;第一类错误和第二类错误&lt;/h1&gt;&lt;p&gt;回忆一下此前提到过的庭审的例子。被告方的辩护律师的观点是被告是无辜的，公诉方则试图说服陪审团和法官被告是有罪的。举证有罪的责任在于原告。被告只有在原告提供有力证据驳斥被告假定无罪的情况下才能被认定为有罪。&lt;/p&gt;
&lt;p&gt;在审判时，有四种可能的结果，一，被告确实有罪且被判有罪，这是个正确的决定。二，被告确实无辜且被判无罪，这也是正确的决定。三，被告实际上是无辜的，但被判有罪，这是错误的决定。四，被告实际上有罪的，但是被判无罪，这也是错误的决定。&lt;/p&gt;
&lt;p&gt;这也是我们在实施显著性检验时会发生的情况。辩方观点类似零假设为真，而被告有罪则等效于零假设为假。判被告有罪类似拒绝零假设，而无罪释放则等同于不拒绝零假设。这会导致四种可能的情形。其中的两种，你做了正确的决定，包括零假设的确为真并且你没有拒绝它以及零假设的确为假并且你拒绝了它。但也有两种你做了错误的决定，包括零假设为真而你拒绝了它以及零假设的确为假而你没有拒绝它。第一个错误我们称为 &lt;strong&gt;第一类错误 (type I error)&lt;/strong&gt; ，或者说 &lt;strong&gt;伪阳性 (false positive)&lt;/strong&gt; 。第个错误我们称为 &lt;strong&gt;第二类错误 (type II error)&lt;/strong&gt; ，或者说 &lt;strong&gt;伪阴性 (false negative)&lt;/strong&gt; 。&lt;/p&gt;
&lt;img src=&quot;/images/t1t2_1.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;让我给你举个例子。想象你的零假设是：美国的持证水肺潜水者总体， 50% 有超过 35 小时的潜水经验。换言之， $ \pi = 0.5 $ 。备选假设是它是另外一个百分比，换言之， $ \pi \neq 0.5 $ 。你问了一组简单随机抽样的 500 个美国潜水者，你发现有 0.56 的比例有超过 35 小时的潜水经验。现在，假定你的零假设实际上是真的，当你决定基于你的样本数据拒绝零假设时，一个第一类错误就出现了。 &lt;/p&gt;
&lt;img src=&quot;/images/t1t2_2.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>极速统计教程之二十二 | 分步计划和置信区间</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-step-by-step-plan-and-ci/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-step-by-step-plan-and-ci/</id>
    <published>2020-02-03T01:47:28.000Z</published>
    <updated>2020-02-03T12:21:50.853Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分步计划"><a href="#分步计划" class="headerlink" title="分步计划"></a>分步计划</h1><p>比较以下两种期望。一，你期望超过半数的持证美国潜水者有超过 35 小时的潜水经验。二，所有持证美国潜水者的平均潜水时长超过 35 小时。第一眼，两个期望看起来很相似。但是，在第一个例子中，你面对的是比例，你感兴趣的是潜水经验超过 35 小时的潜水者的比例。而第二个例子中，你关心的是均值。你想知道潜水时长的均值。因此，当实施显著性检验时，你需要特别注意你的方法。</p><p>这一节中，我将以分布计划的方式来引导你。想象你问了一个容量是 500 个持证潜水者的简单随机样本，他们的潜水时长是多少个小时。假设你发现 0.57 的比例有超过 35 小时的潜水经验，时长均值是 35.5 小时，均值是 8 小时。在我们的样本中，<br>潜水经验的变量分布近似正态。下面是分布计划全图：</p><img src="/images/sbs_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>第一步，评估你面对的是比例还是均值，这个我们已经讨论过。第一个例子是比例，第二个例子是均值。</p><p>第二步，形式化你的假设。在比例的例子中，零假设是：$ \pi = \pi_0 $ ，在均值的例子中，零假设是 $ \mu = \mu_0 $ 。我们可以有三种类型的备选假设：如果你做双尾检验，是 $ \pi\neq\pi_0 $ 或者 $ \mu\neq\mu_0 $ ；如果你做单尾的右尾检验，是 $ \pi\geq\pi_0 $ 或者 $ \mu\geq\mu_0 $ ；如果你做单尾的左尾检验，是 $ \pi\leq\pi_0 $ ，$ \mu\leq\mu_0 $ 。我们零假设是： $ \pi=0.5,\mu=35 $ ，备选假设是 $ \pi\geq0.5,\mu\geq35 $ 。因此我们需要实施右尾检验。</p><p>第三步，检查你的假定是否满足。在两个例子中，随机化都是必要的。你的样本必须通过随机抽样的方法收集，或者说，随机化的实验。在比例的例子中，根据零假设的比例，样本容量乘以比例以及 1 减去样本容量再乘以比例，必须等于或者大于 15 。均值的例子则要求总体分布近似正态。但实践中，这一点只有样本容量很小，且做的是单尾检验时才重要。对于我们的例子，所有的假定都满足。</p><p>第四步，确定显著性水平 $ \alpha $ 。常用的显著性水平是 0.05 。我们的检验将基于 $ \alpha=0.05 $ 。</p><p>第五步，计算检验统计量。在比例的例子中，公式是 $ z = \frac {p-\pi_0}{se_0} , se_0 = \sqrt {\frac {\pi_0 (1-\pi_0)}{n}} $ ，在均值的例子中，公式是 $ t = \frac {\bar x-\mu_0}{se_0} , se_0 = \frac {s}{n} $ 。注意，在比例的案例中，我们使用 z 分布，而在均值的案例中，我们使用 t 分布。</p><p>第六步，抽取相关的抽样分布，展示零假设和检验统计量，补上拒绝域和对应的临界值。在比例的案例中，</p><p>第七步，评估你的检验统计量是否落在拒绝域内。</p><p>第八步，决定是否拒绝零假设。</p><p>第九步，解释你的发现。</p><p>在下结论之前，值得提醒的是，不拒绝零值假设并不暗含你就可以接受零值假设。在第二个例子中，我们不拒绝零值假设，即潜水时长等于 35 小时的假设，但并不能得出潜水时长就等于 35 小时的结论。</p><hr><h1 id="显著性检验和置信区间"><a href="#显著性检验和置信区间" class="headerlink" title="显著性检验和置信区间"></a>显著性检验和置信区间</h1><p>假设你问样本容量为 500 的水肺潜水者他们潜水了多少个小时，均值是 36 小时，标准差是 8 小时，变量的样本分布近似于正态。基于样本信息，你希望推断总体的参数 $ \mu $ ，这是我们所知的推断统计学 —— 基于样本信息得出样本所在总体的结论。  </p><p>推断统计学有两种方法。其一，通过均值的置信区间来推断区间估计。其二，用显著性检验来推断点估计。在这一节中，我将向你展示这两种方法其实关联密切。</p><img src="/images/sbs_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>假定你预期潜水时长的均值不是 35 小时，你将做一个显著性检验。我们对均值感兴趣，检验统计量如下：</p><img src="/images/sbs_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>零假设是： $ \mu = 35 $ ，备选假设是： $ \mu \neq 35 $ 。我们的假定满足，分析基于简单随机样本并且样本足够大，并且样本近似正态分布。检验统计量等于 36 减去 35 ，除以 8 除以 500 的平方根，等于 2.80 。抽样分布看起来是这样的。</p><img src="/images/sbs_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>我们可以通过查询 t 表找到对应双尾检验显著性水平 0.05 的临界点是 $ \pm1.984 $ 。因此我们的检验统计量落在拒绝域内。我们将拒绝零假设，得出潜水时长不等于 35 小时的结论。</p><p>现在，如果我们构造 95% 的置信区间，会发生什么呢？公式如下：样本均值，加减 95% 置信水平对应的 t 分数，乘以标准误差，这个标准误差等于标准差除以样本容量的平方根。相关的 t 分数是 1.984 ，代入公式，得到置信区间是 35.29 到 36.71 。由此我们有信心说，通过无限重复的抽样， 95% 的情况下区间会包含实际的总体均值。这个区间给了我们关于总体均值的一个有说服力的范围。和显著性测试一样，这个置信区间也告诉我们，总体的样本均值不是 35 。通常，双尾显著性检验的结果与置信区间的结果是一致的。</p><img src="/images/sbs_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>更准确的说，如果双尾显著性检验的 P 值等于或者小于 0.05 ，那么 95% 置信区间也不包含零假设的值。类似的，如果双尾检验的 P 值大于 0.05 ，那么 95% 置信区间将包含零假设的值。</p><img src="/images/sbs_5_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这听起来很合理，对吧？它以下图表示。你会看到，观察值 36 落在拒绝域内，而对应的置信区间也不包含零假设的总体均值。</p><img src="/images/sbs_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>现在假设观察到的均值是 35.5 ，而不是 36 ，这样的话，我们的检验统计量将变成 1.40 ，它不落在拒绝域内。我们因此不拒绝零假设，相似的，置信区间的两个端点编程 34.79 和 36.21 ，则包含了零假设的均值 35 。</p><img src="/images/sbs_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>我们可以有信息说，通过无限重复抽样， 95% 的情况区间会包含实际的总体均值。这意味着零假设有说服力，我们不该拒绝零假设。也说明了，构建置信区间的方法和双尾假设检验的方法虽然看起来不同，但是数学上是相关的，彼此一致。</p><img src="/images/sbs_8.jpg" width="68%" height="68%" style="margin: 10 auto;"><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;分步计划&quot;&gt;&lt;a href=&quot;#分步计划&quot; class=&quot;headerlink&quot; title=&quot;分步计划&quot;&gt;&lt;/a&gt;分步计划&lt;/h1&gt;&lt;p&gt;比较以下两种期望。一，你期望超过半数的持证美国潜水者有超过 35 小时的潜水经验。二，所有持证美国潜水者的平均潜水时长超过 
      
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之二十一 | 假设检验和显著性检验</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-hypotheses-and-significance-test/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-hypotheses-and-significance-test/</id>
    <published>2020-02-02T05:57:35.000Z</published>
    <updated>2020-02-02T13:15:49.363Z</updated>
    
    <content type="html"><![CDATA[<h1 id="假设"><a href="#假设" class="headerlink" title="假设"></a>假设</h1><p>教程来到最后一个模块，很快我要放假了。明天我将背起行囊，出发去潜水。好吧，让我们再谨慎一点，我并不完全确定明天我能成行。我的航班可能延误，我可能睡过头误了航班，或者可能生病导致无法去潜水。总之，我期望明天出发，但我并不能完全地确定。或者说，不能 100% 确定。</p><p>当研究人员对于他们感兴趣的参数有所期待时，我们在讨论的是 <strong>统计假设 (statistical hypotheses)</strong> 。这一节将介绍统计假设。他们构成了 <strong>显著性检验 (significance testing)</strong> 方法中最主要的部分。一个统计假设，其实就是一个关于总体的期望。通常，假设会被形式化为一条对总体参数持有特定值或者落在特定范围的声明。这种声明是基于研究或者理论。基于样本的信息，我们评价一个假设靠谱与否。这个过程我们称为显著性检验，它是一种用样本数据来检验提前形式化的假设的方法。就像置信区间一样，显著性检验是一种推断统计学的方法。毕竟，我们也是用样本数据来推断关于总体参数的结论。</p><img src="/images/hypo_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>我们先来看 <strong>零假设检验 (null-hypothesis testing)</strong> ，在这种检验中，显著性检验基于两个假设， <strong>零假设 (null hypothesis)</strong> 和 <strong>备选假设 (alternative hypothesis)</strong> 。零假设以 $ H_0 $ 注记，备选假设以  $ H_a $ 注记。零假设断言你感兴趣的参数是某个特定值。它通常代表变量之间没有关联的情况，或者组与组之间没有差异的情况。它是一个当你的样本数据表明它不太可能发生时需要被拒绝的假设。而备选假设断言你感兴趣的参数落在另一个范围。通常，零假设和备选假设互斥。如果你做显著性测试，假设零假设为真，除非你的数据有很强的反面证据。</p><img src="/images/hypo_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>想象一个法庭的庭审。被告方的辩护律师的观点是被告是无辜的，公诉方则试图说服陪审团和法官被告是有罪的。举证有罪的责任在于原告。被告只有在原告提供有力证据驳斥被告假定无罪的情况下才能被认定为有罪。这正是显著性检验里发生的事情。辩护无辜相当于零假设，而有罪预期则等同于备选假设。</p><img src="/images/hypo_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>在研究实践中，你对于参数的期望是以备选假设的方式出现，而零假设就是对立面，但它必须是一个单值，不能是一个范围。你只有在数据提供强力佐证时才能认定零假设成立。</p><img src="/images/hypo_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><a id="more"></a><p>举个例子，假设你有理由相信全体美国人中有 3% 有过水肺潜水的经历。那么这里的零假设和备选假设分别是什么呢？你的期望被视为备选假设。我们把它写下来， $ H_a:\pi\leq0.03 $ ，零假设是对立面，但必须表示为单一值，因此 $ H_0:\pi=0.03 $ 。</p><img src="/images/hypo_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>假设你对水肺潜水的最大深度很感兴趣。你有理由期望美国潜水者的最大潜水深度均值 <em>不是</em> 25 米。你的备选假设是 $ \mu\neq25 $ ，零假设是 $ \mu=25 $ 。很简单，不是吗？</p><img src="/images/hypo_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>记住这条：在显著性检验中，你总是假定你的零假设成立，如果你为备选假设找到足够的支撑，就拒绝零假设。如果你没有找到足够的证据，你就不能拒绝它。但没能拒绝零假设并不意味着零假设就是真的。你可以拿法庭的例子再回味一下。在庭审中，被告被假定无罪。如果有足够的证据证明他或者她有罪，则定罪。没有足够的证据，被告则不会被定罪。但这并不意味着你可以得出他或者她是无辜的结论。</p><!-- more --><h1 id="关于比例的检验"><a href="#关于比例的检验" class="headerlink" title="关于比例的检验"></a>关于比例的检验</h1><p>假定你对有多少美国人有过水肺潜水经历这个问题感兴趣，你也有理由相信少于 3% 的美国人有这种经历。这意味着你的备选假设是 $ \pi\leq0.03 $ ，你的零假设是 $ \pi=0.03 $ 。</p><p>这一节中，我们将学习如何在对比例感兴趣时实施显著性检验。我们是这样来实施检验的：先假定我们感兴趣的总体参数有某个值，在我们收集到来自总体的样本后估计这个值的可能性。因为我们看到是一个样本，所以聚焦在抽样分布。我们可以决定，比如给定总体比例是 0.03 时样本比例的抽样分布。看下图，我们这样来实施检验：评估标准差（因为面对的是抽样分布，所以是标准误差），样本观察到的比例远离总体比例，这个标准误差的数值我们称为 <strong>检验统计量 (test statistic)</strong> 。</p><img src="/images/tap_0.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>想象我们抽取了 1000 个美国人，受试者中有水肺潜水经历的人比例等于 0.02 。接下来，我们这么做：</p><img src="/images/tap_0_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>你看到一个样本比例的抽样分布，我们假定零值假设为真，总体比例确实等于 0.03 。那么一个样本比例为 0.02 的总体，有多大的可能性其比例真的是 0.03 呢？为了回答这个问题，我们计算检验统计量，或者说样本统计和假定的总体参数之间的偏移幅度。标准误差远离均值的数量用 z 分数表示，我们可以计算样本统计量距离总体均值有多少个 z 分数。 公式如下：</p><img src="/images/tap_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>先计算零假设的标准误差，它等于 0.03 乘以 0.97 再除以 1000 ，取平方根，大约是 0.005 。因为我们的检验统计量是 0.02 减去 0.03 ，除以 0.005 ，等于 -1.85 。这意味着当零假设为真时，我们的样本比例落在总体比例 1.85 个标准误差之下。 这是否足以拒绝零假设呢？</p><img src="/images/tap_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>基于这个信息，我们可以查询 z 表格，对应的概率值是 0.0322 ，这个概率值我们称为 <strong>P 值 (P-value)</strong> 。 P 值告诉我们，基于总体比例是 0.03 的前提，要找到一个比例是 0.02 的样本，可能性是很低的。但是否低到可以拒绝零假设了呢？这取决于我们选择 <strong>显著性水平 (significance level)</strong> 。在我们实施检验之前，我们需要决定 P 值要达到多小以拒绝零假设。最常用的显著性水平是 0.05 ，这时我们说样本提供了足够的证据拒绝零假设。我们的 P 值是 0.3222 ，小于 0.05 。所以如果我们把显著性水平设置在 0.05 ，我们需要拒绝零假设。这也被我们称为 <strong>拒绝域 (reject region)</strong> 。</p><img src="/images/tap_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>形成拒绝域边界的临界 z 值是 -1.64 ，你可以通过查询 z 表格得到它，它对应 0.05 概率的左尾。我们的检验统计量是 -1.85 ，落在拒绝域内。因此我们需要拒绝零假设，并且得出结论：美国有水肺潜水经历的人的比例低于 0.03 。我们说，这个结论是 <strong>统计显著的 (statistically significant)</strong> 。</p><img src="/images/tap_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>在这个例子中，我们的检验基于备选假设是 $ \pi\leq0.03 $ 。因此，我们只聚焦在抽样分布的一边 —— 左边。这叫做 <strong>单尾检验 (one-tailed test)</strong> 。那如果我们的备选检验是 $ \pi\neq0.03 $ 呢？如果是那样的话，我们将不再只聚焦在分布的左边，而分布的两边。这种检验叫做 <strong>双尾检验 (two-tailed test)</strong> 。 </p><img src="/images/tap_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>如果我们还是采用 0.05 作为显著性水平，这意味着左边对应的累积概率是 0.025 ，右边也是。同样可以查询 z 表得到，对应的拒绝域的临界点分别是 -1.96 和 1.96 。现在，我们的检验统计量 -1.85 不再落在拒绝域内，意味着我们不能再拒绝零假设 $ \pi = 0.03 $ 。这说明，选择单尾或者双尾检验，对于结论有重大的差别。实践中，双尾检验要常用的多。我的建议是，只有你有非常好的理论依据时才使用单尾检验。</p><p>现在，让我们来改变显著性水平，看看会发生什么。比如，我们可以显著性水平设置为 0.01 ，这意味着我们在 P 值小于 0.01 时拒绝零假设。如果做单尾检验， 0.01 的显著性水平对于 -2.33 。</p><img src="/images/tap_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>在我们的例子中，检验统计量没有落在拒绝域，因此不拒绝零假设。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>如你所见，选择单尾或者双尾检验，会强烈地改变结果。需要记住的是，大部分单尾或者双尾检验都是基于 0.05 的显著性水平。</p><img src="/images/tap_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><h1 id="关于均值的检验"><a href="#关于均值的检验" class="headerlink" title="关于均值的检验"></a>关于均值的检验</h1><p>你好奇潜水者会在水下待多长时间吗？这个时间取决于他们的氧气罐，经验，潜水深度以及许多其他因素。假设你有理由期望美国潜水者在携带平均水平的氧气罐下潜到平均深度，可以待在水下超过 60 分钟，并且假设你也接触到了 100 个有经验的美国水肺潜水者，测量了他们在携带平均水平的氧气罐待在平均深度下的时长。这个样本的均值是 62 分钟，标准差是 5 分钟。</p><p>你预期潜水者可以在水下待超过 60 分钟，这导致了下面这样一个零假设： $ \mu = 60 $ ，备选假设是 $ \mu\geq60 $ 。我们实施一个关于总体均值的显著性检验，抽样分布如下：</p><img src="/images/tam_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这是一个均值等于 60 的样本均值的抽样分布， 60 是零假设的值。那么基于这样一个总体，一个样本的均值等于 60 的可能性有多大呢？ 同样，为了回答这个问题，我们计算检验统计量，它是样本均值偏离总体均值的标准误差。你可能记得如何计算标准误差 —— 我们需要用总体的标准差，因为我们不知道这个值，需要用样本标准差估计。因为这隐含着额外的误差，我们引入 t 分布来取代 z 分布。</p><img src="/images/tam_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>我们的检验统计量是通过下面的公式计算：</p><img src="/images/tam_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>由样本均值减去零假设的均值，然后除以样本均值的标准误差。标准误差等于样本标准差除以样本容量的平方根。</p><p>我们先计算出标准误差， 5 除以 100 的平方根，得 0.5 。 62 减去 60 ，再除以 0.5 ，得到 4 。这是否足以拒绝零假设呢？仍然取决于显著性水平。让我们引入最常用的显著性水平 0.05 。做单尾检验，查询 t 表，临界值是 1.67 。</p><img src="/images/tam_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>注意到我们的自由度是 99 ，但表里向下最接近的是 60 ，我们需要查看 $ t_{90%} $ ，因为右尾累积概率 0.05 。你需要记住， $ t_{90%} $ 代表置信水平为 90% ，也就表示分布的两尾加起来有 10% ，左右尾各 0.05 。</p><p>结果如下，我们的检验统计量 4 落在拒绝域内，意味着我们需要拒绝总体均值是 60 分钟的零假设。</p><img src="/images/tam_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>我们可以总结，平均情况下，有经验的美国潜水者携带平均的氧气量潜到平均的深度，能够在水下待超过 60 分钟。如果我们的期望并不是超过 60 分钟，而是不等于 60 分钟呢？</p><img src="/images/tam_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这种情况下，我们做双尾检验。假设显著性水平设置为 0.01 ，左尾和右尾的累积概率分别为 0.005 。查表，对应的临界值分别为 -2.66 和 2.66 ，而我们的检验统计量是 4 。因此，我们还是要拒绝零假设，并对我们的发现做统计显著的结论。</p><img src="/images/tam_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>因为我们现在做了双尾检验，所以我们的临时结论现在变成了有经验的美国潜水者在携带平均氧气量，潜到平均深度后，能待在水下的平均时间不等于 60 分钟。</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;假设&quot;&gt;&lt;a href=&quot;#假设&quot; class=&quot;headerlink&quot; title=&quot;假设&quot;&gt;&lt;/a&gt;假设&lt;/h1&gt;&lt;p&gt;教程来到最后一个模块，很快我要放假了。明天我将背起行囊，出发去潜水。好吧，让我们再谨慎一点，我并不完全确定明天我能成行。我的航班可能延误，我可能睡过头误了航班，或者可能生病导致无法去潜水。总之，我期望明天出发，但我并不能完全地确定。或者说，不能 100% 确定。&lt;/p&gt;
&lt;p&gt;当研究人员对于他们感兴趣的参数有所期待时，我们在讨论的是 &lt;strong&gt;统计假设 (statistical hypotheses)&lt;/strong&gt; 。这一节将介绍统计假设。他们构成了 &lt;strong&gt;显著性检验 (significance testing)&lt;/strong&gt; 方法中最主要的部分。一个统计假设，其实就是一个关于总体的期望。通常，假设会被形式化为一条对总体参数持有特定值或者落在特定范围的声明。这种声明是基于研究或者理论。基于样本的信息，我们评价一个假设靠谱与否。这个过程我们称为显著性检验，它是一种用样本数据来检验提前形式化的假设的方法。就像置信区间一样，显著性检验是一种推断统计学的方法。毕竟，我们也是用样本数据来推断关于总体参数的结论。&lt;/p&gt;
&lt;img src=&quot;/images/hypo_1.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;我们先来看 &lt;strong&gt;零假设检验 (null-hypothesis testing)&lt;/strong&gt; ，在这种检验中，显著性检验基于两个假设， &lt;strong&gt;零假设 (null hypothesis)&lt;/strong&gt; 和 &lt;strong&gt;备选假设 (alternative hypothesis)&lt;/strong&gt; 。零假设以 $ H_0 $ 注记，备选假设以  $ H_a $ 注记。零假设断言你感兴趣的参数是某个特定值。它通常代表变量之间没有关联的情况，或者组与组之间没有差异的情况。它是一个当你的样本数据表明它不太可能发生时需要被拒绝的假设。而备选假设断言你感兴趣的参数落在另一个范围。通常，零假设和备选假设互斥。如果你做显著性测试，假设零假设为真，除非你的数据有很强的反面证据。&lt;/p&gt;
&lt;img src=&quot;/images/hypo_2.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;想象一个法庭的庭审。被告方的辩护律师的观点是被告是无辜的，公诉方则试图说服陪审团和法官被告是有罪的。举证有罪的责任在于原告。被告只有在原告提供有力证据驳斥被告假定无罪的情况下才能被认定为有罪。这正是显著性检验里发生的事情。辩护无辜相当于零假设，而有罪预期则等同于备选假设。&lt;/p&gt;
&lt;img src=&quot;/images/hypo_3.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;在研究实践中，你对于参数的期望是以备选假设的方式出现，而零假设就是对立面，但它必须是一个单值，不能是一个范围。你只有在数据提供强力佐证时才能认定零假设成立。&lt;/p&gt;
&lt;img src=&quot;/images/hypo_4.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之二十 | 样本容量</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-sample-size/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-sample-size/</id>
    <published>2020-02-02T03:05:16.000Z</published>
    <updated>2020-02-02T03:43:13.026Z</updated>
    
    <content type="html"><![CDATA[<p>还是前面的新生儿父母睡觉减少时长的例子，由于我们无法去询问你家乡所有的年轻父母。我们采取简单随机抽样。一个很关键的问题是 —— 样本应该取多大。应该是 50 个就够了？或者 至少 300 个或者 1000 个？</p><p>这一节中，我们将分布讨论对均值和比例感兴趣的不同情况。</p><p>先从均值开始。样本容量主要取决于三个因素。首先是你想要的精度。记得吗，置信区间是通过点估计加减一个误差界限来得到的。你允许多大的误差界限，如果你希望它越小，那么你的样本容量就得越大。其次，你的样本容量还依赖你想要的置信水平。越大的置信水平，需要越大的样本容量。最后，数据的变异性也影响样本容量的选择。你的变量的标准差越大，你需要的样本容量也越大。公式如下：</p><p>$$ n = \frac {\sigma^2z^2}{m^2} $$</p><p>n 代表样本容量，m 代表误差界限，$ \sigma $ 代表总体的标准差， z 代表 z 分数。显而易见，你不知道总体的标准差，而且你还没抽取样本也不知道样本的标准差。所以，你需要利用 <strong>合理的猜测 (educated guess)</strong> 来估计一个值。</p><p>让我来演示这个过程是怎么样的。想象我们想要 95% 的置信水平，对应这个置信水平的 z 分数是 1.96 ，并且我不希望误差界限宽过 0.3 小时，就取 0.3 小时吧。现在我们可以填完这个公式的一部分了。现在我们需要对 $ \sigma $ 进行合理猜测了。如果已经存在这方面的研究而且你知道变量的标准差，可以简单地采纳这个标准差。但是，如果这样一个研究之前并未做过，就必须靠我们自己的猜测。我先假定某些父母根本没法睡，某些父母睡觉少于 5 个小时，并且父母们也不可能睡的比之前还多。因此，我们假定变量服从正态分布， 95% 的父母睡觉时间介于 0 到 5 个小时之间。均值是 2.5 小时，标准差是 1.25 小时。毕竟， 95% 是落在均值左右两个标准差范围内，两个标准差等于 2.5 ，那么一个标准差就是 1.25 。我们用这组数字完成公式，得到 66.69 ，取整，得出结论我们需要 67 个受试者。</p><p>对于比例感兴趣而不是均值的情况，也可以采取类似的方式。假设我们想知道新生儿在换尿布时便便的比例，我想要 99% 的置信水平，误差界限 0.10 。公式非常相似：</p><p>$$ n = \frac {p (1-p) z^2}{m^2} $$</p><p>m 是 0.10 ，z 可由查表得 2.58 ，它对应 99% 置信水平。我们不知道的是 p 。还是采用合理的猜测，或者采用一种被称为 <strong>安全方法 (safe approach)</strong> 的方式。你会发现 $ p (1-p) $ 的最大值是 0.25 ，它发生在 p = 0.5 的时候，于是我们用 p = 0.5 完成公式，0.5 乘以 0.5 乘以 2.58 的平方除以 0.10 的平方，得到 166.41 ，即 167 位受试者。</p><p>在理想世界中，你可以去寻求大样本，比如说 1000 位受试者或者更多。但是，在现实世界中，我们的时间有限，资源有限，无法抽取大样本。因此，计算所需的样本容量可以帮助我们把成本降到最低。</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;还是前面的新生儿父母睡觉减少时长的例子，由于我们无法去询问你家乡所有的年轻父母。我们采取简单随机抽样。一个很关键的问题是 —— 样本应该取多大。应该是 50 个就够了？或者 至少 300 个或者 1000 个？&lt;/p&gt;
&lt;p&gt;这一节中，我们将分布讨论对均值和比例感兴趣的不同
      
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之十九 | 比例的置信区间和置信水平</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-confidence-interval-for-proportion/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-confidence-interval-for-proportion/</id>
    <published>2020-02-02T02:28:44.000Z</published>
    <updated>2020-02-02T03:01:23.933Z</updated>
    
    <content type="html"><![CDATA[<h1 id="比例的置信区间"><a href="#比例的置信区间" class="headerlink" title="比例的置信区间"></a>比例的置信区间</h1><p>In the last couple of weeks I have<br>learned that newborn babies like to poo. They like to poo a lot. And it happens to be the case that my<br>daughter Lois especially likes to poo under specific circumstances. That is,<br>precisely when I’m changing her diaper. Seriously, once she decided to<br>answer nature’s call six times. I repeat, six times during<br>the diaper changing process. Is that normal? I’m not sure, but<br>I know how I could check it. Suppose that I asked a simple<br>random sample of 100 new parents if their baby likes to defecate while<br>his or her diaper is being changed. In this video, I’ll tell you how we can,<br>on the basis of such a study, construct a confidence interval to<br>estimate a population proportion. Say that 17% of my 100<br>respondents reported their babies like to poo while<br>the diapers is being changed. 83% reported their babies don’t do that. We thus have a proportion of 0.17, whose babies like to poo while<br>the diaper is being changed. When we construct<br>a confidence interval for a proportion, we employ the sampling<br>distribution of the sample proportion. We know that, as long as the sample is<br>large enough, this sampling distribution is normally distributed with a mean that<br>is equal to the population proportion, pi. And a standard deviation that is<br>equal to the square root of pi multiplied with one minus pi divided by n. We also know that the probability of<br>finding a sample proportion of less than about two standard deviations of the mean,<br>which is the population proportion, is 0.95. More precisely, if we look up the z score<br>which corresponds to this probability, we’ll find a value of 1.96. This means that we have a 95% chance<br>that our sample proportion will fall within 1.96 standard deviations<br>of our population proportion. This is what we call the margin of error. The formula with which we can compute<br>a 95% confidence interval looks like this. p plus and<br>minus 1.96 times the standard deviation of the sampling distribution<br>of the sample proportion. 1.96 is the z score that corresponds<br>to the 95% confidence level. So we could also write, p plus and minus the z score for the 95%<br>confidence level times the standard deviation of the sampling distribution<br>of the sample proportion. We’re talking about a 95% confidence level<br>here, that means that we can say that if we would draw an infinite number of<br>samples from a population in 95% of the cases, our confidence interval<br>would contain population proportion pi. However, as you might have noticed, we don’t know the value of<br>population proportion pi. So it is impossible to compute a standard<br>deviation of the sampling distribution of the sample proportion. We therefore substitute the population<br>parameter pi with an estimate, and this estimate is our sample statistic, P. This leads to the following formula. p plus and minus the z score for the 95%<br>confidence level times the estimated standard deviation of the sample<br>distribution of the sample proportion. Just like when we constructed the<br>confidence interval for a mean, we call this estimated standard deviation of the<br>sampling distribution the standard error. In contrast with the confidence interval<br>for a mean, when it comes to constructing a confidence interval for a proportion, we<br>don’t make use of the t distribution. And just stick with the standard<br>normal distribution. However, your data need to<br>satisfy one essential assumption. You should have at least 15 successes and<br>15 failures. In other words, n times p and n times 1 minus p need to be<br>larger than or equal to 15. If this is not the case, you cannot compute a confidence interval<br>on the basis of the discussed formula. Okay, let’s go back to our example. We have a proportion of 0.17 that reports that the baby poos while<br>the diaper is being changed. This is the formula we use. Let’s first compute the standard error. It’s the square root of 0.17<br>times 0.83 divided by 100. That makes about 0.038. The margin of error then<br>is 1.96 times 0.038. That’s about 0.07. 0.17 minus 0.07 equals 0.10 and 0.17 plus 0.07 equals 0.24. So our confidence interval<br>ranges from 0.10 to 0.24. This means that we can be 95% confident<br>that the population proportion falls between 0.10 and 0.24. Or, in other words,<br>if we would draw an infinite number of samples with n equals<br>100 from a population, and for every sample we would compute confidence<br>intervals with this margin of error, in 95% of the cases the population value<br>would fall within the confidence interval. This 95% confidence interval<br>demonstrates that most babies don’t like to poo while their<br>diaper is being changed. On the other hand,<br>it’s not that exceptional if they do poo. We can be 95% confident<br>that between 10 and 24% does poo during the changing process. Thank God, nothing is wrong<br>with my little baby, Lois. In fact, my theory is that my<br>daughter’s pooing habits are good news. That might well indicate that<br>she will be toilet trained soon. After all,<br>she doesn’t like to poo in the diaper. Now, let’s hope that later on,<br>she does like to poo in the toilet.</p><hr><h1 id="置信水平"><a href="#置信水平" class="headerlink" title="置信水平"></a>置信水平</h1><p>The 95% confidence interval, tells us that we can be 95%<br>confident that our point estimate, which could be a mean or a proportion,<br>falls within our confidence interval. Or in other words, it tells us that if we<br>would draw an infinite number of samples, similar to our extra sample and<br>for every sample, we would compute a 95% confidence<br>interval with a similar margin of error. In 95% of the cases, the population value would fall<br>within this confidence interval. This, of course, also means that<br>in 5% of the cases, this method will produce an interval that does not<br>contain the actual population parameter. If you would like to reduce the chance of<br>an incorrect inference, you could go for a larger confidence interval,<br>such as, for instance, 99%. In this video, I will tell you how<br>you can change your confidence level. And what the consequences are,<br>of doing so. Imagine you asked a sample<br>of 100 new parents, if the babies like to answer nature’s<br>call, during the diaper changing process. 17% reported that, this is the case. Our sample, proportion p,<br>thus equals 0.17. The formula to compute a 95% confidence<br>interval for a proportion is, p plus and minus the z score for the 95% confidence<br>level, times the standard error, which equals the square root of p,<br>multiplied with 1, minus p divided by n. You can look up a z score for<br>a 95% confidence level, in the z table. Look at this standard<br>normal distribution here. When you have a 0.95 probability,<br>that your value falls within z standard errors from the mean, that means, that<br>0.025 probability falls in the two tails. If you look up the z scores,<br>which are displayed here in the z table, we find values of plus or minus 1.96. You can see that here. We can now easily compute the interval,<br>that’s 0.17 plus and minus 1.96 times the standard error<br>which is the square root of 0.17, times 0.83, divided by 100. This leads to a confidence interval<br>with the end point 0.10 and 0.24. You can now imagine, that it is not so difficult to construct intervals<br>with other confidence levels. Let’s first look at the 99%<br>confidence interval. This is the formula. p plus or minus the z score for the 99% confidence<br>level, times the standard error. The only difference is,<br>the different z score. Look at this standard normal distribution. When you have a 0.99 probability that your<br>value falls within z standard errors from the mean, that means, that 0.005<br>probability falls in the two tails. If we look up the z scores,<br>which are indicated here. We find values of plus and minus 2.58. You can see that here. We can now compute the interval. That is 0.17, plus and minus 2.58,<br>times the standard error. Which was 0.038. This leads to a confidence interval<br>with the endpoints 0.07 and 0.27. For the 90% confidence level,<br>we find a z score of 1.645. This leads to a confidence<br>interval of 0.17, plus and minus 1.645, times 0.038. That makes a confidence interval<br>with the endpoints of 0.11 and 0.23. I have here displayed confidence<br>intervals graphically. You can see that a higher confidence level<br>leads to a wider confidence interval. In other words, the more confident we<br>are that we draw a correct inference, the larger of margin of error. That means, that we have to compromise<br>between confidence and precision. As one gets better, the other gets worse. We never settle for a 100% confidence<br>interval, because the margin of error then is far too large, which means that our<br>conclusions are not very informative. In most cases,<br>the 95% confidence interval is used. We can also use other confidence intervals<br>when we construct a confidence interval to estimate a population mean. Suppose, we’ve asked a sample<br>of 30 new parents in Amsterdam, how much hours of sleep they’ve lost<br>after the first child was born. The mean is 2.6 hours per night. And the standard deviation<br>is 0.9 hours per night. This is the formula we use,<br>to construct a 95% confidence interval. x-bar, plus and minus the t score for<br>the 95% confidence level, times the standard error. Which equals the sample<br>standard deviation, divided by the square<br>root of the sample size. Now, what is the t score for<br>95% confidence level? That’s dependent on the degrees of<br>freedom, which equals n minus 1. That is, 30 minus 1 is 29. In the t table, we should look in<br>the column of the 95% confidence level and in the row of 29 degrees of freedom. That gives a t score of 2.045. The confidence interval becomes 2.6<br>plus and minus 2.045, times 0.9, divided by the square root of 30. That gives an interval from 2.26 to 2.94. If we would want to construct an interval<br>with a confidence level of 99%, we simply replace the t score for the 95%<br>level with the t score for the 99% level. You can look it up in the table,<br>it’s 2.756. The confidence interval is 2.6 plus and<br>minus 2.756, times 0.9,<br>divided by the square root of 30. That leads to an interval<br>from 2.15 to 3.05. You can also easily do that for<br>other confidence levels. Let me conclude this video by<br>giving you a step by step plan for constructing a confidence interval. First, decide which confidence<br>level you want to use. For instance, do you settle for<br>the regular 95% level? Or do you want to be more confident and<br>less precise? Or more precise and less confident? Second, decide if you’re dealing<br>with a proportion or a mean. If you’re interested in a proportion,<br>you work with the z distribution, and if you’re interested in a mean,<br>you have to use the t distribution. So, in the case of a proportion,<br>you look up the relevant z score and in the case of a mean,<br>you look up the relevant t score. Don’t forget,<br>that if you’re interested in a mean, you should also compute the degrees of<br>freedom which is equal to n minus 1. Third, compute the endpoints<br>of the confidence interval. And finally, four,<br>interpret the results substantively. That’s it. If you’re not 95% confident now that<br>you can construct a confidence interval yourself, rewatch<br>the last couple of videos.</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;比例的置信区间&quot;&gt;&lt;a href=&quot;#比例的置信区间&quot; class=&quot;headerlink&quot; title=&quot;比例的置信区间&quot;&gt;&lt;/a&gt;比例的置信区间&lt;/h1&gt;&lt;p&gt;In the last couple of weeks I have&lt;br&gt;learned that
      
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之十八 | 均值的推断和置信区间</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-inference-and-confidence-interval/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-inference-and-confidence-interval/</id>
    <published>2020-02-01T03:03:48.000Z</published>
    <updated>2020-02-02T03:04:25.846Z</updated>
    
    <content type="html"><![CDATA[<h1 id="统计推断"><a href="#统计推断" class="headerlink" title="统计推断"></a>统计推断</h1><p>这一节我们以睡眠为例。假设你通常每晚睡 8 个小时，你突然做了年轻爸爸或者年轻妈妈，你的睡眠时间减少到每晚 5 个小时，这意味着每晚减少 3 个小时，相当于每周 20 个小时，每年 1000 个小时，差不多 40 天。换言之，如果你家宝宝继续保持他 / 她的睡眠时间，一年之后你会比之前少睡 大约 40 天。</p><p>回到统计学，想象你想要知道你家乡的年轻父母在孩子刚出生那一年减少了多少睡眠。在这一节中我们将讨论统计推断。我们会基于样本信息，得出关于总体的结论。我们将会区分两种统计推断的方法，一种叫 <strong>统计估计 (statistical estimation)</strong> ，另一种叫 <strong>假设检验 (hypothesis testing)</strong> 。在这篇教程中，我们将先了解统计估计。 </p><p>有两种方式估计总体参数的值，其一叫 <strong>点估计 (point estimate)</strong> ，它是一个对于总体参数的最佳猜想。其二是 <strong>区间估计 (interval estimate)</strong> ，它是一个我们预期参数会落在的范围。 </p><p>想象我们抽取了 60 个受试者样本，有了第一个小孩后每晚减少的睡眠小时数均值为 2.6 小时。这个均值是一个对于总体均值很好的点估计。换言之，$ \bar x $ ，是一个对于 $ \mu $ 的很好的点估计。不过，单一的点估计无法告诉我们估计是否接近我们感兴趣的总体参数。因此，研究人员通常还希望知道点估计可能的准确度。他们借由计算区间估计来显示这种准确度。</p><p>区间估计是一个最有可能包含总体实际参数值的数字区间。基于我们的样本均值 2.6 小时，我们可以预测，比如说，你家乡新生儿父母每晚睡眠减少的平均小时数介于 2.3 小时到 2.9 小时之间。</p><p>这个区间包含总体参数值的概率，被我们称为 <strong>置信水平 (confidence level)</strong> ，置信水平总是一个接近 1 的值，多数情况下是 0.95 。接下来我们将讨论有 95% 置信水平的区间。</p><a id="more"></a><hr><h1 id="已知总体标准差，求均值的置信区间"><a href="#已知总体标准差，求均值的置信区间" class="headerlink" title="已知总体标准差，求均值的置信区间"></a>已知总体标准差，求均值的置信区间</h1><p>假设我们知道 60 个年轻父母的样本在第一个小孩出生后睡眠减少小时数的标准差是 0.9 小时，也知道总体的标准差是 1.1 小时。（实践中，不太可能知道这个参数，但这里我们先假定你知道）</p><p>这一节中，我们将学习如何基于样本信息和总体的标准差来构造 <strong>置信区间 (confidence interval)</strong> 。首先，我们来解释一下这样一个置信区间应该如何解读。</p><p>为了构造一个置信区间，我们需要用到样本均值的抽样分布。毕竟，我们是在处理一个来自总体的样本。 我们知道，只要样本足够大，抽样分布就是正态分布的，并且均值等于总体的均值，标准差等于总体的标准差除以样本数 n 的平方根。我们还知道，找到距离样本均值少于等于两个标准差的概率是 0.95 。更精确的，如果查询对应概率的 z 分数，我们会得到 -1.96 和 1.96 。</p><p>这意味着我们有 95% 的机会令样本均值落在总体均值 1.96 个标准差范围内。 1.96 个标准差的距离我们称为 <strong>误差界限 (margin error)</strong> 。误差界限告诉我们用样本均值 $ \bar x $ 估计总体均值的准确程度。 95% 置信区间的公式如下：</p><img src="/images/ci_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>它是由点估计或者样本均值加减误差界限，即 1.96 个标准差。注意我们是在处理样本均值的抽样分布。因此分布的标准差等于 $ \frac {\sigma}{\sqrt {n}} $ 。接下来请集中注意力，因为过程会有点复杂。 </p><p>假设你抽取一个样本，样本均值由某个点表示，从均值往两侧有一根线表示误差界限。它们一起构成了 95% 的置信区间。如果样本均值落在红色区域，则置信区间包含总体均值 $ \mu $ 。如果样本均值不落在红色区域，则置信区间不包含总体均值 $ \mu $ 。我们讨论的是 95% 的置信区间，这意味着随机选择一个样本，它包含总体均值的概率是 0.95 ，不包含总体均值的 0.05 。换言之，如果我们抽取无限多个样本， 95% 的情况，我们的置信区间会包含总体的均值。</p><p>现在让我们回到例子。例子中样本均值是 2.6 小时。总体标准差 1.1 。样本容量是 60 ，现在我们有了计算置信区间需要的全部数字。公式如下：</p><p>$$ \bar x\pm1.96\sigma_{\bar x} $$</p><p>我们知道 $ \sigma_{\bar x} = \frac {\sigma}{\sqrt {n}} $ ，即 $ \frac {1.1}{\sqrt {60}} $ ，得到 0.142 。接下来计算误差界限， 1.96 乘以 0.142 ，约等于 0.28 。样本均值等于 2.6 ，因此 95% 置信区间是 2.6 减去 0.28 到 2.6 加上 0.28 的区间，即 2.32 到 2.88 。我们可以说，我们有 95% 的信心确定这个区间包含了实际的总体均值。更精确地说，如果我们从总体中抽取无限多个大小为 60 的样本，并且对于每个样本，我们计算误差界限， 95% 的情况下，总体的均值会落在样本的置信区间内。</p><img src="/images/ci_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>如果新生儿父母的这种境况会持续一年，我们有 95% 的信息说，这些人会减少 2.32 乘以 365 小时到 2.88 乘以 365 小时的睡眠时间，或者说， 846.8 小时到 1,051.2 小时，又或者说， 35.3 到 43.8 个整天。</p><hr><h1 id="未知总体标准差，求均值的置信区间"><a href="#未知总体标准差，求均值的置信区间" class="headerlink" title="未知总体标准差，求均值的置信区间"></a>未知总体标准差，求均值的置信区间</h1><p>95% 置信区间用于评估总体的均值，它告诉我们我们有 95% 的信息这个区间包含实际的总体均值。利用这个公式 $ \sigma_{\bar x} = \frac {\sigma}{\sqrt {n}} $ ，你可以计算区间的两个端点。这个公式有一个问题，为了计算置信区间，你需要知道总体的标准差。然而，我们通常并不知道这个参数。毕竟，我们本来就在用样本推测总体的参数。</p><p>这一节中，我们将学习如何在不知道总体参数的情况下做出推断。解决方案是我们估计总体的标准差，因而我们要引入另一个分布，它叫 <strong>T 分布</strong> 。让我来告诉它如何工作。</p><p>想象我们问了 60 个年轻家庭他们在有了第一个孩子之后睡眠时间少了多少个小时，均值是 2.6 小时，标准差是 0.9 小时。为了构建一个 95% 的置信区间，我们需要用到 $\bar x\pm1.96 \sigma_{\bar x}$ ，<br>或者可以写成 $\bar x\pm {Z_{95 %}} \sigma_{\bar x}$ 。这一次，我们不知道总体的标准差。</p><img src="/images/ci_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>因此我们用样本的标准差来估计总体的标准差，公式变成: $\bar x\pm {Z_{95 %}} s_e$ ，其中 $ s_e = \frac {s}{\sqrt {n}} $</p><img src="/images/ci_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>我们把 $ s_e $ 这个估计的抽样分布的标准差称为 <strong>标准误差 (standard error)</strong> 。但是因为我们现在是估计标准差，所以我们在计算中引入了额外的误差。基于此，我们引入另一个分布， z 分布。由于额外的误差，我们现在使用 T 分布，公式如下。</p><p>$\bar x\pm {t_{95 %}} s_e$</p><img src="/images/ci_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>现在让我来详细解释 t 分布和 t 分数。 t 分布跟标准正态分布非常之相似，它是钟形的，对称的，并且均值是 0 。但是，它有一点点区别。 因为我们现在是估计抽样分布的标准差，我们引入了额外的误差。当我们的样本比较小时，这个误差很可观。 t 分布将这小样本的这个误差考虑在内了，因此它比标准正态分布稍微宽一点，标准差更大一些。如下：</p><img src="/images/ci_5_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>黑色的分布是标准正态分布，蓝色的分布是 t 分布。 t 分布的准确形状取决于样本容量。样本越大，t 分布越接近标准正态分布。更准确的说， t 分布的形状取决于单一个参数，我们称为 <strong>自由度 (degrees of freedom)</strong> ，以 $ df $ 注记。 t 分布中的自由度等于样本容量 n - 1 。这意味着我们实际上有许多不同的 t 分布，每一个都有单独的 $ df $。比如，自由度为 2 的 t 分布：</p><img src="/images/ci_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>自由度为 5 的 t 分布：</p><img src="/images/ci_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>自由度为 30 的 t 分布：</p><img src="/images/ci_8.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>可以看到，当我们有 30 或者更大自由度时， t 分布几乎就等同于标准正态分布。更准确的说，标准正态分布其实就是自由度等于无限的 t 分布。 </p><img src="/images/ci_9.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>同标准正态分布和 z 分数一样，我们也可以为特定的 t 分数寻找累积概率。重要的区别在于，这些概率依赖于自由度。当你计算一个 95% 置信区间时，你可以为所有可能的自由度找到对应 95% 置信水平的 t 分数，这个表格称为 <strong>t 表格</strong> ，它和 z 表格类似。</p><img src="/images/ci_10.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>让我用睡眠时间的例子来演示。样本中睡眠减少小时数的均值是 2.6 小时，标准差是 0.9 小时，样本容量是 60 。计算 95% 置信区间的公式：</p><img src="/images/ci_11.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>让我们从标准误差开始，它等于样本标准差除以 n 的平方根，即 0.9 除以 60 的平方根，得到 0.116 。我们的标准误差，或者说，估计的样本均值的抽样分布的标准差等于 0.116 。为了计算误差界限，我们需要用标准误差乘以 95% 置信区间的 t 分数。如你所知， t 分数取决于自由度。自由度 df 等于 n - 1 。我们有 60 个样本，因此 60-1 的 50 。在 t 表格中，我们在列中查找 95% 置信水平，在行中查找 59 自由度。因为表格中没有报告 59 自由度，我们向下取 50 自由度。对应的 t 分数是 2.009 。</p><img src="/images/ci_12.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>因此我们用 0.116 乘以 2.009 ，大约 0.23 。从样本均值 2.6 中加减这个值后，得到我们的置信区间是 2.37 到 2.83 。我们有 95% 的信心认为这个区间包含实际的总体均值。</p><p>为了计算总体均值的置信区间，有两个假定需要满足。首先，你的数据是随机获取的。换言之，样本必须是随机样本，否则你的发现就不是合法的。其次，总体必须近似正态分布。这一点可能是个问题，因为总体中的许多变量可能并不是正态分布的。不过，好消息是，采用 t 分布来构造置信区间，可以有效对抗第二个假设破坏。也就是说，即使违反了假设，这种统计方法仍然是健壮的。最后，在基于 t 分布构造置信区间是，你还需要对异常值保持机警。如果数据里有异常值，那么这个方法可能会失效。因此要记得在开始之前检查数据。</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;统计推断&quot;&gt;&lt;a href=&quot;#统计推断&quot; class=&quot;headerlink&quot; title=&quot;统计推断&quot;&gt;&lt;/a&gt;统计推断&lt;/h1&gt;&lt;p&gt;这一节我们以睡眠为例。假设你通常每晚睡 8 个小时，你突然做了年轻爸爸或者年轻妈妈，你的睡眠时间减少到每晚 5 个小时，这意味着每晚减少 3 个小时，相当于每周 20 个小时，每年 1000 个小时，差不多 40 天。换言之，如果你家宝宝继续保持他 / 她的睡眠时间，一年之后你会比之前少睡 大约 40 天。&lt;/p&gt;
&lt;p&gt;回到统计学，想象你想要知道你家乡的年轻父母在孩子刚出生那一年减少了多少睡眠。在这一节中我们将讨论统计推断。我们会基于样本信息，得出关于总体的结论。我们将会区分两种统计推断的方法，一种叫 &lt;strong&gt;统计估计 (statistical estimation)&lt;/strong&gt; ，另一种叫 &lt;strong&gt;假设检验 (hypothesis testing)&lt;/strong&gt; 。在这篇教程中，我们将先了解统计估计。 &lt;/p&gt;
&lt;p&gt;有两种方式估计总体参数的值，其一叫 &lt;strong&gt;点估计 (point estimate)&lt;/strong&gt; ，它是一个对于总体参数的最佳猜想。其二是 &lt;strong&gt;区间估计 (interval estimate)&lt;/strong&gt; ，它是一个我们预期参数会落在的范围。 &lt;/p&gt;
&lt;p&gt;想象我们抽取了 60 个受试者样本，有了第一个小孩后每晚减少的睡眠小时数均值为 2.6 小时。这个均值是一个对于总体均值很好的点估计。换言之，$ \bar x $ ，是一个对于 $ \mu $ 的很好的点估计。不过，单一的点估计无法告诉我们估计是否接近我们感兴趣的总体参数。因此，研究人员通常还希望知道点估计可能的准确度。他们借由计算区间估计来显示这种准确度。&lt;/p&gt;
&lt;p&gt;区间估计是一个最有可能包含总体实际参数值的数字区间。基于我们的样本均值 2.6 小时，我们可以预测，比如说，你家乡新生儿父母每晚睡眠减少的平均小时数介于 2.3 小时到 2.9 小时之间。&lt;/p&gt;
&lt;p&gt;这个区间包含总体参数值的概率，被我们称为 &lt;strong&gt;置信水平 (confidence level)&lt;/strong&gt; ，置信水平总是一个接近 1 的值，多数情况下是 0.95 。接下来我们将讨论有 95% 置信水平的区间。&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之十七 | 样本比例的抽样分布</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-sampling-distribution-of-sample-proportion/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-sampling-distribution-of-sample-proportion/</id>
    <published>2020-01-31T09:08:32.000Z</published>
    <updated>2020-02-02T03:04:57.184Z</updated>
    
    <content type="html"><![CDATA[<h1 id="抽样分布比例"><a href="#抽样分布比例" class="headerlink" title="抽样分布比例"></a>抽样分布比例</h1><p>想象你住在巴黎，你知道所有的学生中有 0.10 的比例把自己看做嬉皮士。你想要知道这个比例的抽样分布是什么样的。注意，在这里计算总体均值是没有什么意义的。因为你感兴趣的变量是一个二元标量。学生们可以选择认定自己是或者不是嬉皮士。均值和这样一个二元变量无关。</p><p>在本节教程中，我将解释一个总体比例的抽样分布是长什么样。你知道巴黎有 10% 的学生认为自己是嬉皮士，这意味着总体比例，用 $ \pi $ 注记，等于 0.10 。现在想象我们从这个总体中抽取 200 个学生。样本的比例，用 $ p $ 注记，将会是一个接近 0.10 的数字，比如 0.09 或者 0.12 。</p><p>如果抽取了 5 组样本，样本比例可能如下：</p><img src="/images/sdp_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这样样本比例的直方图可能如下：</p><img src="/images/sdp_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>有五个值，全部都出现一次，它们的概率都是 0.2 。现在，你抽取 25 组样本，分布可能如下：</p><img src="/images/sdp_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>抽取 50 个样本，分布如下：</p><img src="/images/sdp_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>无限多组样本，分布如下：</p><img src="/images/sdp_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这是样本比例的抽样分布，分布的均值是 0.10 ，等于总体的比例。为了表明我们是处理抽样分布的均值，均值被注记为 $ \mu_p $ ，下标 p 是为了说明我们正在处理的分布的分数不是个体的分数，而是样本比例。如你所见，逻辑上和样本均值的抽样分布一模一样。</p><a id="more"></a><img src="/images/sdp_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>在样本均值的抽样分布案例中，如果总体本身是正态分布或者样本容量足够，那抽样分布是近似钟形的。通用最小需要 30 个样本数。在样本比例的抽样分布中，只有当你拥有至少 15 个正向的 case 以及至少 15 个负向 case 的前提下，你才能确信分布是钟形的，即至少 15 个嬉皮士和 15 个非嬉皮士。公式表达如下：</p><p>$$ n\pi \geq 15 $$<br>$$ n (1 - \pi) \geq 15 $$</p><p>这对于我们的例子意味着什么呢？首先，样本容量和总体比例的乘积必须大于等于 15 。在我们的案例中，即 200 乘以 0.10 ，等于 20 个嬉皮士。其次，总体比例和 $ 1 - \pi $ 的乘积必须大于等于 15 。在我们的案例中，即 200 乘以 (1-0.10)，等于 200 乘以 0.90 ， 等于 180 个非嬉皮士。 因此我们可以下结论，抽样分布将会是钟形的，因为 20 和 180 都大于 15 。有一个相当直接的公式可以计算样本比例的抽样分布的标准差。我们以 $ \sigma_p $ 注记标准差，你知道 $ \sigma $ 代表标准差，而添加的 p 则表明我们正在讨论的是样本比例的抽样分布。 为了计算这个标准差，公式如下：</p><p>$$ \sigma_p = \sqrt {\frac {\pi (1-\pi)}{n}} $$ </p><p>在我们的案例中，标准差算出来是 0.02 。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>对于二元类别变量，计算总体均值和标准差没有意义。取而代之的是，我们计算分类变量的比例。对于二元变量，我们只有总体的比例 $ \pi $ 。</li><li>相似的逻辑也适用于样本。我们也只有样本比例 p 。对于样本比例的抽样分布来说，我们的确有均值和标准差。只要知道总体的比例，抽样分布的这些参数也很容易计算出来。</li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;抽样分布比例&quot;&gt;&lt;a href=&quot;#抽样分布比例&quot; class=&quot;headerlink&quot; title=&quot;抽样分布比例&quot;&gt;&lt;/a&gt;抽样分布比例&lt;/h1&gt;&lt;p&gt;想象你住在巴黎，你知道所有的学生中有 0.10 的比例把自己看做嬉皮士。你想要知道这个比例的抽样分布是什么样的。注意，在这里计算总体均值是没有什么意义的。因为你感兴趣的变量是一个二元标量。学生们可以选择认定自己是或者不是嬉皮士。均值和这样一个二元变量无关。&lt;/p&gt;
&lt;p&gt;在本节教程中，我将解释一个总体比例的抽样分布是长什么样。你知道巴黎有 10% 的学生认为自己是嬉皮士，这意味着总体比例，用 $ \pi $ 注记，等于 0.10 。现在想象我们从这个总体中抽取 200 个学生。样本的比例，用 $ p $ 注记，将会是一个接近 0.10 的数字，比如 0.09 或者 0.12 。&lt;/p&gt;
&lt;p&gt;如果抽取了 5 组样本，样本比例可能如下：&lt;/p&gt;
&lt;img src=&quot;/images/sdp_1.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;这样样本比例的直方图可能如下：&lt;/p&gt;
&lt;img src=&quot;/images/sdp_2.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;有五个值，全部都出现一次，它们的概率都是 0.2 。现在，你抽取 25 组样本，分布可能如下：&lt;/p&gt;
&lt;img src=&quot;/images/sdp_3.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;抽取 50 个样本，分布如下：&lt;/p&gt;
&lt;img src=&quot;/images/sdp_4.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;无限多组样本，分布如下：&lt;/p&gt;
&lt;img src=&quot;/images/sdp_5.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;这是样本比例的抽样分布，分布的均值是 0.10 ，等于总体的比例。为了表明我们是处理抽样分布的均值，均值被注记为 $ \mu_p $ ，下标 p 是为了说明我们正在处理的分布的分数不是个体的分数，而是样本比例。如你所见，逻辑上和样本均值的抽样分布一模一样。&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之十六 | 样本均值的抽样分布和中心极限定理</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-sampling-distribution-and-central-limit-theorem/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-sampling-distribution-and-central-limit-theorem/</id>
    <published>2020-01-31T02:48:29.000Z</published>
    <updated>2020-02-02T03:04:42.641Z</updated>
    
    <content type="html"><![CDATA[<h1 id="抽样分布"><a href="#抽样分布" class="headerlink" title="抽样分布"></a>抽样分布</h1><p>研究人员经常会用样本来推断样本所处的总体。为了做这件事，他们需要用到统计世界中非常重要的一种概率分布 —— <strong>抽样分布 (sampling distribution)</strong> 。</p><p>这一节中，我将向你解释抽样分布是什么。需要特别注意的是，抽样分布是帮助研究人员基于仅仅一个样本得出关于总体结论的桥梁。另外说明，在这节教程中，我们假装自己知道总体是什么样的。因为在研究实践中，我们通过永远都无法得知总体的全貌。这一步对于理解推断统计学至关重要。</p><p>好吧，让我们进入正题。想象有一群北欧的嬉皮士组织了一场胡子节庆典。庆典将在挪威首都奥斯陆附近的一个小岛举行。显然，你能想到庆典的受众是有胡子的男性。组织售出了 5,000 张门票，并且提供了往来小岛的免费运送。</p><img src="/images/sdl_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>拥有门票的人将在奥斯陆的港口集结。组织将他们随即分装到运送乘客前往该岛的船上，每条船搭载 30 名庆典的粉丝。</p><img src="/images/sdl_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>现在，有一艘船迷失在挪威的群岛间。雪上加霜的是，手机网络崩溃了，因此组织无法联系上船长，船上的乘客也无法联系上组织。所有组织决定派出一些雇员去搜寻走失的船只。你正是其中的一名雇员。在历经里半个多小时的搜寻后，你看到一艘失事的船，上面有大约 30 个人。Yes，终于找到他们了。你正准备通过对讲机向组织报告失联船只已找到，这时你再看了一眼船上的乘客。你发现乘客都是一些带着小孩的家庭。这很奇怪，去胡子节的船上，不是应该都是一些随机选取的有胡子的成年男人吗？而不是一些带着小孩的年轻家庭。你认定这艘船不太可能是你要找的船，决定继续搜寻。果然，不久之后证明你的决定是明智的。你前面遇到的那艘船是一艘运送人们去另外一个岛上的家庭公园的船。</p><p>为什么要讲这个故事呢？这么说吧，如果你理解上面那个故事里 “你” 决策的原因，你就会理解抽样分布背后的基本思想。它是这样的，如果你从总体中抽取一个简单随机样本，那么它是不太可能强烈地区域于样本所处的总体的。在我们的案例中，人们正前往胡子节，他们构成了总体。一艘载有 30 个从总体中随机选取的人的船就是一个简单随机样本。</p><img src="/images/sdl_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>实际上，所有从奥斯陆港口前往庆典小岛的船都可以看做是一个简单随机样本。当然，每艘船都和其他船不一样，但大部分船都会包含大比例的有胡子的男人。不太可能有一艘船上都是各种年轻家庭。当然，有某些家庭参加胡子节是可能的，但是随机遇到一艘船，全部都是年轻家庭，则是非常不太可能发生的。</p><img src="/images/sdl_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>假设你决定测量每艘船的平均胡子长度。每艘船有 30 个人。想象 5,000 个庆典参与者的平均胡子长度时 10.3 毫米，即均值是 10.3 毫米。你还知道胡子的长度在总体中服从一个钟形的分布。在一艘船上，你可能遇到胡子平均长度是 9.4 毫米，另一艘则可能是 10.8 。但是，不太可能遇到一艘船，上面的人平均胡子长度是 3.4 毫米，或者 19.2 毫米。因为这些船上的人的胡子的平均值可以看作是样本的均值，我们用 $ \bar x $ 来注记。</p><img src="/images/sdl_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><a id="more"></a><p>现在想象你正看着三艘船，概率分布可能长这样：</p><img src="/images/sdl_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>一艘船的均值是 9.9 ，一艘是 10.7 ，还有一艘是 10.2 。我们一共有三艘，所以每个均值的概率是 0.33 。现在想象有 17 艘船，40 艘船，100 艘船，你会发现胡子均值长度的分布会越来越接近钟形分布，并且，你会发现分布的均值接近 10.3 ，跟总体的均值一模一样。</p><img src="/images/sdl_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>如果你仔细琢磨一下，就发现这并不奇怪。你会期望，在绝大多数情况下，样本的均值和总体的均值接近。某一艘船的均值可能高一点，另一艘船的均值可能低一点。但是，当你看到许多船时，你会期望所有这些不同船的均值的均值，就等于总体的均值。</p><img src="/images/sdl_8.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>现在，想象你的总体包含了所有的挪威男人。你知道这个总体的胡子长度均值是 1.22 毫米，并且变量服从一个钟形分布。如果你抽取一个 30 人的简单随机样本，你会发现均值接近总体均值，比如 1.34 毫米。你再抽取另一个随机样本，均值可能是 1.19 毫米，也很接近总体均值。如果你重复五次，你会得到五个不同的值，但是都很接近总体的均值。</p><img src="/images/sdl_9.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>当我们可以抽取无限多个样本时，分布将会是一个完美的钟形，均值是精确的 1.22 毫米，跟总体均值一样。我们把这种分布称为 <strong>样本均值的抽样分布 (sampling distribution of the sample mean)</strong> ，它是这样一种分布：你从总体中无限抽取样本，计算所有样本的均值。</p><img src="/images/sdl_10.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>目前为止，你应当意识到，在实际的研究中，我们不可能从某个总体中抽取无限多的样本。但是，你需要知道，如果我们能这么做，这个分布的均值将等于总体的均值，这正是我们把这个分布称为样本均值的抽样分布的原因。不要把这个和样本或者数据分布混淆在一起，这只是实际抽取的一个样本的分布，只针对实际收集的数据而言。</p><hr><h1 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h1><p>如果你从钟形分布的总体中取无限个样本，来自这个无限个样本的均值分布将会是钟形的。并且这种样本均值的分布将会和总体均值完全一样。我们将此分布称为样本均值的抽样分布。</p><p>在这一节中，我将讨论 <strong>中心极限定理 (central limit theorem)</strong> —— 推理统计学中，最重要的公式之一。 </p><img src="/images/sdl_11.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>中心极限定理表明，假设样本量足够大，样本均值 $ \bar X $ (x 的均值) 的抽样分布近似正态分布，即使这个变量在总体中并不是正态分布。这不是很神奇吗？不用理会变量在总体中是如何分布的，样本均值的抽样分布总是如此，总是近似正态分布，只要样本量足够大。作为足够大的指导，通常使用 30 或更大的样本。</p><img src="/images/sdl_12.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>你们可以看这些总体分布可能的形状。这是当你取样本容量 n=30 时，样本均值的抽样分布图。记住，这意味着你从总体中抽取了无数个由 30 个调查对象组成的随机样本，在分布中显示所有生成的样本均值。</p><p>你应该意识到，在实践中，根本不可能抽取无数个样本。但是，好消息是根本不需要抽取多个样本来确定样本分布的形状。 因为如果它是正态分布，你可以通过两个参数来描述它的形状，即均值和标准差。因此，估计这两个参数就足够了。正如我之前告诉你的那样，抽样分布的均值等于总体分布的均值。我们可以这样表示，$ \mu_{\bar x} = \mu $，$ \mu $ 代表总体的均值，$ \mu_{\bar x} $ 代表样本均值的均值。 </p><p>想象你对挪威男人的平均胡须长度感兴趣。总体包括所有挪威男子，$ \mu $ 是总体的平均胡须长度。我们假设它是 1.22 毫米。对于样本均值的均值，如果我们从总体中抽取无数个样本，并记下每个样本中的平均胡须长度，我们就会得到这个分布的平均值，等于总体均值 1.22 。$ \bar X $ 是用来强调抽样分布中的分数是样本均值，而不是个体的分数。换句话说，总体分布的平均值是所有挪威男性的胡子长度得分的平均值。抽样分布的均值是从该人群中抽取的无限多个样本的样本平均值。</p><img src="/images/sdl_13.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>如果我们知道总体分布如何，我们可以轻松的计算出样本的标准差。抽样分布的标准差的符号化是 $ \sigma_{\bar x} = \frac {\sigma}{\sqrt {n}} $ 。添加 $ \bar x $ 下标是为了表明我们正在谈论抽样分布的标准差，其中分数是样本均值，或者换句话说，$ \bar x $ 的 $ \mu $。$ \sigma $ 代表总体的标准差， n 代表样本的大小。此公式表明抽样分布的标准差受两个特征影响。首先，它受总体标准差的影响，假设 n 等于 30 ，你的总体标准差是 1 ，你的抽样分布的标准差等于 1 除于根号 30 ，等于 0.18 。如果你的总体标准差增加至 2 ，样本的标准差变成 2 除于根号 30 ，即 0.37 ，如果你的总体标准差变成 3，样本的标准差变成 0.55 ，等等。</p><p>所以，如果总体分布的的标准差增加，抽样分布的标准差也会增加。换句话说，总体方差越大，样本均值的方差越大。这在直觉上是合理的，对吧？如果你从人群中胡须长度差异很大的人群中抽取 30 个受试者的各种样本，你可以预期这些样本的相互之间的差异比你从几乎没有差异的总体中抽取各种样本的差异更大。你的抽样分布的标准差，也会受到样本容量的影响。再看看这个公式。假设总体标准差等于 2 。现在，如果 n=30 ，$ \sigma_{\bar x} $ 等于 2 除于根号 30 ，等于 0.37 。 如果 n=100 ，你的抽样分布的标准差将变为 2 除于根号 100 ，等于 0.2 。如果 n = 500 ，你的 $ \sigma_{\bar x} $ 变为 0.09 。</p><img src="/images/sdl_14.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这表明，一个更大的样本量导致抽样分布的标准差更小。这在直觉上也是合理的。如果总体中的挪威男性的平均胡子长度为 1.22 毫米，你只有两个受访者作为样本，找到一个更高的平均值并不奇怪。如果你抽取了五个样本，你的样本均值是看起来像这样。</p><img src="/images/sdl_15.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>现在，想象一下你抽取了一个 1000 个受试者的样本，这个样本的均值不太可能是 5 或者 10 毫米。毕竟，长胡子的人会被完全没有胡子的人抵消。如果你抽取五组样本，样本均值可能看起来像这样。</p><img src="/images/sdl_16.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>它们都将非常接近总体平均值 1.22 毫米。所以你的样本容量越大，样本均值越接近总体均值，样本分布的标准差越小。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>中心极限定理告诉你：无论变量在总体中分布如何，只要样本容量至少为 30 ，样本平均值的抽样分布都近似正态分布。</li><li>抽样分布的均值 $ \mu_{\bar x} $ 等于总体均值 $ \mu $ ，抽样分布的标准差 $ \sigma_{\bar x} $ 等于总体分布的标准差 $ \sigma $ 除于 $ \sqrt {n} $。</li></ul><hr><h1 id="三种分布"><a href="#三种分布" class="headerlink" title="三种分布"></a>三种分布</h1><p>许多社会的、政治的以及宗教的团体有它们自己的神圣文字。嬉皮士，也有它们自己的 “圣经”，这是一本名叫 “On the Road” 的书。这一节中，我们对于纽约市的嬉皮士花了多少时间读这本书感兴趣。</p><p>假设我们知道总体，所有嬉皮士读这本书的平均时长是 943 分钟。我们还知道，总体的标准差等于 212 分钟。你从总体中做简单随机抽样抽取了 200 个受试者。这个样本中的平均阅读时长是 867 分钟，标准差 188 分钟。</p><p>这一节，我将介绍对于研究项目十分重要的三种分布 —— <strong>总体分布 (population distribution)</strong> ，<strong>样本分布 (sample distribution)</strong> ， <strong>抽样分布 (sampling distribution)</strong> 。我将向你展示，如果计算针对特定分数的选择性个体的概率。 </p><p>第一个分布，总体分布，它看起来像这样，近似钟形，均值 943 分钟，标准差 212 分钟，主体是纽约的嬉皮士们。</p><p>第二个分布，数据分布或者是样本分布，它是样本数据的分布，看起来像这样。它跟总体分布一样，近似钟形，均值 867 分钟，和总体均值 943 分钟相差不大。标准差 188 分钟。</p><img src="/images/sdl_17.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>注意，样本统计里采用罗马字母注记，而总体里采用希腊字母注记。</p><p>第三种分布，样本均值的抽样分布，它就像下面这样：</p><img src="/images/sdl_18.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>根据中心极限理论，它是正态分布的。在这个分布中，主体不是分布中的个体，而是来自纽约嬉皮士的 200 个受试者样本的一个不确定的数字。样本均值的抽样分布的均值，是这些不确定样本均值的均值。具体的数值，等于总体分布均值的数值，即 943 分钟。为了说明我们正在讨论的是抽样分布，我们添加 $ \bar x $ 下标来表明是样本均值的均值而不是个体分数的均值。抽样分布的标准差，等于总体标准差，除以 n 的平方根，即 212 ，除以 200 的平方根，得到 15 。</p><p>你需要记住的是，第三个分布是一个理论上的分布。我们并不实际地收集无限多的样本。那是不可能做到的，也不必做到。因为只要我们知道总体的均值和标准差，我们就能知道抽样分布长什么样。正态分布的一个大好处是，我们可以通过把原始分数变换成 z 分数，以及引入 z 表格，找出概率。</p><p>现在，想象你从总体中选择一个随机样本，这个嬉皮士阅读时长大于等于 1000 分钟的概率是多大呢？</p><p>首先，我们需要知道一个嬉皮士阅读那本书的时长等于 1000 分钟距离均值有多少个标准差。我们在总体中计算这个人的 z 分数，z 分数是 1,000 减去 943 ，除以 212 ，等于 0.27 。我们感兴趣的是这个值右边的区域。查询 z 表格，我们发现选中一个阅读时长大于等于 1,000 分钟的嬉皮士的概率是 39% 。现在，想象我们抽取 200 个嬉皮士。这个样本均值大于等于 1,000 分钟的概率是多少？千万注意，这是一个完全不同的问题。我们不是在讨论从总体中选取一个特定的人，而是在讨论基于总体中的特定样本的统计学。因此，我们不用总体分布，而是样本均值的抽样分布。通常，过程是相同的，只不过我们用的是不一样的均值和标准差。这里， z 分数计算过程如下。我们从感兴趣的均值，即 1000 ，减去抽样分布的均值，即 943 ，然后除以抽样分布的标准差，即 212 除以 200 的平方根，即 15 。因此， (1000 - 943) / 15 ，最后得到 z 分数是 3.8 。查询 z 表格，我们发现抽取一个样本的平均阅读时长均值大于等于 1,000 分钟的概率是 0.01% 。</p><img src="/images/sdl_19.jpg" width="68%" height="68%" style="margin: 10 auto;"><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><ul><li>决定选用哪种分布时，需要十分小心。如果你是对选择的独立个体感兴趣，应当使用总体分布；但如果你是对选择的样本感兴趣，应当使用抽样分布。在实际的研究实践中，混淆总体和抽样分布几乎不可能发生。因为你永远无从知道总体的全貌。你唯一可以确定的是你的样本长什么样。</li></ul><p>接下来，我们会学习如何在缺少总体分布信息的情况下，利用好抽样分布。</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;抽样分布&quot;&gt;&lt;a href=&quot;#抽样分布&quot; class=&quot;headerlink&quot; title=&quot;抽样分布&quot;&gt;&lt;/a&gt;抽样分布&lt;/h1&gt;&lt;p&gt;研究人员经常会用样本来推断样本所处的总体。为了做这件事，他们需要用到统计世界中非常重要的一种概率分布 —— &lt;strong&gt;抽样分布 (sampling distribution)&lt;/strong&gt; 。&lt;/p&gt;
&lt;p&gt;这一节中，我将向你解释抽样分布是什么。需要特别注意的是，抽样分布是帮助研究人员基于仅仅一个样本得出关于总体结论的桥梁。另外说明，在这节教程中，我们假装自己知道总体是什么样的。因为在研究实践中，我们通过永远都无法得知总体的全貌。这一步对于理解推断统计学至关重要。&lt;/p&gt;
&lt;p&gt;好吧，让我们进入正题。想象有一群北欧的嬉皮士组织了一场胡子节庆典。庆典将在挪威首都奥斯陆附近的一个小岛举行。显然，你能想到庆典的受众是有胡子的男性。组织售出了 5,000 张门票，并且提供了往来小岛的免费运送。&lt;/p&gt;
&lt;img src=&quot;/images/sdl_1.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;拥有门票的人将在奥斯陆的港口集结。组织将他们随即分装到运送乘客前往该岛的船上，每条船搭载 30 名庆典的粉丝。&lt;/p&gt;
&lt;img src=&quot;/images/sdl_2.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;现在，有一艘船迷失在挪威的群岛间。雪上加霜的是，手机网络崩溃了，因此组织无法联系上船长，船上的乘客也无法联系上组织。所有组织决定派出一些雇员去搜寻走失的船只。你正是其中的一名雇员。在历经里半个多小时的搜寻后，你看到一艘失事的船，上面有大约 30 个人。Yes，终于找到他们了。你正准备通过对讲机向组织报告失联船只已找到，这时你再看了一眼船上的乘客。你发现乘客都是一些带着小孩的家庭。这很奇怪，去胡子节的船上，不是应该都是一些随机选取的有胡子的成年男人吗？而不是一些带着小孩的年轻家庭。你认定这艘船不太可能是你要找的船，决定继续搜寻。果然，不久之后证明你的决定是明智的。你前面遇到的那艘船是一艘运送人们去另外一个岛上的家庭公园的船。&lt;/p&gt;
&lt;p&gt;为什么要讲这个故事呢？这么说吧，如果你理解上面那个故事里 “你” 决策的原因，你就会理解抽样分布背后的基本思想。它是这样的，如果你从总体中抽取一个简单随机样本，那么它是不太可能强烈地区域于样本所处的总体的。在我们的案例中，人们正前往胡子节，他们构成了总体。一艘载有 30 个从总体中随机选取的人的船就是一个简单随机样本。&lt;/p&gt;
&lt;img src=&quot;/images/sdl_3.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;实际上，所有从奥斯陆港口前往庆典小岛的船都可以看做是一个简单随机样本。当然，每艘船都和其他船不一样，但大部分船都会包含大比例的有胡子的男人。不太可能有一艘船上都是各种年轻家庭。当然，有某些家庭参加胡子节是可能的，但是随机遇到一艘船，全部都是年轻家庭，则是非常不太可能发生的。&lt;/p&gt;
&lt;img src=&quot;/images/sdl_4.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;假设你决定测量每艘船的平均胡子长度。每艘船有 30 个人。想象 5,000 个庆典参与者的平均胡子长度时 10.3 毫米，即均值是 10.3 毫米。你还知道胡子的长度在总体中服从一个钟形的分布。在一艘船上，你可能遇到胡子平均长度是 9.4 毫米，另一艘则可能是 10.8 。但是，不太可能遇到一艘船，上面的人平均胡子长度是 3.4 毫米，或者 19.2 毫米。因为这些船上的人的胡子的平均值可以看作是样本的均值，我们用 $ \bar x $ 来注记。&lt;/p&gt;
&lt;img src=&quot;/images/sdl_5.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之十五 | 样本和抽样</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-sample-and-sampling/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-sample-and-sampling/</id>
    <published>2020-01-21T12:13:49.000Z</published>
    <updated>2020-01-31T11:34:16.436Z</updated>
    
    <content type="html"><![CDATA[<h1 id="样本和目标总体"><a href="#样本和目标总体" class="headerlink" title="样本和目标总体"></a>样本和目标总体</h1><blockquote><p>几乎所有的统计研究都基于样本。</p></blockquote><p>想象你试图知道伦敦有多少学生以嬉皮士自居，但你几乎不可能去问全部的学生这个问题。所以你决定采样，比方说 200 个调查对象，并估计有多少人把自己看做嬉皮士。</p><p>关于统计的一个好处是，它能基于仅仅这 200 个调查对象，即样本，帮助你得出关于伦敦所有学生的结论，即目标总体。这一节中，我将详细解释样本和目标总体。</p><p><img src="/images/sampling_1.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>如果你从目标总体约 300,000 个学生中选择 200 个调查对象作为样本，基本上你正在聚焦于总体的一个子集。如果你测量一组变量，比如性别，年龄，所在学校，等等。你可以做所有的计算，比如单一变量分析，包括众数、平均数和标准差，或者双变量分析，计算皮尔逊相关系数或者做回归分析。所有这些数字性总结都完全是基于样本，它们被称为 <strong>统计数字 (statistics)</strong> 。通常，这种总结样本数据的方法被称为 <strong>描述统计 (descriptive statistics)</strong> 。不过，在实际的研究实践中，我们经常对特定样本的总结不感兴趣 —— 我们的实际目标是对潜在的目标总体做出推断。</p><p><img src="/images/sampling_2.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>在我们的案例中，所有 300,000 个学生都在伦敦。如果我们借由样本中得到的数据推断关于总体的结论，那我们就是在使用 <strong>推断统计学 (inferential statistics)</strong> 的方法。 统计数字以罗马字母显示。例如，$ \bar x $ 代表平均数， s 是样本的标准差。 参数则以希腊字母显示， μ 代表总体的平均值， σ 代表总体的标准差。 </p><p><img src="/images/sampling_3.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>想象你问这 200 个调查对象他们觉得自己有多大程度上把自己看做嬉皮士。他们可以从 0 到 10 表示自己嬉皮士的程度， 0 代表他 / 她根本不认为自己是嬉皮士，而 10 代表一个人完全将自己视为嬉皮士。</p><p>现在想象样本的 “嬉皮士值” 均值是 3.12 ，核心问题变成：目标总体的均值是多少？推断统计学可以帮助我们解答这类问题。</p><a id="more"></a><h1 id="抽样"><a href="#抽样" class="headerlink" title="抽样"></a>抽样</h1><p>推断统计学指的是基于样本数据来得出对于总体的结论的一系列方法。可以想象，为了理解推断统计学的方法，学会如何抽取样本是至关重要的。这一节中，我将把好的抽样方法和坏的抽样方法放在一起一同讨论。同时，我会讨论到你在抽样过程中可能遭遇的各种 <strong>偏差 (bias)</strong> 。</p><p>样本是总体的子集，此外再无其他。对于推断统计学的方法来说，并非所有的样本都合用。你需要的是 <strong>代表性样本 (representative samples)</strong> 。换言之，你需要你的样本是总体的一个微型版本。为了达到这个目的，一个不错的方法是抽取 <strong>简单随机抽样 (simple random sample)</strong> 。这意味着你确信总体中的每一个对象都有相同的机会被选中。</p><p><img src="/images/sampling_4.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>回到嬉皮士的例子。你决定抽取 200 个调查对象。平均的嬉皮士值是 3.12 ，总体包含伦敦所有的学生，感兴趣的参数是总体的均值，样本包含 200 个被选中的学生。</p><p>你将用于推断总体均值的统计数据是样本的统计均值。为了得出结论，我们希望样本是简单随机样本。如何确保这一点呢？</p><p><img src="/images/sampling_5.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>首先，你需要搞清楚总体是怎样的。我们已经知道，总体是全体伦敦学生。</p><p>第二步，得到全部主体的名单，我们称之为 <strong>抽样框 (sampling frame)</strong> 。想象伦敦有一个组织拥有所有学生的概况信息，包括他们的通信录细节。进一步的，这个组织愿意和你共享名单。你让计算机从名单中随机抽取 200 个学生。这样一来，你就得到了一个简单随机样本。</p><p>下一步是确定你如何触达你的 200 个调查对象。在面对面的采访中，你和调查对象在相同的房间，面对面提问。这么做到的好处是调查对象比较有可能参与，缺点是这样收集数据太昂贵了。另一个选项是通过电话采访，这么做开销小很多，但通常调查对象在电话上耐心有限，因此采访时间短暂。你还可以让调查对象填写问卷。因为他们可以在线完成调查，所以也是很便宜的选项，缺点是他们很可能不参与。</p><p>与此同时，你会遭遇各种形式的偏差。第一个是 <strong>覆盖偏差 (undercoverage)</strong> ，它指的是采样数据框没有囊括所有的个体。在伦敦学生的例子中，如果学生的清单不完整，就会发生这种偏差。有的学生没有机会被纳入样本。</p><p>还有 <strong>抽样偏差 (sampling bias)</strong> ，它指的是每个个体被纳入样本的机会不是均等的。当你的抽取做不到随机时，这种偏差就会发生。举个例子，如果你选择在街上随机接触人群，我们称为 <strong>任意抽样</strong> 或者 <strong>便利抽样 (convenience sample)</strong> 。它并非随机，因为有些人比其他人更少上街，他们被纳入样本的机会就更小。</p><p>其三，在你取得样本后，还有一种形式的偏差，它叫 <strong>无应答偏差 (nonresponse bias)</strong> 。某些被选中的主体可能拒绝参与实验，或者就是无法触达。还有些同意参与的调查对象只愿意回到特定的部分问题。</p><p>问题在于，这些不参与的情况可能不同于总体样本。无论它是覆盖偏差，抽样偏差或者无应答偏差。因为这些个人没有机会被抽样或者被抽样的机会更小，抑或这些个人拒绝回答某些问题，我们可能高估或者低估调查的目标。</p><p>简言之，我们的判断 (estimation) 会因某些分群的 <strong>表达不足 (under-representation)</strong> 或者 <strong>过表达 (overrepresentation)</strong> 出现偏差。</p><p>最后，还有 <strong>反应偏差 (response bias)</strong> 。在这个案例中，实际给定的反应是有偏差的。有可能，因为调查者问了某些前置的其他问题或者调查对象认为某些答案是社会不能接受的。有可能某个学生认为自己是个嬉皮士，但他认为调查者不喜欢嬉皮士于是就告诉调查者他不是。在我们的案例中，评估可能因为某些回应的 <strong>系统性误表达 (misrepresentations)</strong> 而出现偏差。</p><p><img src="/images/sampling_6.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>因此，在抽取样本时，你需要确保抽样是简单随机抽样，尽可能将各种形式的偏差降到最低。不过，很多情况下我们几乎不可能做到简单随机抽样。所幸，有另外两种随机抽样方式一样奏效。</p><p>在介绍它们之前，让我们先重温一下简单随机抽样的工作方式。如果你的总体中包含了所有的伦敦学生，你打算抽取 200 个学生的样本。你把所有学生的名字写在纸上。你把所有的纸放进箱子里，然后随机抽 200 张纸。这就是简单随机抽样。</p><p>第一个替代方案是 <strong>随机多阶段整群抽样 (random multi-stage cluster sample)</strong> 。它的工作方式如下：首先，你在总体中标识出大量的 <strong>整群 (cluster)</strong> ，比如，根据学生注册的不同的教育程序，每种程序用一个桶表示。把学生的纸按照注册的教育程序放入不同的桶中。接下来，你随机选几个桶，然后从这些桶中选取代表学生的纸，这样就得到了样本。多阶段整群抽样在你无法拿到很完整抽样数据框，或者简单随机抽样太昂贵时是一个很好的替代方案。</p><p>第二个替代方案是 <strong>分层随机抽样 (stratified random sample)</strong> 。现在，你将总体分成独立的组，这些组我们称为 <strong>层 (strata)</strong> 。例如，伦敦的各所大学，每个大学用一个盒子表示。你把学生的名字按照他们注册的大学放进不同的盒子里。接下来，你从每个盒子里随机挑出名字。所有这些名字就构成了你的样本。这种方法的好处是你可以确信样本中每一层都有足够的个体，缺点是你需要数据框，你还需要知道每个调查对象属于哪一层。</p><p>有一个重要的警告。大样本无法弥补糟糕的抽样步骤。如果你的样本不够随机，尽管你可以一直增加抽样数，你的样本也永远不会变得更好。假设你的样本是随机的，那大样本理论上总是更好的。不过，一旦你超过了某个临界点，样本量的增加对于总体参数评估准确度的影响就微乎其微了。</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;样本和目标总体&quot;&gt;&lt;a href=&quot;#样本和目标总体&quot; class=&quot;headerlink&quot; title=&quot;样本和目标总体&quot;&gt;&lt;/a&gt;样本和目标总体&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;几乎所有的统计研究都基于样本。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;想象你试图知道伦敦有多少学生以嬉皮士自居，但你几乎不可能去问全部的学生这个问题。所以你决定采样，比方说 200 个调查对象，并估计有多少人把自己看做嬉皮士。&lt;/p&gt;
&lt;p&gt;关于统计的一个好处是，它能基于仅仅这 200 个调查对象，即样本，帮助你得出关于伦敦所有学生的结论，即目标总体。这一节中，我将详细解释样本和目标总体。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/sampling_1.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;&lt;/p&gt;
&lt;p&gt;如果你从目标总体约 300,000 个学生中选择 200 个调查对象作为样本，基本上你正在聚焦于总体的一个子集。如果你测量一组变量，比如性别，年龄，所在学校，等等。你可以做所有的计算，比如单一变量分析，包括众数、平均数和标准差，或者双变量分析，计算皮尔逊相关系数或者做回归分析。所有这些数字性总结都完全是基于样本，它们被称为 &lt;strong&gt;统计数字 (statistics)&lt;/strong&gt; 。通常，这种总结样本数据的方法被称为 &lt;strong&gt;描述统计 (descriptive statistics)&lt;/strong&gt; 。不过，在实际的研究实践中，我们经常对特定样本的总结不感兴趣 —— 我们的实际目标是对潜在的目标总体做出推断。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/sampling_2.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在我们的案例中，所有 300,000 个学生都在伦敦。如果我们借由样本中得到的数据推断关于总体的结论，那我们就是在使用 &lt;strong&gt;推断统计学 (inferential statistics)&lt;/strong&gt; 的方法。 统计数字以罗马字母显示。例如，$ \bar x $ 代表平均数， s 是样本的标准差。 参数则以希腊字母显示， μ 代表总体的平均值， σ 代表总体的标准差。 &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/sampling_3.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;&lt;/p&gt;
&lt;p&gt;想象你问这 200 个调查对象他们觉得自己有多大程度上把自己看做嬉皮士。他们可以从 0 到 10 表示自己嬉皮士的程度， 0 代表他 / 她根本不认为自己是嬉皮士，而 10 代表一个人完全将自己视为嬉皮士。&lt;/p&gt;
&lt;p&gt;现在想象样本的 “嬉皮士值” 均值是 3.12 ，核心问题变成：目标总体的均值是多少？推断统计学可以帮助我们解答这类问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之十四 | 二项分布</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-binomial-distribution/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-binomial-distribution/</id>
    <published>2020-01-19T04:57:01.000Z</published>
    <updated>2020-01-19T07:35:20.509Z</updated>
    
    <content type="html"><![CDATA[<p>对于离散随机变量，有一个最重要的概率分布，它是 <strong>二项分布 (binomial distribution)</strong> 。二项分布处于二元数据。因为二元数据的情况非常多，所以二项分布使用频繁。</p><p>让我们从例子开始，你会在这些例子中看到两种结果。比如，参加会议是否迟到，投票赞成或者反对，噪音等级超过 80 分贝或者没有。当你收集这类现象的试验时，成功或者失败的数字服从二项分布。例如，你可以考虑每 25 个与会人员，有多少个迟到，或者投反对票的人有几个。</p><img src="/images/bd_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>下面是你可以确定一个随机变量服从二项分布的条件：首先，每一个试验成功的概率相同；其次，试验在统计上是独立的 —— 即一个试验的结果不会影响其他试验。</p><img src="/images/bd_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>实际上，你发现二项分布的三个要素。首先，试验现象有两种结果，并且成功概率是常量。这种实验被称为 <strong>伯努利试验验 (Bernoulli trial)</strong> 。其次，你观察试验结果 n 次。第三，你对成功的结果计数，记为 x 。这三个元素被结合成一个公式，它给出了在 n 次试验中取得特定数量成功结果的概率。公式如下：</p><p>$$ P (x) = \frac {n!}{x!(n - x)!} p^x (1 - p)^{n-x}, x = 0,1,2,…,n $$</p><p>你可以直接把 n，x 和 p 填进公式从而获得答案。</p><img src="/images/bd_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>如公式所示，随机变量 x 只能取 0 到 n 的值。这很合理，因为你只能有有限次成功，0 ，1 ， 2 ，直到 n 。因此这个公式是一个概率质量函数，它直接给出了匹配每个可能的 x 的概率值，你不必像考虑概率密度函数那样考虑区间。</p><img src="/images/bd_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>感叹号不常见，它表示 <strong>阶乘法 (factorial)</strong> ，即把所有从 1 到指定的整数全部相乘的结果。例如， 4 阶乘等于 1 乘以 2 乘以 3 乘以 4 。 公式前部的这个阶乘的除法实际上是给出了无视顺序，从 n 个元素中选出 x 个元素的方法，它也被称为 <strong>二项系数 ( binomial coefficient)</strong> ，有的时候也速记为 $ C^x_n $ 。</p><p>现在，让我们把二项公式应用到特定的例子里吧。想象你每天通勤的路线上需要经过一座吊桥。这桥有 10% 的时间是打开的，但打开时机是随机的。那么你在一周中碰到 0 ， 1， 2 ，直到 5 天的概率是多少呢？</p><img src="/images/bd_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>实验有 5 次试验，遇到打开的桥的概率是 0.1 。因此，这里的二项分布的概率如下：</p><img src="/images/bd_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>如果你把 6 个概率和 x 相乘并加总，你会发现这个值等于 1 。本应如此。</p><a id="more"></a><p>让我们借助同一个例子，移到一个相关的问题，如果 5 天内最多一天遭遇打开的吊桥，这个概率怎么算呢？可以很好地利用上面的概率表，我们要找的是没遇到打开的吊桥和有一天遇到打开的吊桥的情况，两个概率之和是 0.92 。</p><img src="/images/bd_8.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>为了回答最后一个问题，我们需要利用累积的二项概率分布，即给定所有结果，低于或者等于某个成功数量的概率。方程如下：</p><p>$$ F (x) = P (X \leq x) = \sum_{k = 0}^{x} \frac {n!}{k!(n - k)!} p^k (1 - p)^{n - k} $$</p><p>这个公式跟二项概率质量函数几乎相同，除了在前面做了求和，并且把所有的 x 替换成了符号 k 。</p><p>现在让我们来看一下二项分布的形状。它是离散的，意味着它只会给出 0 , 1 , 2, 之类的概率。</p><img src="/images/bd_9.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>有趣的是，二项分布的形状会根据参数的变化而变化。基于参考，分布可以是 <strong>右偏态 (right-skewed)</strong> 的，或者 <strong>左偏态的 (left-skewed)</strong> 的，或者是对称的。</p><img src="/images/bd_10.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这三个分布显示 20 个成功概率不同的试验。第一个成功概率是 0.1 ，第二个成功概率是 0.5 ，第三个是 0.9 。</p><img src="/images/bd_11.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>一般来说，成功概率更低的二项分布是右偏态的，而成功概率高的是左偏态的。通过水平对齐，你会发现中间分布的顶点低于两边的，因此它更分散。这是二项分布很有趣的一个属性。实际上，二项分布的标准差取决于 p ，均值也是。二项分布的均值就等于 p ，它的标准差等于 n 乘以 p 乘以 (1 - p)，然后求平方根。当 p 等于 0 或者 1 时，标准差等于 0 。当 p 等于 0.5 时，它的标准差达到最大。</p><img src="/images/bd_12.jpg" width="68%" height="68%" style="margin: 10 auto;"><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>二项分布是一个离散概率分布，用于只有两个独立互斥结果的随机变量 —— 成功或者失败。它给出了对于随机变量的 n 个结果，其中 x 个成功的概率。也叫做试验成功的概率。</li><li>二项分布假定所有试验的概率 p 都是固定的，它的均值等于 n 乘以 p ，标准差等于 n 乘以 p 乘以 (1 - p)，然后求平方根。</li><li>二项分布根据 p 的变化可以向右或者向左偏斜，或者对称。当 p 接近 0 时是右偏态，当 p 接近 1 时是左偏态。二项分布公式如下：<br>$$ P (x) = \frac {n!}{x!(n - x)!} p^x (1 - p)^{n-x}, x = 0,1,2,…,n $$<br>速记为 $$ X \sim B (N, P) $$</li><li>二项分布的累积概率分布公式如下：<br>$$ F (x) = P (X \leq x) = \sum_{k = 0}^{x} \frac {n!}{k!(n - k)!} p^k (1 - p)^{n - k} $$</li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于离散随机变量，有一个最重要的概率分布，它是 &lt;strong&gt;二项分布 (binomial distribution)&lt;/strong&gt; 。二项分布处于二元数据。因为二元数据的情况非常多，所以二项分布使用频繁。&lt;/p&gt;
&lt;p&gt;让我们从例子开始，你会在这些例子中看到两种结果。比如，参加会议是否迟到，投票赞成或者反对，噪音等级超过 80 分贝或者没有。当你收集这类现象的试验时，成功或者失败的数字服从二项分布。例如，你可以考虑每 25 个与会人员，有多少个迟到，或者投反对票的人有几个。&lt;/p&gt;
&lt;img src=&quot;/images/bd_1.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;下面是你可以确定一个随机变量服从二项分布的条件：首先，每一个试验成功的概率相同；其次，试验在统计上是独立的 —— 即一个试验的结果不会影响其他试验。&lt;/p&gt;
&lt;img src=&quot;/images/bd_2.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;实际上，你发现二项分布的三个要素。首先，试验现象有两种结果，并且成功概率是常量。这种实验被称为 &lt;strong&gt;伯努利试验验 (Bernoulli trial)&lt;/strong&gt; 。其次，你观察试验结果 n 次。第三，你对成功的结果计数，记为 x 。这三个元素被结合成一个公式，它给出了在 n 次试验中取得特定数量成功结果的概率。公式如下：&lt;/p&gt;
&lt;p&gt;$$ P (x) = \frac {n!}{x!(n - x)!} p^x (1 - p)^{n-x}, x = 0,1,2,…,n $$&lt;/p&gt;
&lt;p&gt;你可以直接把 n，x 和 p 填进公式从而获得答案。&lt;/p&gt;
&lt;img src=&quot;/images/bd_3.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;如公式所示，随机变量 x 只能取 0 到 n 的值。这很合理，因为你只能有有限次成功，0 ，1 ， 2 ，直到 n 。因此这个公式是一个概率质量函数，它直接给出了匹配每个可能的 x 的概率值，你不必像考虑概率密度函数那样考虑区间。&lt;/p&gt;
&lt;img src=&quot;/images/bd_4.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;感叹号不常见，它表示 &lt;strong&gt;阶乘法 (factorial)&lt;/strong&gt; ，即把所有从 1 到指定的整数全部相乘的结果。例如， 4 阶乘等于 1 乘以 2 乘以 3 乘以 4 。 公式前部的这个阶乘的除法实际上是给出了无视顺序，从 n 个元素中选出 x 个元素的方法，它也被称为 &lt;strong&gt;二项系数 ( binomial coefficient)&lt;/strong&gt; ，有的时候也速记为 $ C^x_n $ 。&lt;/p&gt;
&lt;p&gt;现在，让我们把二项公式应用到特定的例子里吧。想象你每天通勤的路线上需要经过一座吊桥。这桥有 10% 的时间是打开的，但打开时机是随机的。那么你在一周中碰到 0 ， 1， 2 ，直到 5 天的概率是多少呢？&lt;/p&gt;
&lt;img src=&quot;/images/bd_5.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;实验有 5 次试验，遇到打开的桥的概率是 0.1 。因此，这里的二项分布的概率如下：&lt;/p&gt;
&lt;img src=&quot;/images/bd_6.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;如果你把 6 个概率和 x 相乘并加总，你会发现这个值等于 1 。本应如此。&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之十三 | 正态分布</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-the-normal-distribution/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-the-normal-distribution/</id>
    <published>2020-01-16T02:36:29.000Z</published>
    <updated>2020-01-18T09:49:48.728Z</updated>
    
    <content type="html"><![CDATA[<h1 id="正态分布-normal-distribution-的函数形式"><a href="#正态分布-normal-distribution-的函数形式" class="headerlink" title="正态分布 (normal distribution) 的函数形式"></a>正态分布 (normal distribution) 的函数形式</h1><p>在所有的概率分布中，有一个特别出众，我们经常遇到。它就是 <strong>正态分布 (normal distribution)</strong> 。</p><p>在本节中，我们会学习它的重要属性。正态分布又被称为 <strong>高斯分布 (gaussian distribution)</strong> 。它是对称的，钟形，以均值 μ 和 标准差 σ 为特征。分布的最高点是均值的位置，宽度则由标准差指定。均值 μ 和 标准差 σ 被称为正态分布的 <strong>参数 (parameters)</strong> 。</p><img src="/images/nd_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>正态分布的累积概率分布是一个 <strong>S 函数曲线 (sigmoideal shape)</strong> ，均值处于概率为 0.5 的地方，标准差决定了曲线的陡峭程度。</p><img src="/images/nd_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>随机变量 X 有一个均值 μ ，标准差 σ 的正态分布，可以速记为：</p><p>$$ X \sim N (\mu, \sigma^2) $$ </p><p>而下面这个等式描述了完整的概率密度：</p><p>$$ f (x)=\frac {1}{\sqrt {2\pi}\sigma} e^{-0.5\left (\frac {x-\mu}{\sigma}\right)^2} $$ </p><p>这个方程之所以重要，并非因为它第一眼看起来很复杂 —— 包含了三个重要的数学常量，$ \pi $，$ e $ 和 2 的平方根，还因为它连接了统计国王和物理世界。这个方程可以描述粒子扩散的过程。如果你释放一个扩散物，比如放一块糖到茶里，茶里的糖将按照这个方程的规律扩散。不仅流体是这样，大气中的颗粒物，道路交通，社会中的信息，都遵循这个分布的规律。</p><a id="more"></a><p>同时，我们会频繁地遇见高斯分布，是因为根据 <strong>中心极限定理 (central limit theorem)</strong> ，各种独立的随机过程组合之后，就会产出这种分布。不过，让我们不要跑题。我将通过拆解的方式来解释这个方程。</p><p>整个方程给出了随机变量 X 的概率密度，整个函数是一个 <strong>指数函数 (exponential function)</strong> ，前面是一个常数，然后指数部分包括小 x ，即随机变量可能取得的值。观察指数部分，从 x 中减去平均数，然后除以 σ ，这实际上是在计算 z 分数。所以随机变量的值在参与到方程后续的计算之前先做了标准化。</p><img src="/images/nd_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>现在让我们聚焦到 e 之前的常数。在没有常数之前，曲线之下的面积是跟着 σ 变化的。但是通常乘以这个常量，这块面积变成了精确的 1 。这个常量的值实际上正是曲线顶部的高度，也就是 x 等于 μ 的地方。</p><img src="/images/nd_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>正态概率分布有一个违反直觉的属性 —— 当逼近极大或者极小的 x 时，概率接近于 0 ，但实际永远不可能是 0 。</p><img src="/images/nd_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这导致一个事实：随机变量的值可以往负无穷大和正无穷大无限伸展。即使这些值是极小的概率，但仍然满足所有概率之和等于 1 的规律。</p><img src="/images/nd_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>最终确定之前，让我们回到 μ 和 σ 这两个参数，它们决定正态分布曲线的位置和形状。下图是一个西欧男性在一周中每天上班路上花的通勤时间。平均的通勤时间是 3 分钟，标准差 6 分钟，而同一个国家的西欧女性，通勤均值更小，但是标准差更大。你会发现，曲线越宽，顶点越低。</p><img src="/images/nd_8.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>曲线还有一个属性 —— 当 x 轴的单位变化时， y 轴的单位也会发生变化。比如，你用小时而不是分钟来表示时间时，概率密度就从每分钟变成了每小时。</p><img src="/images/nd_9.jpg" width="68%" height="68%" style="margin: 10 auto;"><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>正态分布或者说高斯概率密度函数，是对称的钟形曲线，其对应的累积概率函数是 S 形曲线。位置和形状完全由两个参数描述，均值和标准差。均值决定曲线的中点，而标准差决定曲线的宽度。曲线越宽，则顶点必定越低。因为曲线下的面积始终等于 1 。</li><li>对于一个均值为 63 ，标准差为 12 的变量 x ，速记如下：<br>$$ X \sim N (63, 12^2) $$<br>正态分布方程如下：<br>$$ f (x)=\frac {1}{\sqrt {2\pi} 12} e^{-0.5\left (\frac {x-63}{12}\right)^2} $$</li><li>这种方程不但描述了概率分布，也描述物理世界中许多过程的结果，其中的许多扩散形式十分重要。</li></ul><hr><h1 id="正态分布的概率计算"><a href="#正态分布的概率计算" class="headerlink" title="正态分布的概率计算"></a>正态分布的概率计算</h1><p>如果我们知道某个随机变量的概率分布，那我们就可以计算变量落在某个区间的概率。</p><p>这一节中吗，我将通过一个具体的例子来解释这类计算是如何进行的。</p><p>概率密度函数，经常被缩写为 pdf ，给出了随机变量每单位的概率。下面是一个出租车司机日常等待时间的 pdf 。在 y 轴你看到是每小时的概率， x 轴是以小时为单位的概率。现在，假设你是一个出租车司机，你想要知道一天中等待时间超过 7 小时的概率。你需要计算面积区域。基于图像，你可以粗造地估计面积。</p><img src="/images/pdf_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>借助累积概率函数，也可以做到这一点，并且更精确。通过 x 轴 7 个小时的位置读取对应的 y 轴上的概率，再从 1 中减去这个概率。因为你关心的是长于 7 个小时而不是短于 7 个小时的概率。</p><img src="/images/pdf_1_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>现在，让我们应用此前了解到的正态分布的等式。它是一个中点位于 μ ，宽度由 σ 定义的 pdf 形状。对应的累积概率函数在下方。</p><img src="/images/pdf_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>有趣的是，尽管曲线会随着 μ 和 σ 变化，距离中点一个 σ 的区间，对应的概率始终不变。</p><img src="/images/pdf_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>让我演示一下，假设一条曲线的均值是 20 ，标准差是 9 ，另一条曲线的均值是 30 ，标准差是 6 。对两条 pdf ，从均值减去一个标准差到均值加上一个标准差的区域，曲线之下的面积都是 0.68 。无论 μ 和 σ 分布是多少，所有的正态分布都满足这个情况。</p><img src="/images/pdf_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>现在把区间扩展到围绕均值正负两个 σ ，区间对应的概率大致是 0.95 。</p><img src="/images/pdf_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>再扩展到正负三个 σ ，区间对应的概率大致是 0.997 。</p><img src="/images/pdf_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>统计计算中经常用到一个、两个、三个 σ 区间的概率值。</p><img src="/images/pdf_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>让我通过一个练习来演示一下一个、两个、三个 σ 的规则。假设你在一周中花在通勤上的时间服从正态分布，均值 40 分钟，标准差 10 分钟。 那 95% 的状态下，你的通勤时间会落在哪个范围。是的，它在均值减两个标准差到均值加两个标准差的区间。在这里，就是从 40 分钟减去 20 分钟到 40 分钟加上 20 分钟的区间。</p><img src="/images/pdf_8.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>让我假定你想要知道通勤超过 50 分钟的概率，在已知平均时间是 40 分钟，标准差是 10 分钟以及一个 σ 规则的前提下，你会如何计算呢？为了解答这个问题，你需要一点创造力 —— 你知道正态分布是对称的。因此有一半的概率落在均值的一侧，继而可以知道从均值减去一个标准差到均值这个区间，概率是 0.68 的一半，即 0.34 ，于是，小于 50 分钟的概率就是 0.5 加上 0.34 ，即 0.84 。然后取补集，即 1 - 0.84 ，等于 0.16 。</p><img src="/images/pdf_9.jpg" width="68%" height="68%" style="margin: 10 auto;"><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><ul><li>基于概率密度函数，你可以计算随机变量落在给定区间的概率，通过估算曲线在那个范围下的面积。借助累积概率函数，通过读取 y 轴对应的概率值也能做到这一点，并且更精确。</li><li>对于一个服从正态分布的变量来说，围绕均值的区间，有一个固定的概率对应关系。</li></ul><hr><h1 id="标准正态分布"><a href="#标准正态分布" class="headerlink" title="标准正态分布"></a>标准正态分布</h1><p>在计算器和计算机还不得的时代，正态分布有一种非常重要的特殊形态 ——  <strong>标准正态分布 (standard normal distribution)</strong> ，也被称为 <strong>z 分布 (z-distribution)</strong> 。不过即便在今天，标准正态分布仍被高频使用，用于快速计算和呈现分析结果。</p><p>这一节中，我将解释标准正态分布的属性和应用。</p><p>尽管距离均值 1 个， 2 个， 3 个标准差的概率值很有分析的价值，仍有许多不在这些位置上的情况需要计算概率。</p><img src="/images/snd_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>举个例子，比如距离均值 1.3 个标准差的概率。实际上，为了表示距离均值任意数量个标准差的意思，我们选择字母 z 。 这些 z 值的概率分布是一个均值为 0 ，标准差为 1 的正态分布，也被叫做为标准正态分布，或者 z 分布。</p><img src="/images/snd_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>z 分布的累积分布常常用表格来呈现。下面这份表格给出一个正态分布的随机变量的累积概率，位置通过均值加上 z 个标准差偏移来确定。</p><img src="/images/snd_2_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这份表格同时展示了 z 值和关联的累积概率。</p><img src="/images/snd_2_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>如你所见，从值 -2.00 开始，以很小的步长增长，要累积到接近 1 的地方，列表会很长。因此，我们通常采用另外一种更简洁的形式来呈现 —— 用 z 值第 1 位小数作为一条边，第 2 位小数作为另一条边。</p><img src="/images/snd_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>基于这样一个表格，你能够基于给定的 z 值，快速地找到与之关联的累积概率。比如，为了找到 z 值等于 1.41 的累积概率，你先选择 1.4 ， 然后选择 0.01 ，最后找到对应的概率是 0.92 。</p><img src="/images/snd_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>但如果我们是从一个普通的正态分布开始，该如何拿到 z 呢？首先，你需要这样考虑：对于一个随机变量 X 的某个值 x ，要把它看成均值加上 z 个标准差偏移。这个时候，你想知道 z ，可以反过来借由 x ，均值和标准差。把等式做一个调整，你发现 z 值等于随机变量的观察值与均值之差，再除以标准差。</p><img src="/images/snd_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>让我们把上面的变换应用到实例中。想象一群绿脚大雁每年秋天都要从波罗的海地区迁徙到欧洲的大西洋海岸。迁徙持续时间服从均值为 4 天，标准差为 1.3 天的正态分布。现在，要计算这群大雁在 6 天内到达迁徙目的地的概率。</p><img src="/images/snd_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>首先，你需要对 6 天做 <strong>z 变换 (z transform)</strong> ，通过 x 减去均值，然后除以标准差，得到 1.54 。下一步，在表格中查询 z 值，找到匹配的概率概率。</p><img src="/images/snd_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>如你所见，这个 z 值匹配的是概率 0.9382 ，这就是针对前面问题的答案 —— 这群大雁在 6 天内完成迁徙的概率。</p><img src="/images/snd_8.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>如果是迁徙时间介于两天到五天之间，你又会怎么计算呢？下面是问题的正式描述：</p><img src="/images/snd_9.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>首先，计算小于 5 天的概率，然后计算小于 2 天的概率。然后将两个概率相减，就得到要求的范围： 2 天到 5 天。小于 5 的概率是 0.78 ，小于 2 的概率是 0.06 。从 2 到 5 的概率等于两者之差，即 0.72 。</p><img src="/images/snd_10.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>现在，让我们休息一下。我们已经看到，可以把任意正态分布转换成标准正态分布或者说 z 分布的变量，通过减去均值再除以标准差来实现。然后，借助表格化的分布数据，我们能找到小于某个值、大于某个值或者介于两个值之间的概率。因此，如果你已经有一个概率了，你想反过来找出对应的随机变量的值，这时候要怎么做呢？</p><p>别担心，做法几乎相同，只需要反过来。还是用前面大雁迁徙的粒子。假设它们平均需要 4 天，标准差 1.3 天来完成迁徙。那么，你可以找出迁徙持续时间的十分位。</p><img src="/images/snd_12.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>持续时间的十分位意思是迁徙时间少于所有情况中的 10% 的情况，或者多于所有情况中的 90% 的情况。首先，你通过查表看到最接近概率 0.1 的 x 的值，它是 - 1.28 ，然后借助公式 $ x = μ + zσ $ ，你得到 x 的值时 2.34 天。</p><img src="/images/snd_13.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>最后，我想强调的是， z 变换适用于任意类型的数值数据，它会得到一个均值为 0 ，标准差为 1 的数据集，并且不包含对数据潜在分布的假定。因此，标准化数据是一个好方法，尤其是你想在不同的案例间做比较的时候。不过， z 变换并不能自动地创造出服从 z 分布并且能允许你计算概率的数据。你要得到 z 分布的数据，前提是数据本来就服从正态分布，并且你能算出均值和标准差。</p><img src="/images/snd_14.jpg" width="68%" height="68%" style="margin: 10 auto;"><h2 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h2><ul><li>z 变换可以应用于标准化数据，取得一个均值为 0 ，标准差为 1 的数据集，无论原始数据集是何种分布。当已知数据富服从正态分布时，可以基于 z 分数，借助对应 z 分数的累积概率表格来做概率计算。</li><li>对于给定的 x ，你通过从中减去均值，再除以标准差的方式来获得 z 。 z 表格提供了匹配 z 值的累积概率。这些概率指的是随机变量小于或者等于 x 的概率。相反地，对于给定的概率，你可以在表格中找出 z 值，然后计算出匹配这个值的 x 。</li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;正态分布-normal-distribution-的函数形式&quot;&gt;&lt;a href=&quot;#正态分布-normal-distribution-的函数形式&quot; class=&quot;headerlink&quot; title=&quot;正态分布 (normal distribution) 的函数形式&quot;&gt;&lt;/a&gt;正态分布 (normal distribution) 的函数形式&lt;/h1&gt;&lt;p&gt;在所有的概率分布中，有一个特别出众，我们经常遇到。它就是 &lt;strong&gt;正态分布 (normal distribution)&lt;/strong&gt; 。&lt;/p&gt;
&lt;p&gt;在本节中，我们会学习它的重要属性。正态分布又被称为 &lt;strong&gt;高斯分布 (gaussian distribution)&lt;/strong&gt; 。它是对称的，钟形，以均值 μ 和 标准差 σ 为特征。分布的最高点是均值的位置，宽度则由标准差指定。均值 μ 和 标准差 σ 被称为正态分布的 &lt;strong&gt;参数 (parameters)&lt;/strong&gt; 。&lt;/p&gt;
&lt;img src=&quot;/images/nd_1.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;正态分布的累积概率分布是一个 &lt;strong&gt;S 函数曲线 (sigmoideal shape)&lt;/strong&gt; ，均值处于概率为 0.5 的地方，标准差决定了曲线的陡峭程度。&lt;/p&gt;
&lt;img src=&quot;/images/nd_2.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;随机变量 X 有一个均值 μ ，标准差 σ 的正态分布，可以速记为：&lt;/p&gt;
&lt;p&gt;$$ X \sim N (\mu, \sigma^2) $$ &lt;/p&gt;
&lt;p&gt;而下面这个等式描述了完整的概率密度：&lt;/p&gt;
&lt;p&gt;$$ f (x)=\frac {1}{\sqrt {2\pi}\sigma} e^{-0.5\left (\frac {x-\mu}{\sigma}\right)^2} $$ &lt;/p&gt;
&lt;p&gt;这个方程之所以重要，并非因为它第一眼看起来很复杂 —— 包含了三个重要的数学常量，$ \pi $，$ e $ 和 2 的平方根，还因为它连接了统计国王和物理世界。这个方程可以描述粒子扩散的过程。如果你释放一个扩散物，比如放一块糖到茶里，茶里的糖将按照这个方程的规律扩散。不仅流体是这样，大气中的颗粒物，道路交通，社会中的信息，都遵循这个分布的规律。&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之十二 | 随机变量的平均数和方差</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-mean-and-variance-of-random-variable/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-mean-and-variance-of-random-variable/</id>
    <published>2020-01-15T01:07:13.000Z</published>
    <updated>2020-01-16T01:45:45.311Z</updated>
    
    <content type="html"><![CDATA[<h1 id="随机变量的平均数"><a href="#随机变量的平均数" class="headerlink" title="随机变量的平均数"></a>随机变量的平均数</h1><p>在了解了随机变量的概率分布之后，我们可以开始对这种变量进行计算了。</p><p>首先，你需要知道，<strong>总结性统计 (summary statistics)</strong> ，跟观测数据相似，都能用来捕捉分布的本质。这一节中，我们要来研究概率分布的平均数，以及我们在调整随机变量或者组合随机变量之后，平均数如何变化。</p><p>以下将一个随机变量的平均数以 $ μ $ 注记，它表示对许多观测值预期的平均结果，因此也被称为随机变量的 <strong>期望值 (expected value)</strong> ，以 $ E $ 注记。</p><p>一个离散随机变量的平均数是所有可能的值乘以概率权重之后的均值，因此它等于每个可能的值乘以概率，然后加总。对于连续随机变量，同样的规则也适用。为了应对连续性，加总的计算被替换成积分 (integral) ，概率也不像离散那样被定义为 i ，而是 x 的函数。 </p><p>举个例子，假设你正在一个熟悉的街区日常漫步，路上会经过三个交通灯。每等一个交通灯会使整个漫步多花 2 分钟。对于这三组交通灯的等待，你记录了等 0 个 到等 3 个的频率，下面是概率表：</p><img src="/images/mvorv_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>你预期的等待时间计算方法如下，最后会得到 2 分 12 秒。有趣的是， 2 分 12 秒这个值实际永远不会发生。你要么不用等，要么就是等 2， 4， 6 分钟中的某个时间。</p><p>现在，让我们来审视一下随机变量的平均数。如果我们给随机变量 x 乘上一个系数再加上一个值， 变成 $ a + bx $ ，那么平均值会变成 $ μ_{a+bx} $ 。</p><a id="more"></a><p>现在回到我们的例子。由于你找到一条捷径，旅程节省了一分钟。但同时，交通灯变得更忙了 —— 等待时间增加到 2 分 30 秒，即增加了 25% 。你抄近路省出的时间对应方程里的 a ，等待时间增长系数 1.25 对应 b 。新的概率分布通过下面这张表格呈现。</p><img src="/images/mvorv_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>新的等待时间平均值变为 1 分 45 秒。</p><p>现在让我们来看看两个随机变量相加或者相减的时候回发生什么。结果是：两个相加或者相减的随机变量的平均值也是它们各自平均值的简单求和或者求差。这个结论甚至不要求两个变量相互独立。</p><img src="/images/mvorv_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>举个例子，假设你想要计算一个礼拜的等待时间的平均值，那你只需要把每天的平均值加起来就可以了：</p><img src="/images/mvorv_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>平均值，或者一个离散随机变量的期望值，是变量所有可能的值乘以它们的概率，然后求和。如果随机变量通过乘法或者加上常数改变，那么平均值会发生相同的变化。</li><li>几个随机变量的平均值加总在一起是它们平均值的总和，即便这几个变量在统计上不一定是独立的。</li></ul><hr><h1 id="随机变量的方差"><a href="#随机变量的方差" class="headerlink" title="随机变量的方差"></a>随机变量的方差</h1><p>在平均数之后，你需要了解的第二个总结性统计指标是随机变量的方差，即离散程度的度量。</p><p>这一节中，我们要来研究概率分布的方差，以及我们在调整随机变量或者组合随机变量之后，方差如何变化。</p><p>一个随机变量 X 的方差 var (X) 是以它与平均值的差值的平方的期望来定义的：</p><p>$$ var (X) = E [(X - μ)^2] $$</p><p>如果你想基于概率分布算出方差，它其实是变量可能的值与平均值之差的平方，然后加总或者积分。<br>连续随机变量的方差：<br>$$ \int {(X - μ)^2f (x) dx} $$<br>离散随机变量的方差：<br>$$ \sum {(x_i - μ)^2P (x_i)} $$</p><p>连续随机变量的方差比较复杂一些，用到了积分。离散随机变量看起来就简单一些。</p><p>举个例子，这个离散分布给出了一年中你可能遭遇交通事故的风险。平均风险是 0.04 ，即每 25 年一次。</p><img src="/images/mvorv_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>首先，你计算出事故次数和平均值之差，然后平方，乘上对应的概率，最后加总。事故风险的方差看起来接近 0.06 ，标准差 0.24 左右。</p><p>现在，让我们来看看，如果通过给随机变量加一个 a 或者乘以 b ，方差会发生什么变化。</p><img src="/images/mvorv_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>当你将两个 a 放定义方差的等式中变换时，你会发现常量 a 消失了，而因子 b 被平方了。因此，通过加或者减一个值到随机变量，它的方差不变。但通过乘以一个数 b ，它的方差会变成原始方差乘以 b 的平方。标准差，即方差的平方根，则跟随因子 b 一起变化。</p><p>举个例子，你是否经历过晴天人们更愿意跟你打招呼，阴天更不爱搭理你的情景呢？下面图中上方是一个阴天时你走在街上每分钟遇到的点头或者微笑次数的分布。平均每分钟 1.4 次，方差 0.84 。而图中下方是晴天时的数据，你发现大家变得更友好了，具体来说，友好的倍数是 2 。</p><img src="/images/mvorv_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>理论告诉我们，平均值应该变成 2 倍于 1.4 ，即 2.8 ，而方差应该变为 4 倍，即 3.36 。让我们检视一下新的分布的方差。</p><img src="/images/mvorv_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这个表格展示了具体的步骤。从微笑或者点头次数减去平均值得到差值，平方，乘以概率，最后加总，确实是 3.36 。</p><p>现在让我们来看看如果把两个随机变量相加或者相减会怎么样。对于随机变量 X 和 Y ，两者之和的方差是两者各自方差的和再加上 2 乘以 X 和 Y 之间的 <strong>协方差 (covariance)</strong> 。而两者之差的方差是两者各自方差的和再减去 2 乘以 X 和 Y 之间的协方差。</p><img src="/images/mvorv_8.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>下面这两个更完整的等式则适用于 X 和 Y 各自有因子 a 的情况。</p><img src="/images/mvorv_9_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这些等式适用于任意两个相加或者相减的随机变量，而且显而易见，它们要求你知道两个变量之间的协方差。然而，协方差信息通常是不可得的，因此我们这里不考虑通用的情况，而是先考虑一个更严格的案例，即变量之间不相关的情况。这样会使问题简单很多，因为两个不相关变量之间的协方差是 0 ，后面 1 项就从等式中消失了。</p><img src="/images/mvorv_9_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>因此，在不相关变量之间，相加或者相减都无关紧要了，方差总是两个方差之和。你还可以把等式泛化到任意多个随机变量之和。</p><img src="/images/mvorv_10.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>还有一个值得注意的点是，随机变量相加的标准差总是小于独立的随机变量标准差相加之和。这看起来很合理，因为随机变量结合之后，有一些变异性会被抵消。</p><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><ul><li>随机变量的方差，是这个变量所有可能的值减去它的平均值，乘以概率，然后平方，最后加总或者积分。<br>$$ 连续随机变量：\int {(X - μ)^2f (x) dx} $$<br>$$ 离散随机变量：\sum {(x_i - μ)^2P (x_i)} $$ </li><li>给随机变量增加常量不会改变方差，但因子会导致方差变为因子平方倍。</li><li>几个不相关随机变量相加或者相减的方差等于这些变量各自方差之和。标准差是方差的平方根，因此为了得到调整后的标准差，你需要先得到调整后的方差。</li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;随机变量的平均数&quot;&gt;&lt;a href=&quot;#随机变量的平均数&quot; class=&quot;headerlink&quot; title=&quot;随机变量的平均数&quot;&gt;&lt;/a&gt;随机变量的平均数&lt;/h1&gt;&lt;p&gt;在了解了随机变量的概率分布之后，我们可以开始对这种变量进行计算了。&lt;/p&gt;
&lt;p&gt;首先，你需要知道，&lt;strong&gt;总结性统计 (summary statistics)&lt;/strong&gt; ，跟观测数据相似，都能用来捕捉分布的本质。这一节中，我们要来研究概率分布的平均数，以及我们在调整随机变量或者组合随机变量之后，平均数如何变化。&lt;/p&gt;
&lt;p&gt;以下将一个随机变量的平均数以 $ μ $ 注记，它表示对许多观测值预期的平均结果，因此也被称为随机变量的 &lt;strong&gt;期望值 (expected value)&lt;/strong&gt; ，以 $ E $ 注记。&lt;/p&gt;
&lt;p&gt;一个离散随机变量的平均数是所有可能的值乘以概率权重之后的均值，因此它等于每个可能的值乘以概率，然后加总。对于连续随机变量，同样的规则也适用。为了应对连续性，加总的计算被替换成积分 (integral) ，概率也不像离散那样被定义为 i ，而是 x 的函数。 &lt;/p&gt;
&lt;p&gt;举个例子，假设你正在一个熟悉的街区日常漫步，路上会经过三个交通灯。每等一个交通灯会使整个漫步多花 2 分钟。对于这三组交通灯的等待，你记录了等 0 个 到等 3 个的频率，下面是概率表：&lt;/p&gt;
&lt;img src=&quot;/images/mvorv_1.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;你预期的等待时间计算方法如下，最后会得到 2 分 12 秒。有趣的是， 2 分 12 秒这个值实际永远不会发生。你要么不用等，要么就是等 2， 4， 6 分钟中的某个时间。&lt;/p&gt;
&lt;p&gt;现在，让我们来审视一下随机变量的平均数。如果我们给随机变量 x 乘上一个系数再加上一个值， 变成 $ a + bx $ ，那么平均值会变成 $ μ_{a+bx} $ 。&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之十四 | 二项分布</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-probability-distributions/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-probability-distributions/</id>
    <published>2020-01-14T06:48:10.000Z</published>
    <updated>2020-01-21T12:25:13.138Z</updated>
    
    <content type="html"><![CDATA[<h1 id="随机变量和概率分布"><a href="#随机变量和概率分布" class="headerlink" title="随机变量和概率分布"></a>随机变量和概率分布</h1><p>随机变量的随机性其实并不像它的名字传递的那样多。这一节教程中，我将通过随机变量的可能结果和它们对应的概率来描述 <strong>概率分布 (probability distribution)</strong> 。换句话说，随机分布使随机性具体化，并且提供了一条在计算中使用随机变量的道路。当我们观察个体或者对象的时候，我们可以关注每个个体的若干个属性，这些属性就叫做 <strong>变量</strong> 。</p><p>现在，想象你收集了一份数据，并且决定重复实验。你能够找到相同的试验个体来测量变量，或者能找到相近的个体。不管采用哪一种，你会发现你的变量的值每次都不一样。这就是所谓的变量。举个例子，你测量一个人的身高几次，每次的结果可能会有几毫米到 1 厘米的偏离，这取决于你测量的时间在一天中的时刻，你的测量设备的精度，等等。</p><p>通常我们预料变量的值具有随机的变异性。如果这种概率的随机性是中肯的，则这个变量被称为 <strong>随机变量 (random variable)</strong> 。随机变量可以有一组可能的值，每个值都和概率关联。因此，如果随机变量的样本足够大，不同值的相对频率就接近概率。为了让表达更清晰，让我们用斜体的大写字母来表示随机变量，小写字母来表示它取到的值。</p><p>即 <strong><em>X</em></strong> 为随机变量，$ x_1, x_2, x_3, … $ 为随机变量的值。</p><p>随机变量有两种，一种是 <strong>离散的 (discrete)</strong> ，一种是 <strong>连续的 (continuous)</strong> 。离散随机变量可以有一组可数数量的不同值，比如 0 / 1 / 2 / 3 。实际上，如果一个随机变量只能取得有限数量的不同值，那它必定是离散的。离散随机变量的例子很多，比如一个家庭里小孩的数量。连续随机变量则可以取得无限数量的可能值。它通常是测量。为了演示无限性，假设一个身高值测出来是 3.1 米，如果换更精确的测量仪器，也许能测到 3.14 米。更精确的仪器，也许还能测到 3.145 米。换言之，通过更精确的测量，或者放大操作，无限数量的结果是可能的。年龄，温度，速度，这些都可以是连续随机变量的例子。</p><p>随机变量的值可以很方便地通过随机分布来呈现。随机分布的呈现形式可以是表格，图或者数学方程，并且是通过随机变量的每个取值关联的概率列表来定义的。</p><img src="/images/pd_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>根据定义，每个随机变量都有一个概率分布，离散随机变量的概率分布叫 <strong>概率质量函数</strong> ，而连续随机变量的概率分布叫概率密度函数。至于为什么有这种区别，稍后解释。</p><a id="more"></a><p>对于离散随机变量来说，通过列出每种可能的结果，容易看出概率。假设变量 <strong><em>X</em></strong>  接收 1, 2, 3, 或者 4 。那么下面这张表就列出了每种结果的概率。分布还可以用概率直方图来描述，这跟频率表或者频率直方图的用法如出一撤。</p><img src="/images/pd_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>对于连续随机变量，可以采用图表。下图中的概率分布并没有在 y 轴上给出概率，而给出了 <strong>概率密度 (probability density)</strong> 。为了获得概率，你需要考虑曲线某个区间下方的区域而非曲线的高度。概率就是由这块区域的面积给出的。</p><img src="/images/pd_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>y 轴之所以要采用密度是因为你的随机变量单位可能会改变。比如，你表示的长度由米改成厘米，这个时候密度相应改变，而区域的面积不应该变化。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>随机变量是一个由随机现象产生多种可能结果的变量。当结果有限可数时，它是离散的；当结果数量无限时，它是连续的。</li><li>概率分布为随机变量可取得的每个值指定概率。离散随机变量的概率分布叫概率质量函数，而连续随机变量的概率分布叫概率密度函数，它的概率值时通过概率曲线指定区间下的面积来获得的。</li><li>概率密度函数可以以表格、图表或者方程的形式呈现。</li></ul><hr><h1 id="累积概率分布"><a href="#累积概率分布" class="headerlink" title="累积概率分布"></a>累积概率分布</h1><p>你已经了解了基本的概率规则，也了解了概率分布，是时候向你介绍累积概率分布了。<br>首先看看下面这个简单的离散随机分布。你能找出 X 的值是 2 或者 3 的概率吗？</p><img src="/images/cpd_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>答案可以通过把 x 是 2 或者 x 是 3 的概率相加得到。因此这个值是 0.7 。</p><img src="/images/cpd_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>表格上列出的概率，或者说概率质量函数 x 轴上的概率，全部都是互斥。因此任意概率的并集实际上就是这些概率值之和。相似的，根据补集的规则， X 大于等于 1 的概率等于 1 减去 x 是 1 的概率，也就是 0.9 。 </p><img src="/images/cpd_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>现在让我们往下接着走。基于概率分布，我们很容易计算出小于或者等于某个值的概率。举个例子， x<br>小于或者等于 1 的概率是 0.1 。 x 小于或者等于 2 的概率是 0.1 加上 0.3 ，也就是 0.4 。</p><img src="/images/cpd_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这种概率被称为 <strong>累积概率 (cumulative probability)</strong> 。 全部累积概率的列表被称为 <strong>累积概率分布 (cumulative probability distribution)</strong> ，或者 <strong>累积分布函数 (cumulative distribution function)</strong> 。这个累积概率分布的概率直方图可以像下面这样：</p><img src="/images/cpd_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>对于概率密度函数也是如此。例如，下面这个概率密度函数，对应旁边的累积分布。</p><img src="/images/cpd_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>有趣的部分是， y 变量从概率密度变成了概率。</p><img src="/images/cpd_61.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>如你所见，累积概率函数从 0 开始，持续增加到最大值 1 。所有结果的概率之和等于 1 。累积分布，特别是它的图形化形式，十分便于回答两个问题。</p><img src="/images/cpd.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>你可以在 x 轴上选择随机变量的某个值，然后在 y 轴上找到观察值的哪一部分小于或等于该值。或者相反，你可以在 y 轴上选择一个分数，然后在 x 轴上找到相应的阈值。对于这个阈值，有一个简短的叫法是 <strong>分位 (quantile)</strong> 。举个例子，对于累积概率 0.1 以下的阈值，就称为 0.1 分位。因此累积概率分布实际上展示了随机变量的分位。举个例子，你会发现，对于累积概率 0.5 ，你找到其实就是随机变量的中位数，对于累积概率 0.25 ，你找到是随机变量的四分位。</p><img src="/images/cpd_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>值得注意的是，对称概率分布下，中位数和平均数一致。</p><img src="/images/cpd_8.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>因此，对于对称分布，找到平均值的地方，累积概率也是 0.5 。 </p><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><ul><li>随机变量的累积概率是获取一个小于或者等于某个阈值的概率。另一方面，累积概率体现了随机变量的分位。举个例子，累积概率 0.5 代表随机变量中位数被找到的地方。</li><li>跟概率分布一样，累积概率分布也可以以表格、图表或者方程的形式呈现，通过从小到大计算随机变量的概率实现。</li><li>随机变量从 0 持续增加到 1 。在对称概率分布下，中位数和平均数一致。</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;随机变量和概率分布&quot;&gt;&lt;a href=&quot;#随机变量和概率分布&quot; class=&quot;headerlink&quot; title=&quot;随机变量和概率分布&quot;&gt;&lt;/a&gt;随机变量和概率分布&lt;/h1&gt;&lt;p&gt;随机变量的随机性其实并不像它的名字传递的那样多。这一节教程中，我将通过随机变量的可能结果和它们对应的概率来描述 &lt;strong&gt;概率分布 (probability distribution)&lt;/strong&gt; 。换句话说，随机分布使随机性具体化，并且提供了一条在计算中使用随机变量的道路。当我们观察个体或者对象的时候，我们可以关注每个个体的若干个属性，这些属性就叫做 &lt;strong&gt;变量&lt;/strong&gt; 。&lt;/p&gt;
&lt;p&gt;现在，想象你收集了一份数据，并且决定重复实验。你能够找到相同的试验个体来测量变量，或者能找到相近的个体。不管采用哪一种，你会发现你的变量的值每次都不一样。这就是所谓的变量。举个例子，你测量一个人的身高几次，每次的结果可能会有几毫米到 1 厘米的偏离，这取决于你测量的时间在一天中的时刻，你的测量设备的精度，等等。&lt;/p&gt;
&lt;p&gt;通常我们预料变量的值具有随机的变异性。如果这种概率的随机性是中肯的，则这个变量被称为 &lt;strong&gt;随机变量 (random variable)&lt;/strong&gt; 。随机变量可以有一组可能的值，每个值都和概率关联。因此，如果随机变量的样本足够大，不同值的相对频率就接近概率。为了让表达更清晰，让我们用斜体的大写字母来表示随机变量，小写字母来表示它取到的值。&lt;/p&gt;
&lt;p&gt;即 &lt;strong&gt;&lt;em&gt;X&lt;/em&gt;&lt;/strong&gt; 为随机变量，$ x_1, x_2, x_3, … $ 为随机变量的值。&lt;/p&gt;
&lt;p&gt;随机变量有两种，一种是 &lt;strong&gt;离散的 (discrete)&lt;/strong&gt; ，一种是 &lt;strong&gt;连续的 (continuous)&lt;/strong&gt; 。离散随机变量可以有一组可数数量的不同值，比如 0 / 1 / 2 / 3 。实际上，如果一个随机变量只能取得有限数量的不同值，那它必定是离散的。离散随机变量的例子很多，比如一个家庭里小孩的数量。连续随机变量则可以取得无限数量的可能值。它通常是测量。为了演示无限性，假设一个身高值测出来是 3.1 米，如果换更精确的测量仪器，也许能测到 3.14 米。更精确的仪器，也许还能测到 3.145 米。换言之，通过更精确的测量，或者放大操作，无限数量的结果是可能的。年龄，温度，速度，这些都可以是连续随机变量的例子。&lt;/p&gt;
&lt;p&gt;随机变量的值可以很方便地通过随机分布来呈现。随机分布的呈现形式可以是表格，图或者数学方程，并且是通过随机变量的每个取值关联的概率列表来定义的。&lt;/p&gt;
&lt;img src=&quot;/images/pd_1.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;根据定义，每个随机变量都有一个概率分布，离散随机变量的概率分布叫 &lt;strong&gt;概率质量函数&lt;/strong&gt; ，而连续随机变量的概率分布叫概率密度函数。至于为什么有这种区别，稍后解释。&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之十 | 条件概率和独立性</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-conditional-probability-and-independence/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-conditional-probability-and-independence/</id>
    <published>2020-01-11T05:18:35.000Z</published>
    <updated>2020-01-11T12:41:24.218Z</updated>
    
    <content type="html"><![CDATA[<h1 id="联合概率和边际概率"><a href="#联合概率和边际概率" class="headerlink" title="联合概率和边际概率"></a>联合概率和边际概率</h1><blockquote><p>对有趣现象的计数，在日常生活中常常转换成比例，最终变为概率。利用概率估算的力量，可以更好地理解这些现象之间的关系或做出预测。 <strong>联合概率 (joint probability)</strong> 和 <strong>边际概率 (marginal probability)</strong> 是两个在这种情况下会用到的重要概率类型。在这一节教程中，我将解释联合概率和边际概率的含义，并展示它们的属性。</p></blockquote><p>想象你在沙滩上观察你的海滩同伴。你会注意到三种不同类型的活动 —— 它们是互斥的。有的休息，他们都坐在或躺在沙滩上。有的玩，这些人到处乱跑，建造沙堡或站在水中。最后，有的在游泳。此外，你还可以按性别区分。所以你观察到的每个人都是一个案例.</p><p><img src="/images/conditional_p_1.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>在数据集中，性别和活动是变量。你最终得到以下结果的列联表。总共计了 113 人，其中有 79 人在休息，有 20 人在玩，并且他们中只有 14 人在游泳。女性和男性的数量，分别是 62 和 51 。</p><p><img src="/images/conditional_p_2.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>这些数字实际上是每行和每列变量位于此表边缘的总和，因此被称为边际值。请注意，这与口语上 “边缘的”，即并不重要的，并不是一回事。在表中边际值代表对于单个变量的说明，没有关于任何其他变量。例如说休息的人数不考虑性别。</p><p><img src="/images/conditional_p_3.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>现在，我们打开这个频率表通过将每个单元格数字除以总数 113 得到比例的表格。</p><p><img src="/images/conditional_p_4.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>在此表中，中心块包含六个位置，它们加起来等于一。同时，每列中的比例加总到底部的边缘行中的值，每行中的比例加总到右边的边缘列中的值。并且边缘行的值加起来等于边缘列的值加起来。</p><a id="more"></a><p>你的计数可以看作随机样本，测量在海滩的人的活动和性别分布，于是你会想到把比例看作概率。在中间区域，是活动与性别的交集。例如，给定的人是男性，正在游泳。这些值称为 <strong>联合概率 (conditional probability)</strong> 。 <strong>联合概率只是各种事件的交集概率的简称</strong> 。</p><p>我们的每个联合概率关联的事件都与表中任何其他联合概率关联的事件互斥，因为每个人在海滩上只被放置在六个互斥事件之一。同时，联合概率形成一系列完全穷尽的事件，因为案例中不会出现其他的可能活动和性别的组合。因此，联合概率总和为一。</p><p><img src="/images/conditional_p_5.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>在边缘的地方，你可能期望有 <strong>边际概率</strong> 。是的，这些概率仅考虑一个变量。例如，给定的人是男性，无论其活动如何，或者给定在玩，不论性别。边际概率来自联合概率的并集。例如休息的概率，玩耍的概率和游泳概率。因此，这里适用加法规则，即概率相加。</p><p><img src="/images/conditional_p_6.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>因此，如果你的原始计数不可得，但有联合概率，你始终可以计算出边际概率 —— 通过求和。相反，如果只给你边际概率，你将无法在每种情况下反推出联合概率。</p><p><img src="/images/conditional_p_7.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>当你在对源自一个随机样本或者试验中的现象计数时，可以把它们转换成概率。</li><li>如果观察多个随机变量，可以计算出这些变量的联合概率和边际概率。</li><li>联合概率是变量间某些结果交集的概率，而边际概率是每个变量所有结果概率的总和。</li><li>典型的例子里，如果变量有两个，列联表示组织数据的绝佳形式。联合概率放在中间，边际概率放在边缘。所有的联合概率加起来等于 1 ，它们在两个方向上分布加总得到一个边际概率。</li><li>你总是可以通过加总，基于联合概率算出边际概率；但仅有边际概率，不借助额外的假定是无法算出联合概率的。</li></ul><hr><h1 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h1><p>术语 <strong>条件 (condition)</strong> 意味着取决于别的东西。和日常语言中的概率上下文或多或少具有相同的含义。</p><p>其正式定义是：给定另外一件事已发生，这件事件发生的可能性。数学符号如下：</p><script type="math/tex; mode=display">P (A | B)</script><p>即给定 B 发生或以 B 为条件，事件 A 发生。垂直线是 “给定” 的速记，或者说 “有条件” 的速记。条件概率的计算公式是：</p><script type="math/tex; mode=display">P (A | B) = \frac {P (A \cap B)}{P (B)}</script><p>即事件 A 和事件 B 都发生的概率除以事件 B 发生的概率。也可以用下面的文氏图来说明：</p><p><img src="/images/conditional_p_8.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>该图强调 A 和 B 的交集概率只能小于或等于 B 的概率。</p><p>让我们应用方程到一个熟悉的例子。你考虑了沙滩上的人们进行的各种活动，也可以按性别区分人们。将结果转换一张有概率的表。现在，有了这些变量，活动和性别，如何举出一个条件概率的例子？具体来说，是你知道一个结果发生的概率，然后要计算这个结果发生后，其他结果再发生的概率。让我们举一个具体的例子。你将估算一个概率 —— 该人是男性，且则该人正在休息。</p><p>为了算得这个概率，应用前面说到的公式，联合概率除以是男性的概率。因此， 0.3 除以 0.45 。</p><p><img src="/images/conditional_p_9.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>现在我有一个问题要问你。你能计算给定活动的性别概率吗？方法一样：</p><p><img src="/images/conditional_p_10.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>因此，根据联合概率和边际概率，您可以计算出条件概率。虽然条件概率方程很简单，但它还有更多可以挖掘。再看一下方程式，如果两边都乘以事件 B 的边际概率，你就得到了一个计算联合概率的公式。</p><p>这其中隐含的意思是，如果交给你一项任务：找到事件 A 和事件 B 的联合概率，如果你不知道 A 和 B 之间是否独立，你需要同时拿到 B 的概率和给定 B 发生 A 的条件概率，或者拿到 A 的概率和给定 A 发生 B 的条件概率。</p><h2 id="小结："><a href="#小结：" class="headerlink" title="小结："></a>小结：</h2><ul><li>条件概率是指给定另一件事已发生时某件事的概率。</li><li>表明上看不是很特别，但条件概率是很多概率估算的核心。</li><li>数学上，给定 B 的 A 的条件概率等于 A 和 B 的联合概率除以概率 B 。</li><li>条件概率的定义，也适用于不论是否独立的事件的联合概率。给定 B 的 A 的条件概率可以看成是 B 发生后，样本空间缩小到 B 时 A 发生的概率。</li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;联合概率和边际概率&quot;&gt;&lt;a href=&quot;#联合概率和边际概率&quot; class=&quot;headerlink&quot; title=&quot;联合概率和边际概率&quot;&gt;&lt;/a&gt;联合概率和边际概率&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;对有趣现象的计数，在日常生活中常常转换成比例，最终变为概率。利用概率估算的力量，可以更好地理解这些现象之间的关系或做出预测。 &lt;strong&gt;联合概率 (joint probability)&lt;/strong&gt; 和 &lt;strong&gt;边际概率 (marginal probability)&lt;/strong&gt; 是两个在这种情况下会用到的重要概率类型。在这一节教程中，我将解释联合概率和边际概率的含义，并展示它们的属性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;想象你在沙滩上观察你的海滩同伴。你会注意到三种不同类型的活动 —— 它们是互斥的。有的休息，他们都坐在或躺在沙滩上。有的玩，这些人到处乱跑，建造沙堡或站在水中。最后，有的在游泳。此外，你还可以按性别区分。所以你观察到的每个人都是一个案例.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/conditional_p_1.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在数据集中，性别和活动是变量。你最终得到以下结果的列联表。总共计了 113 人，其中有 79 人在休息，有 20 人在玩，并且他们中只有 14 人在游泳。女性和男性的数量，分别是 62 和 51 。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/conditional_p_2.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;&lt;/p&gt;
&lt;p&gt;这些数字实际上是每行和每列变量位于此表边缘的总和，因此被称为边际值。请注意，这与口语上 “边缘的”，即并不重要的，并不是一回事。在表中边际值代表对于单个变量的说明，没有关于任何其他变量。例如说休息的人数不考虑性别。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/conditional_p_3.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;&lt;/p&gt;
&lt;p&gt;现在，我们打开这个频率表通过将每个单元格数字除以总数 113 得到比例的表格。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/conditional_p_4.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在此表中，中心块包含六个位置，它们加起来等于一。同时，每列中的比例加总到底部的边缘行中的值，每行中的比例加总到右边的边缘列中的值。并且边缘行的值加起来等于边缘列的值加起来。&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之九 | 概率和集合</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-probability-and-sets/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-probability-and-sets/</id>
    <published>2020-01-10T08:50:24.000Z</published>
    <updated>2020-01-11T04:25:25.201Z</updated>
    
    <content type="html"><![CDATA[<h1 id="集合基础-——-理论概念"><a href="#集合基础-——-理论概念" class="headerlink" title="集合基础 —— 理论概念"></a>集合基础 —— 理论概念</h1><p>在这篇教程中，我将介绍一些重要概念，它们是关于 <strong>集合 (set)</strong> ，即项的数据集。这对于理解概念以及得出概率的计算规则十分有用。同时，集合的特殊性还在于它不仅可用于概率演算，还用在逻辑学中。</p><p>让我们开始吧。如之前的教程中提到的，样本空间是随机现象所有结果的数据集。举个例子，抛一枚硬币两次，有四种可能的结果。事件是样本空间的子集。例如，最后一次抛硬币你得到正面朝上。</p><p><img src="/images/set_1.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>我们看到，一个样本空间可以两个或更多结果完全不同的事件。比如，抛硬币两次，0 次正面朝上，1 次正面朝上， 2 次正面朝上。它们被称为 <strong>互斥 (disjoint)</strong> 的事件。另外一个术语叫 <strong>互不相容 (mutually exclusive)</strong> 。</p><p>有一对特殊的互斥事件，某个事件和它的对立面 (即这个事件不发生的事件)。这种上下文中，对立的事件被称为 <strong>补集 (complement)</strong> 。比如，这里可以是没有正面朝上和其他三种情况互为补集。</p><p><img src="/images/set_2.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>你也可以有多个事件共同填满完整的样本空间。这些事件被称为 <strong>完全穷尽 (collectively exhaustive)</strong> 事件。如果它们彼此不重叠，就是 <strong>相互独立，完全穷尽 (disjoint collectively exhaustive)</strong> 。互斥事件相关联的概率之和小于或者等于 1 ，完全穷尽事件的概率之和等于 1 。</p><p><img src="/images/set_3.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>直觉上很容易理解这些概念，它们可以通过 <strong>文氏图 (Venn diagrams)</strong> 来表达。文氏图通过简单的几何形状来呈现集合或者集合的部分。</p><a id="more"></a><p>这些矩形描绘同一个样本空间，在空间中，有一个事件 A ，剩下的部分都是事件 A 的补集。同一个样本空间里，还有另外一个事件 B ，和 A 不重叠。因此它们两者是互斥的。</p><p>如果我们把这个文氏图应用于两次抛硬币的实验，你能把四个不同的结果放进图中并且描述事件吗？</p><p><img src="/images/set_4.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>可以是这样的，只有一次正面朝上是事件 A ，有两次正面朝上是事件 B 。 A 的补集会包含两次反面朝上和两次正面朝上。</p><p><img src="/images/set_5.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>还用文氏图，两次抛硬币的实验也可以是这样的：</p><p><img src="/images/set_6.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>两个事件， A 和 B ，相互之间有重叠。 A 是事件 “第二次结果是正面朝上”， B 是事件 “只有一次正面朝上”。结果 “反面，正面” 会同时落在两个事件之内。“反面，反面” 也属于样本空间的一部分，但不落在 A 和 B 任何一个事件内。两个事件重叠的部分被称为 <strong>交集 (intersection)</strong> 。</p><p>事件 A 和 事件 B 的交集可以速记为:</p><script type="math/tex; mode=display">A \cap B</script><hr><p>现在，让我们来找出两个事件交集的概率。如果两个事件是互斥的，事件很简单。交集的概率为 0 。如果两个事件并不互斥，即它们重叠，事情就稍微有点复杂。</p><p>假定我们正在处理的是独立事件。也就是说，例子中抛出第二个正面的事件的概率不受只抛出一个正面的事件的影响。对于独立事件 A 和 B ，它们的交集的概率是两者各自概率的乘积。</p><p>这里，事件 A 有两种情况，所以概率是 2 / 4 。事件 B 的情况相同，概率也是 2 / 4 。因此，最后的交集的概率等于两者概率乘积，也就是 1 / 4 。</p><p><img src="/images/set_7.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>样本空间中不共享任何结果的事件被称为 <strong>互斥事件</strong> 或者 <strong>互不相容</strong> 。</li><li>多个事件一起填满整个样本空间，则把它们称为 <strong>完全穷尽</strong> 事件。</li><li>如果样本空间里只有两个互斥事件构成完全穷尽，那么它们互为 <strong>补集</strong> 。</li><li>互斥事件的概率之和小于或者等于 1 。完全穷尽事件的概率之和等于 1 。</li><li>事件 A 和 B 的 <strong>交集</strong> 同时是两个事件的一个子集，这个子集包含了 A 的一部分，并且这部分也是 B 的一部分。独立事件 A 和 B 的交集是通过事件 A 的概率和事件 B 的概率乘积来计算的。对于互斥事件，按照定义，交集属性等于 0 。</li></ul><hr><h1 id="并集"><a href="#并集" class="headerlink" title="并集"></a>并集</h1><p>这一节中，我将介绍 <strong>并集 (Union)</strong> 的概念和并集的概率。并集在现实生活中会导致一个比其各个部分集合的总和具有更多新属性的实体吗？很遗憾，在概率理论中，这种魔力是不存在的。并集只是<br>需要特别注意 —— 不要将事情加倍计算。</p><p>还是贝壳的例子，你在海滩上随机捡三个贝壳。周围只有两种贝壳， Q 和 R 。两种类型的贝壳数量相等并且你可以认为有无数。在这种情况下，样本空间包括八个结果。整个实验的树形图如下。</p><p><img src="/images/union_1.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>获得任何组合的概率的八分之一。让我们设定，总共捡起一个 R 贝壳作为事件 A ，总共捡起两个 R 贝壳作为事件 B 。如果我们对事件 A 发生或事件 B 发生，或者 A 和 B 同时发生感兴趣。</p><p><img src="/images/union_2.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>以这种方式组合事件被称为 “并集”，速记为:</p><script type="math/tex; mode=display">A \cup B</script><p>要计算关于事件 A 和 B 的并集的概率，你必须求出两个事件的总和，然后减去 A 和 B 的交集。减去交集的原因是它被计数了两次。拿到一个 R 贝壳的概率 —— 事件 A ，是八分之三。<br>拿到两个 R 贝壳的概率同样也是八分之三，它们的总和是八分之六，即四分之三。</p><p>实际上，事件 A 和 B 不分享任何结果，即他们不相交的，则他们的交集概率为零。因此，并集的概率是四分之三。</p><p><img src="/images/union_3.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>现在，考虑两个不同的事件。 事件 C ，你选择的第一个贝壳将会是 R 贝壳。事件 D ，最后一个贝壳 是 R 贝壳。显然，这两个事件不是互斥的，因为它们有重叠。事件 C 和 D 的交集包括<br>第一个贝壳是 R 贝壳，同时第三个贝壳也是 R 贝壳的情况。</p><p><img src="/images/union_4.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>通过将 C 的概率加到 D 的概率，再减去 C 和 D 的交集来找到 C 和 D 的并集，是四分之三。</p><p><img src="/images/union_5.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>现在挑战升级 —— 事件 A ， B ， C 和 D 的并集是？如果你把方程式机械地应用过来，事情会有些乏味，因为会有不少加法和减法的计算。</p><script type="math/tex; mode=display">P (A \cup B \cup C \cup D) = P (A) + P (B) + P (C) + P (D) \\ - (P (A \cap B) + P (B \cap C) + P (C \cap D) + P (A \cap C) + P (A \cap D) + P (B \cap D) + P (A \cap B \cap C \cap D))</script><p><img src="/images/union_6.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>不过，由于总的样本空间中并没有特别多的基本事件，这里有一个更简单的方法。你可以列出八个<br>基本事件，然后检查它们出现在四个组合事件中的哪一个。最后，你会发现只有一个基本事件不发生在组合事件中。从四个组合事件来看，有七个基本事件的结果是四个组合事件中的某一个的部分。因此，并集的概率是这七个基本事件之和，即八分之七。</p><p><img src="/images/union_7.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><ul><li>多个事件的并集是这样一个事件：它包含原始事件的所有结果，并且没有重复。</li><li>几个事件的并集概率是各个事件的概率之和减去事件之间的交集的概率。</li><li>对于两个事件，等式为 $ P (A \cup B) = P (A) + P (B) - P (A \cap B) $ 。如果事件 A 和 B 互斥，则交集的概率为零。并集方程简化为 $ P (A \cup B) = P (A) + P (B) $。</li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;集合基础-——-理论概念&quot;&gt;&lt;a href=&quot;#集合基础-——-理论概念&quot; class=&quot;headerlink&quot; title=&quot;集合基础 —— 理论概念&quot;&gt;&lt;/a&gt;集合基础 —— 理论概念&lt;/h1&gt;&lt;p&gt;在这篇教程中，我将介绍一些重要概念，它们是关于 &lt;strong&gt;集合 (set)&lt;/strong&gt; ，即项的数据集。这对于理解概念以及得出概率的计算规则十分有用。同时，集合的特殊性还在于它不仅可用于概率演算，还用在逻辑学中。&lt;/p&gt;
&lt;p&gt;让我们开始吧。如之前的教程中提到的，样本空间是随机现象所有结果的数据集。举个例子，抛一枚硬币两次，有四种可能的结果。事件是样本空间的子集。例如，最后一次抛硬币你得到正面朝上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/set_1.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们看到，一个样本空间可以两个或更多结果完全不同的事件。比如，抛硬币两次，0 次正面朝上，1 次正面朝上， 2 次正面朝上。它们被称为 &lt;strong&gt;互斥 (disjoint)&lt;/strong&gt; 的事件。另外一个术语叫 &lt;strong&gt;互不相容 (mutually exclusive)&lt;/strong&gt; 。&lt;/p&gt;
&lt;p&gt;有一对特殊的互斥事件，某个事件和它的对立面 (即这个事件不发生的事件)。这种上下文中，对立的事件被称为 &lt;strong&gt;补集 (complement)&lt;/strong&gt; 。比如，这里可以是没有正面朝上和其他三种情况互为补集。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/set_2.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;&lt;/p&gt;
&lt;p&gt;你也可以有多个事件共同填满完整的样本空间。这些事件被称为 &lt;strong&gt;完全穷尽 (collectively exhaustive)&lt;/strong&gt; 事件。如果它们彼此不重叠，就是 &lt;strong&gt;相互独立，完全穷尽 (disjoint collectively exhaustive)&lt;/strong&gt; 。互斥事件相关联的概率之和小于或者等于 1 ，完全穷尽事件的概率之和等于 1 。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/set_3.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;&lt;/p&gt;
&lt;p&gt;直觉上很容易理解这些概念，它们可以通过 &lt;strong&gt;文氏图 (Venn diagrams)&lt;/strong&gt; 来表达。文氏图通过简单的几何形状来呈现集合或者集合的部分。&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之八 | 样本空间、事件和树形图</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-sample-space-events-tree-diagrams/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-sample-space-events-tree-diagrams/</id>
    <published>2020-01-09T09:16:28.000Z</published>
    <updated>2020-01-10T03:58:24.746Z</updated>
    
    <content type="html"><![CDATA[<h1 id="样本空间-sample-space"><a href="#样本空间-sample-space" class="headerlink" title="样本空间 (sample space)"></a>样本空间 (sample space)</h1><p><em>海滩是一个多变的环境 —— 尤其当天气很好的时候，有许多人，需要可以做的事情和可以看的风景。这一节教程里，海滩是我们的背景。我将向你解释几个可以帮助我们找到概率的概念，以及一个可视化的辅助工具 —— <strong>树形图 (tree diagram)</strong> 。</em></p><p>这是一个温暖的下午，你可以来点下午茶。幸运的是，你所在的海滩上，有一个卖下午茶的摊位。不过，茶点几乎快卖完了，只剩下一种类型的冰淇淋和两瓶软饮料。</p><img src="/images/sample_space.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>有点不走运的是，有三个人排在你前面。不过还有个好消息是，摊主只卖给每个顾客一件东西。由于你实在很渴望喝到眼前这冰爽的饮料，你不禁开始寻思，“我喝到饮料的机会有多大呢？” </p><img src="/images/sample_space_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>注意，你并不清楚其他顾客会做出的决定，所以他们的购买对你来说全部都是随机事件。第一个顾客可能买饮料或者冰淇淋，在这件事发生之后，第二个顾客拥有同样的选项，然后轮到第三个顾客。如果前面的两位顾客都买了饮料，那她就只剩冰淇淋可以选，否则的话，她也还有两个选项。</p><p>通过下面这幅树形图，你排序了所有可能的随机试验结果。看起来有 7 种可能的组合。这里所有随机现象的里列表我们称为 <strong>样本空间 (sample space)</strong> 。</p><a id="more"></a><img src="/images/sample_space_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>如果一个随机试验有离散的结果，比如我们的这个案例，一种描绘样本空间的便捷方式是通过树形图列出所有的可能性。就像上图中我们已经做的那样。在一个树形图中，有一些中间结果的划分，跟最终分支如出一撤。任何结果，包括结果的组合，被称为 <strong>事件 （event）</strong>，因此， <strong>一个事件其实就是一个样本空间的子集</strong> 。在这个特定的案例中，你关心的事件，不走运的那些 —— 没有饮料喝了，反之，还能买到饮料。 </p><p>任何一个随机事件都有与之关联的概率，并且小的事件可以组合成大的事件。量化这些事件的概率，可以通过实验。实验可以包含在一段足够长的时间内，观察冰淇淋和饮料的销售情况。但这里时间不够，当第一个顾客正在思考要买什么的时候，你就必须做出自己的决定了。于是你诉诸另外一种策略 —— 对样本空间里的结果做出有说服力的假设。</p><p>你假定每一种事件发生的机会相等 —— 每个顾客选冰淇淋和饮料的概率都是 0.5 。在这种方式中，你可以依赖通用的概率规则。概率处于 0 到 1 之间，所有可能的结果，例如，所有选项在树形图里以节点表示，它们最终的总和也等于 1 。借助它们，你可以很快得到答案。这个答案可能帮助你做出决定：是应该保持乐观，在队伍中等着轮到自己，还是应该开始考虑寻求别的方式购买饮料。</p><p>不过，要记得，经过所有事件都已经展开，你并不知道你对于概率的评估是否正确。虽然你收集了排在你前面的三个顾客的试验信息，但对于整个购买冰淇淋和饮料这种事情来说。你的信息极其有限，并没有办法推导出十分精确的概率估算。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>样本空间是所有随机现象的结果的集合，而事件是样本空间的子集，它对应某一个随机变量的结果或者一组可能的结果。</li><li>每个事件都有概率。为了找到这些概率，你可以用到树形图。在树形图中，你可以创建样本空间，并对各种事件显式地做出假设。为了量化树形图里每个事件的概率，你可以进行实验。</li><li>某些时候，你可以对样本空间里的结果做出有说服力的假设，然后基于推理估计出它们的概率。</li><li>在任何案例中，通用的概率规则都适用于树形图。任意事件的概率都处于 0 和 1 之间，而最终所有可能的结果的概率总和等于 1 。</li></ul><hr><h1 id="用树形图量化概率"><a href="#用树形图量化概率" class="headerlink" title="用树形图量化概率"></a>用树形图量化概率</h1><p>当你在思考随机现象并且把注意力放在事件之间的关系以及它们在树形图中的概率时，你已经开始计算概率和评估某件事发生的可能性。</p><p>下面我会解释实践中树形图中的概率是如何量化的。还是上面那个例子。下面这张图显示，你假定每个顾客都有 0.5 的概率选择冰淇林或者饮料。通用概率规则适用于树形图里的每一个节点。具体来说，如果你观察图中的第一个顾客，有两个分支，每个分支 0.5 的概率。到第二个顾客，有两对分支，每对占 0.5 的概率，一对里的两个分支又各占 0.5 的概率。</p><p>如果这个时候轮到你了，你需要沿着一条路径，从第一个顾客的某个购买结果算到第二个顾客的某个购买结果。在树形图中，通过计算这条路径上所有概率的乘积来找出最终组合的事件的概率。</p><p>两个顾客之后，你还有多大的机会买到饮料呢？至少得剩一瓶饮料吧，满足这个情况的事件分支有三条，像图示中那样，总的概率是 0.75 。</p><img src="/images/tree_diagram.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>还有没有更快的算法呢？—— 利用所有概率的总和等于 1 这个规则。所以 1 减去 两瓶饮料都卖出去的概率会给到我们相同的答案。</p><p>现在我们加大难度，考虑第三个顾客了。这里有一点特殊。她在四个分支中有三个拥有两个选项，但在两瓶饮料都卖完的这个分支上，只有一个选项 —— 买冰淇淋。同时在这里，规则也需要被满足，即所有概率的总和等于 1 ，所以这个单分支的概率就等于 1 。</p><img src="/images/tree_diagram_1.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>现在我们回到你买到饮料的机会上。我们需要算出四条分支的概率总和，即轮到你之前最多一瓶饮料被卖掉的概率总和。每条分支的概率等于 0.5 的三次方，即 0.125 ，加起来是 0.5。</p><img src="/images/tree_diagram_1_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><hr><p>上面我们演示了利用树形图找出概率的变量，但也有必要指出一些需要注意的事情。首先是树形图可以很从容地处理小问题，对于理解有很多结果的随机现象，它并不是很适合 —— 它会变得很庞大，无助于保持概览。</p><img src="/images/tree_diagram_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>其次，为了实际应用树形图来量化概率，需要每个节点的概率规格。这在有的时候是很容易的，比如你假定每个选项机会均等，并且独立于前面的选择。另一方面，它也可能很困难。</p><p>举个例子，假如第二个顾客的购买选择会受到第一个顾客的影响怎么办呢？</p><img src="/images/tree_diagram_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><ul><li>在树形图中，你可以创建样本空间，并对各种事件显式做出假定，包括每个事件的概率，它们在序列之中的相互独立性。</li><li>你可以在树形图中计算组合事件的概率。为了计算沿着一系列分支的从起点到结果的概率，所有的概率需要相乘。而为了找到某个包含很多种结果的事件的概率，所有这些结果的概率则需要相加。</li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;样本空间-sample-space&quot;&gt;&lt;a href=&quot;#样本空间-sample-space&quot; class=&quot;headerlink&quot; title=&quot;样本空间 (sample space)&quot;&gt;&lt;/a&gt;样本空间 (sample space)&lt;/h1&gt;&lt;p&gt;&lt;em&gt;海滩是一个多变的环境 —— 尤其当天气很好的时候，有许多人，需要可以做的事情和可以看的风景。这一节教程里，海滩是我们的背景。我将向你解释几个可以帮助我们找到概率的概念，以及一个可视化的辅助工具 —— &lt;strong&gt;树形图 (tree diagram)&lt;/strong&gt; 。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;这是一个温暖的下午，你可以来点下午茶。幸运的是，你所在的海滩上，有一个卖下午茶的摊位。不过，茶点几乎快卖完了，只剩下一种类型的冰淇淋和两瓶软饮料。&lt;/p&gt;
&lt;img src=&quot;/images/sample_space.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;有点不走运的是，有三个人排在你前面。不过还有个好消息是，摊主只卖给每个顾客一件东西。由于你实在很渴望喝到眼前这冰爽的饮料，你不禁开始寻思，“我喝到饮料的机会有多大呢？” &lt;/p&gt;
&lt;img src=&quot;/images/sample_space_2.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;注意，你并不清楚其他顾客会做出的决定，所以他们的购买对你来说全部都是随机事件。第一个顾客可能买饮料或者冰淇淋，在这件事发生之后，第二个顾客拥有同样的选项，然后轮到第三个顾客。如果前面的两位顾客都买了饮料，那她就只剩冰淇淋可以选，否则的话，她也还有两个选项。&lt;/p&gt;
&lt;p&gt;通过下面这幅树形图，你排序了所有可能的随机试验结果。看起来有 7 种可能的组合。这里所有随机现象的里列表我们称为 &lt;strong&gt;样本空间 (sample space)&lt;/strong&gt; 。&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之七 | 概率和随机性</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-probability-and-randomness/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-probability-and-randomness/</id>
    <published>2020-01-09T05:48:50.000Z</published>
    <updated>2020-01-09T09:21:26.189Z</updated>
    
    <content type="html"><![CDATA[<h1 id="随机性-（randomness）"><a href="#随机性-（randomness）" class="headerlink" title="随机性 （randomness）"></a>随机性 （randomness）</h1><p>识别和理解随机性，和推断它是一样重要的技能。它们不仅在统计分析中有用，对于每天发生在我们身边的日常事物，同样有意义。这篇教程中，我将向你解释为什么人们如此不擅长应对随机性。</p><p>想象你在海滩上看着海浪翻滚，然后你注意到一枚美丽的贝壳，它的个头和形状明显地异于周围其它贝壳。于是你想想看附近还有有没有这种贝壳。这是一项无法预见的行动计划 —— 贝壳可能是随机分布在这个巨大的海滩上的。因此，你找到另外一枚同类贝壳的时间是不确定的，甚至你都可能找不到一枚相似的。</p><p>你开始思考这件事，然后你意识到随机性几乎在日常生活中无处不在。所以，无怪乎我们有丰富的词汇来描述它，比如不确定性、机会、风险、可能性。还有，变异性和不确定性的程度能够非常精细地描述随机性。</p><p>看看下面这组词汇：罕有、少见、有时、普通、频繁、经常。有意思的是，某件事是否随机，不仅是现象自身的特性，也很大程度上取决于我们对它的认识。假如你之前就来过这片海滩，你可能已经发现过这种贝壳，从而改变这一次的搜索策略，以便增加找到更多这种贝壳的机会。你搜索的尺度也有关系，如果在很小的区域做一个短暂的搜索，可能不是很有把握找到新贝壳，但是搜索时间延长，搜索区域扩大，找到机会就会增大。</p><p>尽管有这么多的词汇，以及我们在日常经验中熟记随机性的能力，我们其实一点都不擅长量化地评估随机性。一方面，我们在真实的随机数据中寻找各种 “模式”。你一定听过一个词叫 “宿命”。另一方面，我们自身又无法制造随机熟记。有一个失败尝试的案例 —— 下图中左边的通过拼接得到的贝壳随机分布的地图，实际上是分布太规则的。而右边那幅是现实的随机分布模式，看起来有更多聚集在一起的 “簇”。</p><p><img src="/images/randomness.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><a id="more"></a><p>另外一个被我们用来解释随机性的例子叫 “赌徒谬误” —— 它的错误之处在于用一系列前面发生的随机现象预测未来的随机现象。人们没有意识到的是，如果你连续掷出了四次 6 ，感觉上不太可能再第五次掷出 6 。然后，这个投掷的结果为 6 的概率之前是 六分之一，之前是，现在还是。</p><p><img src="/images/randomness_2.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>我们之所以应对随机性孱弱，原因在于我们的大脑倾向于用记忆模式的方式衡量随机性。考量到这一点，为了量化随机性、理性思考随机性并且产出现实可行的随机模式，学习正确的方法十分重要。它们帮助我们避免错误，更准确和更有效地对我们周遭的世界做出预测。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>随机性并非一个现象的内在属性，它同时取决于我们对它的知识，观察方法以及我们关注它的尺度。尽管有大量表达随机性的词汇，人类天生不擅长量化评估它。我们困于宿命论，困于对某些纯随机模式的过度解读，这些操作同时也不利于构建随机性。</p><hr><h1 id="概率-probability"><a href="#概率-probability" class="headerlink" title="概率 (probability)"></a>概率 (probability)</h1><blockquote><p>坚持不懈，终有所成。</p></blockquote><p>尽管已经有很多关于这个概念的箴言和引证，我想再加一句 —— “毅力战胜一切”。这一节中，我将一步步引导你学会用概率来量化随机性。</p><p>人类的大脑也许并不是很适合回答随机性。但幸运的是，有一个基础的机制，它的运转极大地简化了我们的生活 —— 随机性会发生变化，从事物可变、案例稀少且无法预测，到事物恒定、案例庞大且可以预测。对于这个基础，我们甚至有一个数学上的证据，它就是 <strong>大数定律</strong> 。它有赖于独立性，也就是说，某个随机现象的结果，不受之前结果的影响。</p><p>让我举个例子，说明大数定律在现实生活中是长什么样子。还是想象你在海滩，决定搜寻贝壳。很快，你发现了海滩一共有四种类型的贝壳，随机分布，数量相等，就像下图这样：</p><p><img src="/images/possibility.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>现在，你需要数出一个 Q 贝壳的分数，可以通过选取操作来完成。比如，随机选 20 个贝壳，然后计算这 20 个样本里 Q 贝壳的数量。结果如下：</p><p><img src="/images/possibility_2.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>如你所见，20 个贝壳只有 2 个 Q 贝壳。 <strong>相对频率 (relative frequency)</strong> 是十分之一。基于你的推理，这个分数本来应该是在四分之一左右。 但是，你也知道，小样本的不规则性，是随机性的本质。所以呢？“保持冷静，继续前进。”</p><p><img src="/images/possibility_3.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>不着急下结论，继续选取更多的贝壳，观察比例如何变化，一直演化到四分之一 —— 这种比例被称为 <strong>“累积比例 (cumulative proportion)”</strong> 。</p><p><img src="/images/possibility_4.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>每一次你随机选取新的贝壳时，都被看作是一次可能带来 Q、R、S、T 四种贝壳之一的机会实现。用概率的术语来说，操作的结果，也就是你拿到的贝壳的类型，被称为 <strong>事件 (event)</strong> 。选取贝壳的这个行为被称为 <strong>独立试验 (independent trial)</strong> 。整个做这么多试验的事情被称为 <strong>实验 (experiment)</strong> 。在计算相对频率的时候，因为你用贝壳总数除每一种类型的贝壳，有两个属性将始终满足：每一个类型的概率将大于等于 0 或者小于等于 1 ；所有随机现象的结果的概率总和将等于 1 。</p><p><img src="/images/possibility_5.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>不过，现在让我们回到现实。生活并不是海滩，当然也不会有随机分布的贝壳。在日常生活中，纯粹的独立试验并不常见。通常，在随机事件之间存在 <strong>相互依赖 (interdependent)</strong> 。尽管如此，通过简化的假定，概率经常还是可以被很好地量化。此外，你需要拿到充足数量的样本，以便大数定律能发挥作用，确保你要估计的概率接近它的实际值。</p><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><ul><li>概率是一种量化随机性的方法，它可以用相对频率的均值来表示。根据这个定义，概率会始终大于等于 0 ，并 IE 小于等于 1 。所有可能事件的概率总和等于 1 。</li><li>正式的定义用到了实验、事件和独立试验的概念。某个事件的概率是通过它出现在整个实验中的相对频率来计算的。实验包含一系列独立试验。举个例子，掷骰子是一个事件，而每次掷出是一个独立试验。</li><li>让大数定律发挥作用的好方法是保持冷静，持续试验，直到 <strong>累积概率 (cumulative probability)</strong> 不怎么变化为止。</li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;随机性-（randomness）&quot;&gt;&lt;a href=&quot;#随机性-（randomness）&quot; class=&quot;headerlink&quot; title=&quot;随机性 （randomness）&quot;&gt;&lt;/a&gt;随机性 （randomness）&lt;/h1&gt;&lt;p&gt;识别和理解随机性，和推断它是一样重要的技能。它们不仅在统计分析中有用，对于每天发生在我们身边的日常事物，同样有意义。这篇教程中，我将向你解释为什么人们如此不擅长应对随机性。&lt;/p&gt;
&lt;p&gt;想象你在海滩上看着海浪翻滚，然后你注意到一枚美丽的贝壳，它的个头和形状明显地异于周围其它贝壳。于是你想想看附近还有有没有这种贝壳。这是一项无法预见的行动计划 —— 贝壳可能是随机分布在这个巨大的海滩上的。因此，你找到另外一枚同类贝壳的时间是不确定的，甚至你都可能找不到一枚相似的。&lt;/p&gt;
&lt;p&gt;你开始思考这件事，然后你意识到随机性几乎在日常生活中无处不在。所以，无怪乎我们有丰富的词汇来描述它，比如不确定性、机会、风险、可能性。还有，变异性和不确定性的程度能够非常精细地描述随机性。&lt;/p&gt;
&lt;p&gt;看看下面这组词汇：罕有、少见、有时、普通、频繁、经常。有意思的是，某件事是否随机，不仅是现象自身的特性，也很大程度上取决于我们对它的认识。假如你之前就来过这片海滩，你可能已经发现过这种贝壳，从而改变这一次的搜索策略，以便增加找到更多这种贝壳的机会。你搜索的尺度也有关系，如果在很小的区域做一个短暂的搜索，可能不是很有把握找到新贝壳，但是搜索时间延长，搜索区域扩大，找到机会就会增大。&lt;/p&gt;
&lt;p&gt;尽管有这么多的词汇，以及我们在日常经验中熟记随机性的能力，我们其实一点都不擅长量化地评估随机性。一方面，我们在真实的随机数据中寻找各种 “模式”。你一定听过一个词叫 “宿命”。另一方面，我们自身又无法制造随机熟记。有一个失败尝试的案例 —— 下图中左边的通过拼接得到的贝壳随机分布的地图，实际上是分布太规则的。而右边那幅是现实的随机分布模式，看起来有更多聚集在一起的 “簇”。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/randomness.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之六 | 回归</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-regression/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-regression/</id>
    <published>2020-01-02T04:50:17.000Z</published>
    <updated>2020-01-09T03:25:15.197Z</updated>
    
    <content type="html"><![CDATA[<h1 id="回归-——-找到-“那根线”！"><a href="#回归-——-找到-“那根线”！" class="headerlink" title="回归 —— 找到 “那根线”！"></a>回归 —— 找到 “那根线”！</h1><p>最近的一项研究表明，吃大量的巧克力可能是个好主意。</p><img src="/images/regression.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这个散点图展示了一个国家每个人年均消费的巧克力数量。可以看出，一年中人们吃的巧克力数量，跟这个国家每百万人口中的诺贝尔奖获得者人数，呈正相关性。</p><p>注意，这个散点图里的巧克力消耗量显示为自变量，而诺贝尔奖获得者人数显示为因变量。</p><p>散点图里分析的单位是国家。如你所见，相关性很高。实际上，这里的皮尔逊相关系数是 0.93 。这说明，多吃巧克力虽然可能令你发胖，但同时也让你变聪明。皮尔逊相关系数告诉我们，两个连续变量之间的线性相关性有多强，这种线性相关性被显示为一根直线。在我们的案例中，是这条线。</p><img src="/images/regression_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这就是我们所说的 <strong>回归线 (regression line)</strong> 。在本节教程中，我将告诉你如何找到回归线。重要的是要知道我们如何找到这条线，而不仅仅是因为回归线向你展示了两个变量之间的关系。 <em>找到回归线是许多统计分析的基础。</em></p><p>那么，我们如何找到回归线呢？想象你正在绘制散点图里每一条可能的直线。所以，你像下面这样画了许多可能的线。这是一组数量巨大的线。实际上，这几乎不可能做到。不过，暂时想象你有超能力 —— 你能做到这一点。</p><a id="more"></a><img src="/images/regression_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>接下来，你可以测量每条可能的线与每个案例之间的距离。在我们的例子，即线到每个国旗之间的距离。</p><p>让我给你举一个基于随机线的例子，比如，下面这个。测量日本和线的之间的垂直距离，西班牙和线之间的距离等等。直到你知道你的研究中每个案例的距离。</p><img src="/images/regression_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>每一个距离都被称为 <strong>残差 (residual)</strong>，你最终会得到正的残差，它们以线之上的案例到线之间的蓝色线段展示；以及负的残差，它们以线之下的案例到线之间的红色线段展示。</p><p>你为每一条可能的线测量残差。最终，我们选择一条能够 <em>使得残差的平方和最小的线</em> ，这便是我们要找的那根线。</p><img src="/images/regression_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>为什么是残差的平方和呢？因为正的残差和负的残差会相互抵消。</p><p>最佳拟合的线被称为 <strong>回归线</strong> ，分析的方法被称为 <strong>普通最小二乘回归 (ordinary least squares regression)</strong> ，这是指我们找到这条线的方式。</p><p>在实践中，几乎不可能绘制每一条可能的线和残差的和。幸运的是，数学家已经找到了寻找回归线的技巧。我不会解释这个把戏在这里是如何运作的，因为它相当复杂。目前为止，知道它基于残差的平方和就已经足够了。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><blockquote><p>你学到两件事：第一，你学会如何计算并寻找回归线；第二，你了解到，吃巧克力很可能有助于你通过这门课程。:D</p></blockquote><hr><h1 id="回归-——-描述-“那根线”"><a href="#回归-——-描述-“那根线”" class="headerlink" title="回归 —— 描述 “那根线”"></a>回归 —— 描述 “那根线”</h1><p>回归线是最好地描述两个变量之间线性关系的直线。但我们要如何描述这条线的样子呢？</p><p>这是一个非常重要的问题，因为通过用公式描述，我们可以很容易地把 <strong>回归的分析 (regression analysis)</strong> 传达给其他人，预测其他国家的诺贝尔奖获得者人数，以及确定不符合该模式的国家。基于此散点图中的回归线，我们可以预测：每年巧克力人均消费量为 6 公斤的国家，平均每 1000 万个人中有 11 位诺贝尔奖获得者。</p><img src="/images/regression_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>同样，基于同一条线，我们将预测一个每年人均巧克力消费量为 11 公斤的国家，平均每 1000 万人中 会有 25 个诺贝奖获得者。</p><img src="/images/regression_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>对大多数国家来说，这一预测并不完全正确。毕竟，大多数国家并不恰好在回归线上。然而，这是我们能做出的最好的预测 —— 根据我们掌握的信息。</p><img src="/images/regression_8.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>有一个简单的公式，我们可以用它来描述回归线。这就是那个公式。 </p><p>$$\hat y = a + bx$$</p><p>$\hat y$ 不是 y 的实际值，但它表示 y 的预测值。例如，当 x 等于 12 时， $\hat y$ 等于 28 。 请注意，在这种情况下， y 的实际值为 33 。但是， y 的预测值是回归线上的 y 的值。这意味着，正好在回归线上所有的值是 $\hat y$ 。</p><p>a 就是我们所说的 <strong>截距</strong> ，它是一个常数。当 x 等于 0 时，它是 y 的预测值。换句话说，当回归线上 y 的预测值与 y 轴的相交时， x 等于 0 。在我们的案例里，它是 -5.63 。请注意，这个值没有实质性的含义。不可能每 1000 万人中有 -5.63 名诺贝尔奖获得者。它只有一个目的：描述回归线的数学性质。</p><p>b 就是我们所说的 <strong>回归系数 (regression coefficient)</strong> 或 <strong>斜率 （regression slope）</strong> 。 它是当 x 增加一个单位时， $\hat y$ 的变化。在我们的例子中，我们看到当 x 增加一个单位，例如，从 4 到 5， y 的预测值增加 2.80 个单位。</p><p>因为是一条直线，回归线的斜率是处处相等的。所以，如果我们看看当 x 从 8 增加到 9 时会发生什么， $\hat y$ 也是增加 2.80 单位。我们案例中的回归系数为 2.80 。这可以推导出下面这个 <strong>回归方程 (regression equation)</strong>。 </p><p>$$ \hat y = 5.63 + 2.80x $$</p><p>请看这两条回归线。它们具有相同的回归系数或 b 值。 当 x 增加一个单位时，第一条线和第二条线的 y 值增长的量是一样的。但是，这些线具有不同的截距，或一个值。毕竟，它们在不同的位置上穿过 y 轴。</p><img src="/images/regression_9.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这两条回归线具有不同的回归系数。当 x 增加一个单位时，第一条线上的 $\hat y$ 比第二号线上的 $\hat y$ 增加地更多。然而，这两条线的截距是相同的，因为它们在同一个点穿过 y 轴。</p><img src="/images/regression_10.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>我已经对你说过了，我们可以用回归线来预测 y 值 —— 基于给定的 x 值。我们还可以使用回归公式进行预测。让我们用一个回归公式。 $\hat y = -5.63 + 2.80x$ 。我们可以使用公式预测 y 值。如果 x = 3.5，该怎么办？我们得到 -5.63 + (2.80 * 3.5)。 这就得出了 4.17 。 所以这里的 $\hat y = 4.17$ 。 如果 x = 10.21，该怎么办？ 然后你得到 -5.63 + (2.80 x 10.21) 。 这使得 $\hat y$ 等于 22.96 。 当我们只看回归线时，我们得到了相同的值。对于 x 值等于 3.5 时，我们得到的预测 y 值约为 4 。 对于 x 值等于 10.21 时，我们得到的 $\hat y$ 值约为 23 。 你已经可以看到，使用公式有一个巨大的优势 —— 你可以做出更精确的预测。</p><p>通常情况下，计算机会为你找到回归线，所以你不需要自己计算。然而，当你知道你的变量的均值和标准差，以及相应的皮尔逊系数，你可以通过两个公式计算回归方程。</p><p>$$b = r\left (\frac {s_y}{s_x}\right)$$<br>$$a = \bar y - b (\bar x)$$</p><p>第一个公式通过将皮尔逊的回归系数乘以 y 的标准差，再除以 x 的标准差。这表明了回归系数事实上是皮尔逊系数的一个不标准化的版本。当 pearson 的 r 等于 0 时，回归系数等于 0 。当皮尔逊的 r 是一个正数，回归系数也是正数，当皮尔逊系数为负时，回归系数也是负的。</p><img src="/images/regression_11.jpg" width="68%" height="68%" style="margin: 10 auto;">这些是我们的研究的均值、标准差和皮尔逊系数。因此，为了找到回归系数，我们乘以 0.93 * (11.87/3.95)，结果是 2.79 。第二个公式用回归系数乘 x 的均值，之后从 y 的均值减去结果来计算截距。<p>所以 13.17-(2.79 * 6.71) 。 这样就可以得到 -5.55 了。回归方程为 -5.55 + 2.79 x 。</p><p>与这一个计算机算出的回归方程的不同是由舍入误差导致的。我用汇总均值、标准差和皮尔逊系数来计算，这导致了一个不太精确的回归方程。因此，在使用这些公式时，尽量减少舍入。恭喜你成功完成了这个教程的上半部分！现在，你可以进行回归分析并计算预测值了。了解回归的基础知识是至关重要的，因为能够了解之后的推理回归过程。</p><p>所以多看这篇教程几次。:D</p><blockquote><p>如果自变量 x 是你看这篇教程的次数，并且因变量 y 是你掌握的回归分析的知识，当你这样做时，回归分析的回归斜率将是一个正数。</p></blockquote><p>如果你不明白上面这句话意味着什么，立即重温这篇教程吧。</p><hr><h1 id="回归-——-“那根线有多适用？”"><a href="#回归-——-“那根线有多适用？”" class="headerlink" title="回归 —— “那根线有多适用？”"></a>回归 —— “那根线有多适用？”</h1><p>在这一节，我们来研究回归线对你的数据有多适用。</p><p>为什么需要关注回归线的适用程度呢？因为我们希望知道回归分析预测因变量的准确性有多高。回归线适用数据的程度是用一种称为 <strong>R 方 (r-squared)</strong> 的方法来表示的。</p><p>想象一下，你身处一个有 99 个其他学生的班级，你刚刚参加完一场统计学的考试。你的教授手上已经拿到随机选取的 20 个学生的考试成绩。教授想要分享这 20 个学生的考试成绩，但同时不想让大家知道这些学生是谁。因此，她匿名了这些分数的主人。</p><img src="/images/r_squared.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这是你看到的分数。因为是匿名的，你无从得知哪个学生拿到哪个分数。注意，最低分数是 0 ，最高分数是 10 。现在，想象你被要求预测你邻桌同学的分数。你怎么预测得到的分数会更靠谱呢？一个显而易见的答案是，用这 20 个分数的平均值，这个值时 6.8 。现在，继续想象教授还给了你这 20 个分数对应学生上一次统计学考试的分数，同样也是匿名的。结果如下：</p><img src="/images/r_squared_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>现在，你会如何预测你邻桌的分数呢？是的，你可以利用到回归分析了。下面是回归线和 <strong>回归方程 (regression equation)</strong> 的散点图。</p><img src="/images/r_squared_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>你会发现，那些在之前的考试中取得高分的同学趋向于在这一次考试中也拿到高分。实际上，你可以用这条回归线和对应的回归方程对分数做出预测。当你问到你的邻桌他之前的分数，你可以用回归线预测他这一次考试最有可能的分数。</p><img src="/images/r_squared_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>想象上一次分数是 8.1 ，代入回归方程，得到 2.80 加 (0.59 乘以 x)，等于 7.6 。因此，这一次的分数最有可能是 7.6 。这是什么意思呢？当你只有一个变量的信息时，你做出的预测的准确性要远远低于你拥有两个相关变量信息的情况。R 方就是一个告诉你用回归线预测因变量而不是平均值这种方式有多适用的程度。</p><p>再回到我们的散点图。我加了一根水平线，用以表示这次考试分数的平均值。</p><img src="/images/r_squared_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这根线之所以是水平的，是因为平均值是一个定值 6.8 ，它不会改变。可以看到，每个观察值和回归线的残差，相比于它们到平均值的残差，总体要小得多。</p><img src="/images/r_squared_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>这表明，回归线的预测效果明显好于平均值。</p><p>在我们的案例中， R 方是 0.69 。这表示使用回归线预测错误的可能性比你使用平均值要小 69% 。 R 方也经常用另外一种说法来解释 —— 它是指你的因变量的方差，多大程度上可以由自变量的方差来解释。</p><p>一个变量的方差告诉你各个观察值相对于平均值的离散程度。因此，在我们的案例中，这一次考试分数的方差中的 69% ，可以被前一次考试的分数预测。用可视化的方式表达这种解释，可以用到两个圆。</p><img src="/images/r_squared_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>左边的圆表示自变量的方差，右边的圆表示因变量的方差。重叠的部分就是 R 方，或者说 <strong>可解释方差 (explained variance)</strong> 。当重叠部分很小时， R 方很小，重叠部分很大时， R 方很大。</p><img src="/images/r_squared_8.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>你需要了解一个很重要的事实 —— R 方和皮尔逊相关系数关联紧密。实际上，正如它的名字指示的， R 方就是皮尔逊相关系数的平方。因此，要计算 R 方，只要算出皮尔逊系数然后平方就行了。</p><p>这也说明 R 方总是一个正数。在我们的案例中，皮尔逊相关系数等于 0.83 。平方得到 R 方 0.69 。注意，如果两个变量的线性相关性是完美的，那么皮尔逊相关系数和 R 方都是 1 。如果完全线性无关，那皮尔逊相关系数和 R 方都是 0 。</p><p>但是，你需要记住： R 方的含义和皮尔逊相关系数很不同。皮尔逊相关系数告诉你两个变量之间是否存在正的或者负的相关性，以及这种相关性有多强。而 R 方并没有告诉你两个变量之间关联的方向。不过，它告诉你两件事，一是回归线预测相对于平均值预测优胜多少，二是因变量的方差有多少是可以被自变量的方差解释的。</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;回归-——-找到-“那根线”！&quot;&gt;&lt;a href=&quot;#回归-——-找到-“那根线”！&quot; class=&quot;headerlink&quot; title=&quot;回归 —— 找到 “那根线”！&quot;&gt;&lt;/a&gt;回归 —— 找到 “那根线”！&lt;/h1&gt;&lt;p&gt;最近的一项研究表明，吃大量的巧克力可能是个好主意。&lt;/p&gt;
&lt;img src=&quot;/images/regression.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;这个散点图展示了一个国家每个人年均消费的巧克力数量。可以看出，一年中人们吃的巧克力数量，跟这个国家每百万人口中的诺贝尔奖获得者人数，呈正相关性。&lt;/p&gt;
&lt;p&gt;注意，这个散点图里的巧克力消耗量显示为自变量，而诺贝尔奖获得者人数显示为因变量。&lt;/p&gt;
&lt;p&gt;散点图里分析的单位是国家。如你所见，相关性很高。实际上，这里的皮尔逊相关系数是 0.93 。这说明，多吃巧克力虽然可能令你发胖，但同时也让你变聪明。皮尔逊相关系数告诉我们，两个连续变量之间的线性相关性有多强，这种线性相关性被显示为一根直线。在我们的案例中，是这条线。&lt;/p&gt;
&lt;img src=&quot;/images/regression_2.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;这就是我们所说的 &lt;strong&gt;回归线 (regression line)&lt;/strong&gt; 。在本节教程中，我将告诉你如何找到回归线。重要的是要知道我们如何找到这条线，而不仅仅是因为回归线向你展示了两个变量之间的关系。 &lt;em&gt;找到回归线是许多统计分析的基础。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;那么，我们如何找到回归线呢？想象你正在绘制散点图里每一条可能的直线。所以，你像下面这样画了许多可能的线。这是一组数量巨大的线。实际上，这几乎不可能做到。不过，暂时想象你有超能力 —— 你能做到这一点。&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之五 | 相关性</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-correlation/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-correlation/</id>
    <published>2020-01-02T01:28:57.000Z</published>
    <updated>2020-01-08T08:59:51.811Z</updated>
    
    <content type="html"><![CDATA[<p>很多人喜欢吃巧克力，但多数人吃巧克力是比较谨慎的。因为吃了太多巧克力，很有可能会增加体重。在这一期的教程中，我将讨论如何使用表格和图表展示 <em>两个变量之间的关系</em> 。这有助于发现两个变量之间是否存在 <strong>相关性 (correlation)</strong> 。</p><h1 id="列联表-Contingency-Tables"><a href="#列联表-Contingency-Tables" class="headerlink" title="列联表 (Contingency Tables)"></a>列联表 (Contingency Tables)</h1><p>我们来进一步研究吃巧克力和体重之间的关系。</p><p>假设我在我们学校选择了 200 名女学生。她们身高都是一米七。这样，身高就是一个常数，不会影响体重或吃巧克力。让学生报告体重及每周巧克力消费情况。体重可以选择这样几个类别：小于 50 公斤； 50 至 69 公斤； 70 至 89 公斤和 90 公斤或以上。巧克力消费量可以选择这样几个类别：每周少于 50 克；每周 50 至 150 克；每周超过 150 克。</p><p>结果如下，这里看到的是 <strong>列联表</strong> 。 <strong>列联表</strong> 能够显示 <strong>两个定序或定类变量之间的关系</strong> 。 它类似于频率表，但主要区别在于 <strong>频率表始终只考虑一个变量，而列联表考虑两个变量</strong> 。</p><a id="more"></a><p>在我们的研究中，有两个变量：体重和巧克力消费量。</p><p><img src="/images/crosstab.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>该表显示我们有 33 个体重小于 50 公斤的样本 其中 27 人每周吃巧克力少于 50 克。还可以看到，每周有 90 人吃 50 至 150 克巧克力，其中 7 个体重 90 公斤及以上。</p><p>这种情况下，该表并不能提供两个变量之间的相关性信息，因为列和行包含不同数量的个案 —— 计算百分比可以提供更多洞察力。这种情况下，我们计算列的百分比，这意味着对于每个单元格，我们计算该单元格中的案例百分比，与相应列中的案例总数进行比较。</p><p>结果如示：</p><p><img src="/images/crosstab_2.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>我们也可以将这些百分比表示为比例: 45％ 则变为 0.45， 38％ 变为 0.38 。我们将这些比例称为 <strong>条件比例 (conditional proportions)</strong> —— 因为形成需要以另一个变量为前提条件。在这种情况下，该变量是巧克力消费量。</p><p><img src="/images/crosstab_3.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>我们也可以忽略巧克力消费的信息，并使用表格边缘的计数。这些都是 <strong>边际比例 (marginal proportions)</strong> 。例如， 33 除以 200 等于 0.17 。这个比例显示，研究中比例是 0.17 或 17％ 的受访者中，重量不到 50 公斤。</p><p><img src="/images/crosstab_4.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>这是什么意思呢？ 在每周吃巧克力超过 150 克的样本中， 56％ 的人体重达 90 公斤及以上；吃巧克力少于 50 克的样本中，只有 5％ 体重为 90 公斤或以上；另外，那些吃巧克力不到 50 克的人， 45％ 的人体重不到 50 公斤，而吃巧克力超过 150 克的人，只有 2％ 的体重不到 50 公斤。</p><p><img src="/images/crosstab_5.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>这些百分比表明：吃更多巧克力的人也更容易超重，而少吃巧克力的人也更可能体重较小。换句话说，<em>百分比表明巧克力消费量与体重之间存在相关性。</em></p><hr><h1 id="散点图-Scatterplot"><a href="#散点图-Scatterplot" class="headerlink" title="散点图 (Scatterplot)"></a>散点图 (Scatterplot)</h1><ul><li>列联表对定类和定序变量很有用，但不适用于定量变量。<em>对于定量变量，散点图更合适。</em> 假设没有提供类别，而是让 200 名女性给出确切的体重，例如 65 或 72 公斤。假设也要求他们告知每周吃巧克力的确切重量，例如每周可以是 64 克或 99 克。现在，有比之前更精确的信息展示定量变量，巧克力消费和体重之间关系的最佳方法是使用 <strong>散点图</strong> 。</li></ul><p>制作散点图，我们绘制两条线，称之为 <strong>轴</strong> 。我们将水平轴称为 <strong>X 轴</strong> 。这里展示的是 <strong>自变量 (independent variable)</strong> ，垂直轴称为 <strong>Y 轴</strong> ，我们用它来表示 <strong>因变量 (dependent variable)</strong> 。如果因变量和自变量之间没有区别，则 Y 轴和 X 轴上的位置是一个选择问题。在我们的例子中，自变量是巧克力消耗量，因变量是体重。</p><p>假如我们的研究表明，最少的巧克力消耗等于每周零克，最高的量是每周 700 克。我们在 x 轴上标注这些值；同样，体重的最小值为 40 公斤，最大值为 110 公斤。</p><p><img src="/images/scatterplot.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>接着我们在此图中显示每个人，为样本中的所有人做标注，这就绘制出了一幅散点图。散点图一目了然地显示巧克力消费量与体重之间存在相关性：吃的巧克力越多，体重就越高。</p><p><img src="/images/scatterplot_2.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><hr><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><blockquote><p>大家学到了什么呢？不止于巧克力消耗量和体重的相关关系，我想大多数人已经意识到了：我们可以通过表格和图表显示 <strong>两个变量之间的关系</strong> ，<strong>当研究中的变量是定类或定序变量时，我们使用列联表；当它们是定量测量时，我们使用散点图</strong> 。</p></blockquote><hr><h1 id="皮尔逊积矩相关系数-Pearson’s-r"><a href="#皮尔逊积矩相关系数-Pearson’s-r" class="headerlink" title="皮尔逊积矩相关系数 (Pearson’s r)"></a>皮尔逊积矩相关系数 (Pearson’s r)</h1><p>散点图一目了然地表明两个变量之间存在很强的相关性，但 <strong>这种相关性有多强</strong> ？我们现在将要讨论最常用的相关性度量方法之一 —— <strong>皮尔逊积矩相关系数</strong> 。皮尔逊相关系数最重要的优点之一是：它用一个数字表示两个变量之间线性相关的 <strong>方向</strong> 和 <strong>强度</strong> 。</p><p>巧克力消费和体重之间的关系可以用这条直线来描述。因为所有案例都紧密围绕这条线，所以可以得出结论，这是一个相当强的相关性关系。</p><p><img src="/images/pearsonsr.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>另一个需要注意的点是，直线向上延伸，表明更多的巧克力消耗与更高的体重相关。因此，也可以说存在 <strong>正相关</strong> 关系。结论：这里存在一个强正向线性关系。</p><p>然而，变量也可以以不同的方式相关联。</p><p><img src="/images/correlation.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>在上图的第一幅图中，可以看到变量 x 和 y 之间存在相当强的正向线性关系，如同巧克力消费和体重的示例一样；而在第二幅图中，存在一个相当强的负向线性相关性 —— 直线向下表示当变量 x 上升时，变量 y 下降。第三幅图也可以看到正向线性关系，但是它比之前的强度要小得多 —— 因为每个案例都远离直线。第四幅图则是一个完全负向线性相关。之所以说完全的，是因为所有案例都完全落在线上。</p><p>但两个变量之间的相关性不必是线性的。在第五幅图中，可以看到变量 x 和 y 之间的关系。最能代表两个变量之间关系的线并不是直线。相反，是一个 U 形线，我们称之为曲线关系。</p><blockquote><p>散点图有助于我们总体评估相关性是强还是弱，但它并没有告诉我们这种关系强度到底是多少。皮尔逊相关系数恰巧可以展示确切数字 —— 更具体地说，皮尔逊相关系可以告诉我们 <strong>两个定量变量之间线性关系的方向和精确强度</strong> 。正皮尔逊相关系数表示相关性为正，而负系数表示相关性为负。</p></blockquote><p>系数的大小表示 <strong>观测结果围绕数据假想最佳拟合直线的紧密程度</strong> 。<em>皮尔逊相关系数是始终介于 -1 和 1 之间的数字：负 1 表示完全负相关；正 1 表示完全正相关； 0 表示完全没有相关性。</em></p><p>那如何计算皮尔逊相关系数呢？试想巧克力消费和体重的研究不是 200 个样本，而是四个样本。</p><p>下面是数据矩阵和散点图：</p><p><img src="/images/pearsonr_2.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>可以看到两个变量的每个值的组合在图形中变为一个圆点。要计算皮尔逊相关系数，我们需要这个公式：</p><script type="math/tex; mode=display">r = \frac {\sum {Z_xZ_y}}{n - 1}</script><p>这是什么意思呢？首先将所有原始分数改为 z 分数，换句话说，标准化所有数值 —— 原因是我们希望皮尔逊相关系数是介于 -1 和 1 之间的数字 。如果不进行标准化，相关性将会以原始数据呈现。</p><p>首先，我们计算两个变量的均值：变量 x 的值为 162.5 ，即巧克力消耗量；变量 y 的值为 71.25 ，即体重。然后计算两个变量的标准差， x 的结果为 110.9 ， y 的结果为 18.4。再然后计算每个案例的 z 分数，从每个值中减去均值，然后除以标准差。</p><p>为自变量的每个值，即巧克力消耗量，因变量的每个值，即体重，进行如此计算。下一步，计算 y 值 z 分数和 x 值 z 分数的乘积。 </p><p><img src="/images/pearsonr_3.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><p>计算公式的最后一部分，将所有这些 z 分数的乘积相加，将得数除以 n 减 1。所以在我们的例子中，皮尔逊相关系数是 2.78 除以 (4 - 1) ，等于 0.93 。这是什么意思呢 —— 这意味着巧克力消费与体重之间存在强烈的正向线性关系。</p><blockquote><p>一个重要注意事项：即使关系是非线性的，也可以随时计算皮尔逊相关系数。因此，<em>在计算皮尔逊相关系数之前，要先检查散点图看变量是否存在线性相关</em> ，这一点非常重要。如果不存在，就不要计算皮尔逊相关系数，因为它就不能提供太多变量关系信息。</p></blockquote><p>例如，下面这个散点图显示 x 和 y 之间存在强烈的 <strong>曲线关系</strong> 。如果计算皮尔逊相关系数，会得到一个非常低的值，负 0.15 。这并不能说相关性较弱，只能说线性相关性较弱。</p><p><img src="/images/pearsonr_4.jpg" width="68%" height="68%" style="margin: 10 auto;"></p><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><blockquote><p>计算四个样本的皮尔逊相关系数是相当容易的。但是，可以想象，当样本是 200 个时，这几乎是不可能完成的任务。幸运的是，每个统计程序都可以快速计算皮尔逊相关系数。然而，重要的是要了解皮尔逊相关系数究竟意味着什么。了解公式的含义也很重要，它可以帮你更好地理解变量的相关性，也可能会帮你决定 “每周吃多少巧克力。” :)</p></blockquote><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;很多人喜欢吃巧克力，但多数人吃巧克力是比较谨慎的。因为吃了太多巧克力，很有可能会增加体重。在这一期的教程中，我将讨论如何使用表格和图表展示 &lt;em&gt;两个变量之间的关系&lt;/em&gt; 。这有助于发现两个变量之间是否存在 &lt;strong&gt;相关性 (correlation)&lt;/strong&gt; 。&lt;/p&gt;
&lt;h1 id=&quot;列联表-Contingency-Tables&quot;&gt;&lt;a href=&quot;#列联表-Contingency-Tables&quot; class=&quot;headerlink&quot; title=&quot;列联表 (Contingency Tables)&quot;&gt;&lt;/a&gt;列联表 (Contingency Tables)&lt;/h1&gt;&lt;p&gt;我们来进一步研究吃巧克力和体重之间的关系。&lt;/p&gt;
&lt;p&gt;假设我在我们学校选择了 200 名女学生。她们身高都是一米七。这样，身高就是一个常数，不会影响体重或吃巧克力。让学生报告体重及每周巧克力消费情况。体重可以选择这样几个类别：小于 50 公斤； 50 至 69 公斤； 70 至 89 公斤和 90 公斤或以上。巧克力消费量可以选择这样几个类别：每周少于 50 克；每周 50 至 150 克；每周超过 150 克。&lt;/p&gt;
&lt;p&gt;结果如下，这里看到的是 &lt;strong&gt;列联表&lt;/strong&gt; 。 &lt;strong&gt;列联表&lt;/strong&gt; 能够显示 &lt;strong&gt;两个定序或定类变量之间的关系&lt;/strong&gt; 。 它类似于频率表，但主要区别在于 &lt;strong&gt;频率表始终只考虑一个变量，而列联表考虑两个变量&lt;/strong&gt; 。&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>极速统计教程之四 | Z-score</title>
    <link href="https://theinfinitegame.tech/data-science/statistics-z-scores/"/>
    <id>https://theinfinitegame.tech/data-science/statistics-z-scores/</id>
    <published>2020-01-01T02:49:06.000Z</published>
    <updated>2020-01-06T01:47:54.489Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>通俗解释 z-score ，即 z-score 是对某一原始分值进行转换，变成的一个标准分值，该标准分值可使得原来无法比较的数值变得可比。</p></blockquote><h1 id="Z-score"><a href="#Z-score" class="headerlink" title="Z-score"></a>Z-score</h1><p>本教程中我们还继续沿用前面教程中足球队的例子。</p><img src="/images/z-score.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>你在这里看到的是所谓的球员纹身占比，以纹身占身体的百分比表示。点图和标准差表明，第二队的分布比第一队的变化更大。</p><p>有时研究人员会问：一个特定的观测结果是常见还是特例。为了回答这个问题，研究人员会用 <strong>一个数与平均数的差再除以标准差</strong> 。这个数字就是我们所说的 z 分数。在这篇教程中，我将解释如何计算 z 分数，以及它们的用处。</p><p>我们先来看看第一队的分布情况。平均数是 15 ，标准差是 2.5 。为了计算 z 分数，我们使用这个公式：</p><p>$$ z = \frac {(x - \bar x)}{s} $$</p><p>这个公式不是很复杂，它告诉你如何计算感兴趣的数值。该数值与平均数之差，再除以标准差。</p><a id="more"></a><p>来看看纹身占比是 10.8％ 意味着什么。该值的 z 分数是 10.8 减去 15 再除以 2.5 等于负 1.68 。所以 z 分数是负 1.68 。你可以为所有数值进行如此计算。如果这样做，这些就是结果。</p><img src="/images/z-score_2.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>请注意，最终会得到负 z 分数和正 z 分数。负 z 分数表示低于平均数的值；正 z 分数表示高于平均数的值。因为平均数是分布的平衡点，所以负的和正的 z 分数相互抵消。换句话说，如果将所有 z 分数相加，结果为 0 。</p><p>好的，不过如何知道某个 z 分数是低还是高呢？</p><p>这取决于分布和前后关系。有一个黄金定律：如果变量的直方图是钟形的，那么 68％ 的观测值在 z 分数 -1 和 1 之间， 95％ 在 z 分数 -2 和 2 之间， 99％ 在 z 分数 -3 和 3 之间。这意味着对于这种类型的分布， z 分数大于 3 或小于 -3 ，可以被认定是特例。</p><img src="/images/z-score_3.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>但是，如果分布严重偏向右侧，如下图所示，较大的正 z 分数会更常见，因为分布的右侧有更多极值。</p><img src="/images/z-score_4.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>类似，如果分布严重偏向左侧 则较大的负 z 分数会更常见，因为分布的左侧存在更多极值。</p><img src="/images/z-score_5.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>无须考虑形状，适用于任何分布的规则。 <strong>75％ 的数据必须落在 z 分数正负 2 之内。</strong></p><img src="/images/z-score_6.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>且 <strong>89％ 的数据在 z 分数正负 3 之间。</strong> </p><img src="/images/z-score_7.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>因此， z 分数本身就在一定程度上，给出了关于观测极端程度的信息。如果要比较不同的分布， z 分数就更有用了。比如，来看一下 19.3 的体重是否常见：</p><img src="/images/z-score_8.jpg" width="68%" height="68%" style="margin: 10 auto;"><p>在第 1 组中，这并不常见。 z 分数为 19.3 减去 15 再除以 2.5 ，等于 1.72 。在第 2 组中， 19.3 的 z 分数等于 19.3 减去 15 除以 8 等于 0.54 。这表明在第 2 组中， 19.3 的体重更常见。在第 2 组中， z 分数是 0.54 ，在第 1 组中，是 1.72 。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>如果我们将原始分数重新编码为 z 分数，就是 <strong>将变量标准化</strong> 。 <strong>标准化</strong> 意味着我们用 z 分数 替换原始度量中测量的分数，其优点是我们可以一眼看出特定分数是相对常见还是特殊。</p><p>因此，一个球员纹身占比是五分之一是否异常，这取决于球队或你想比对的另一组数据。</p><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;通俗解释 z-score ，即 z-score 是对某一原始分值进行转换，变成的一个标准分值，该标准分值可使得原来无法比较的数值变得可比。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;Z-score&quot;&gt;&lt;a href=&quot;#Z-score&quot; class=&quot;headerlink&quot; title=&quot;Z-score&quot;&gt;&lt;/a&gt;Z-score&lt;/h1&gt;&lt;p&gt;本教程中我们还继续沿用前面教程中足球队的例子。&lt;/p&gt;
&lt;img src=&quot;/images/z-score.jpg&quot; width=&quot;68%&quot; height=&quot;68%&quot; style=&quot;margin: 10 auto;&quot;&gt;

&lt;p&gt;你在这里看到的是所谓的球员纹身占比，以纹身占身体的百分比表示。点图和标准差表明，第二队的分布比第一队的变化更大。&lt;/p&gt;
&lt;p&gt;有时研究人员会问：一个特定的观测结果是常见还是特例。为了回答这个问题，研究人员会用 &lt;strong&gt;一个数与平均数的差再除以标准差&lt;/strong&gt; 。这个数字就是我们所说的 z 分数。在这篇教程中，我将解释如何计算 z 分数，以及它们的用处。&lt;/p&gt;
&lt;p&gt;我们先来看看第一队的分布情况。平均数是 15 ，标准差是 2.5 。为了计算 z 分数，我们使用这个公式：&lt;/p&gt;
&lt;p&gt;$$ z = \frac {(x - \bar x)}{s} $$&lt;/p&gt;
&lt;p&gt;这个公式不是很复杂，它告诉你如何计算感兴趣的数值。该数值与平均数之差，再除以标准差。&lt;/p&gt;
    
    </summary>
    
    
      <category term="data-science" scheme="https://theinfinitegame.tech/categories/data-science/"/>
    
    
      <category term="统计" scheme="https://theinfinitegame.tech/tags/%E7%BB%9F%E8%AE%A1/"/>
    
      <category term="数据科学" scheme="https://theinfinitegame.tech/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
</feed>
